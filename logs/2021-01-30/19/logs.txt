
-------------   Fold 1 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-28/1/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/60
60/60 - 11s - loss: 0.2543 - lwlrap: 0.4752 - val_loss: 0.1720 - val_lwlrap: 0.5853
Epoch 2/60
60/60 - 9s - loss: 0.1590 - lwlrap: 0.7580 - val_loss: 0.1580 - val_lwlrap: 0.5561
Epoch 3/60
60/60 - 10s - loss: 0.1423 - lwlrap: 0.7355 - val_loss: 0.1800 - val_lwlrap: 0.6681
Epoch 4/60
60/60 - 10s - loss: 0.1776 - lwlrap: 0.8234 - val_loss: 0.2263 - val_lwlrap: 0.7068
Epoch 5/60
60/60 - 9s - loss: 0.0884 - lwlrap: 0.7900 - val_loss: 0.2003 - val_lwlrap: 0.6414
Epoch 6/60
60/60 - 10s - loss: 0.0862 - lwlrap: 0.8623 - val_loss: 0.0469 - val_lwlrap: 0.7414
Epoch 7/60
60/60 - 10s - loss: 0.0965 - lwlrap: 0.8803 - val_loss: 0.1906 - val_lwlrap: 0.7967
Epoch 8/60
60/60 - 9s - loss: 0.0264 - lwlrap: 0.9182 - val_loss: 0.1674 - val_lwlrap: 0.7957
Epoch 9/60
60/60 - 10s - loss: 0.0218 - lwlrap: 0.9601 - val_loss: 0.1460 - val_lwlrap: 0.8280
Epoch 10/60
60/60 - 10s - loss: 0.0189 - lwlrap: 0.9774 - val_loss: 0.1647 - val_lwlrap: 0.8411
Epoch 11/60
60/60 - 10s - loss: 0.0244 - lwlrap: 0.9860 - val_loss: 0.2026 - val_lwlrap: 0.8434
Epoch 12/60
60/60 - 9s - loss: 0.0083 - lwlrap: 0.9824 - val_loss: 0.0897 - val_lwlrap: 0.8251
Epoch 13/60
60/60 - 9s - loss: 0.0024 - lwlrap: 0.9905 - val_loss: 0.1248 - val_lwlrap: 0.8314
Epoch 14/60
60/60 - 9s - loss: 0.0044 - lwlrap: 0.9811 - val_loss: 0.2054 - val_lwlrap: 0.8269
Epoch 15/60
60/60 - 9s - loss: 0.0202 - lwlrap: 0.9733 - val_loss: 0.1845 - val_lwlrap: 0.8343
Epoch 16/60
60/60 - 9s - loss: 0.0043 - lwlrap: 0.9793 - val_loss: 0.1543 - val_lwlrap: 0.8251
Epoch 17/60
60/60 - 9s - loss: 0.0269 - lwlrap: 0.9869 - val_loss: 0.0845 - val_lwlrap: 0.8081
Epoch 18/60
60/60 - 9s - loss: 0.0045 - lwlrap: 0.9859 - val_loss: 0.2379 - val_lwlrap: 0.8193
Epoch 19/60
60/60 - 9s - loss: 0.0211 - lwlrap: 0.9945 - val_loss: 0.1135 - val_lwlrap: 0.8144
Epoch 20/60
60/60 - 10s - loss: 0.0064 - lwlrap: 0.9952 - val_loss: 0.1023 - val_lwlrap: 0.8484
Epoch 21/60
60/60 - 9s - loss: 0.0096 - lwlrap: 0.9977 - val_loss: 0.1808 - val_lwlrap: 0.8465
Epoch 22/60
60/60 - 9s - loss: 0.0092 - lwlrap: 0.9986 - val_loss: 0.1226 - val_lwlrap: 0.8431
Epoch 23/60
60/60 - 9s - loss: 0.0070 - lwlrap: 0.9979 - val_loss: 0.2016 - val_lwlrap: 0.8342
Epoch 24/60
60/60 - 10s - loss: 0.0046 - lwlrap: 0.9974 - val_loss: 0.1856 - val_lwlrap: 0.8492
Epoch 25/60
60/60 - 9s - loss: 0.0056 - lwlrap: 0.9937 - val_loss: 0.2584 - val_lwlrap: 0.8350
Epoch 26/60
60/60 - 10s - loss: 0.0059 - lwlrap: 0.9954 - val_loss: 0.0790 - val_lwlrap: 0.8681
Epoch 27/60
60/60 - 9s - loss: 0.0018 - lwlrap: 0.9898 - val_loss: 0.2882 - val_lwlrap: 0.8107
Epoch 28/60
60/60 - 9s - loss: 0.0126 - lwlrap: 0.9985 - val_loss: 0.3935 - val_lwlrap: 0.8347
Epoch 29/60
60/60 - 9s - loss: 0.0015 - lwlrap: 0.9943 - val_loss: 0.3718 - val_lwlrap: 0.8268
Epoch 30/60
60/60 - 9s - loss: 6.2059e-04 - lwlrap: 0.9977 - val_loss: 0.3369 - val_lwlrap: 0.8476
Epoch 31/60
60/60 - 9s - loss: 0.0027 - lwlrap: 0.9980 - val_loss: 0.2753 - val_lwlrap: 0.8468
Epoch 32/60
60/60 - 9s - loss: 5.9340e-04 - lwlrap: 0.9992 - val_loss: 0.3125 - val_lwlrap: 0.8586
Epoch 33/60
60/60 - 9s - loss: 0.0099 - lwlrap: 0.9990 - val_loss: 0.4258 - val_lwlrap: 0.8450
Epoch 34/60
60/60 - 9s - loss: 8.5278e-04 - lwlrap: 0.9984 - val_loss: 0.4823 - val_lwlrap: 0.8463
Epoch 35/60
60/60 - 9s - loss: 0.0085 - lwlrap: 0.9977 - val_loss: 0.3765 - val_lwlrap: 0.8403
Epoch 36/60
60/60 - 9s - loss: 0.0011 - lwlrap: 0.9993 - val_loss: 0.4845 - val_lwlrap: 0.8341
Epoch 37/60
60/60 - 9s - loss: 7.1351e-04 - lwlrap: 0.9982 - val_loss: 0.4384 - val_lwlrap: 0.8279
Epoch 38/60
60/60 - 9s - loss: 0.0011 - lwlrap: 0.9986 - val_loss: 0.3341 - val_lwlrap: 0.8571
Epoch 39/60
60/60 - 10s - loss: 5.4319e-04 - lwlrap: 0.9970 - val_loss: 0.4348 - val_lwlrap: 0.8390
Epoch 40/60
60/60 - 9s - loss: 0.0015 - lwlrap: 0.9988 - val_loss: 0.3759 - val_lwlrap: 0.8458
Epoch 41/60
60/60 - 9s - loss: 0.0245 - lwlrap: 1.0000 - val_loss: 0.2713 - val_lwlrap: 0.8445
Epoch 42/60
60/60 - 9s - loss: 0.0066 - lwlrap: 0.9998 - val_loss: 0.2720 - val_lwlrap: 0.8348
Epoch 43/60
60/60 - 9s - loss: 0.0019 - lwlrap: 0.9969 - val_loss: 0.3858 - val_lwlrap: 0.8182
Epoch 44/60
60/60 - 9s - loss: 6.9985e-04 - lwlrap: 1.0000 - val_loss: 0.3364 - val_lwlrap: 0.8330
Epoch 45/60
60/60 - 9s - loss: 0.0103 - lwlrap: 0.9997 - val_loss: 0.3232 - val_lwlrap: 0.8434
Epoch 46/60
60/60 - 9s - loss: 6.9541e-04 - lwlrap: 0.9993 - val_loss: 0.2728 - val_lwlrap: 0.8436

-------------   Fold 2 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-28/1/pretrained_best_fold1.h5

 -> Training Model 

Epoch 1/60
60/60 - 11s - loss: 0.2013 - lwlrap: 0.5687 - val_loss: 0.1177 - val_lwlrap: 0.7500
Epoch 2/60
60/60 - 10s - loss: 0.0745 - lwlrap: 0.8649 - val_loss: 0.0894 - val_lwlrap: 0.7577
Epoch 3/60
60/60 - 9s - loss: 0.0713 - lwlrap: 0.8081 - val_loss: 0.0956 - val_lwlrap: 0.7145
Epoch 4/60
60/60 - 9s - loss: 0.1239 - lwlrap: 0.8388 - val_loss: 0.1202 - val_lwlrap: 0.5729
Epoch 5/60
60/60 - 9s - loss: 0.1760 - lwlrap: 0.8554 - val_loss: 0.0496 - val_lwlrap: 0.7360
Epoch 6/60
60/60 - 10s - loss: 0.1304 - lwlrap: 0.8619 - val_loss: 0.0454 - val_lwlrap: 0.8433
Epoch 7/60
60/60 - 10s - loss: 0.0482 - lwlrap: 0.9280 - val_loss: 0.0459 - val_lwlrap: 0.8601
Epoch 8/60
60/60 - 9s - loss: 0.0590 - lwlrap: 0.9438 - val_loss: 0.0351 - val_lwlrap: 0.8282
Epoch 9/60
60/60 - 10s - loss: 0.0046 - lwlrap: 0.9686 - val_loss: 0.0572 - val_lwlrap: 0.8821
Epoch 10/60
60/60 - 10s - loss: 0.0058 - lwlrap: 0.9764 - val_loss: 0.0314 - val_lwlrap: 0.9002
Epoch 11/60
60/60 - 10s - loss: 0.0108 - lwlrap: 0.9835 - val_loss: 0.0419 - val_lwlrap: 0.9078
Epoch 12/60
60/60 - 9s - loss: 0.0048 - lwlrap: 0.9892 - val_loss: 0.0481 - val_lwlrap: 0.9030
Epoch 13/60
60/60 - 9s - loss: 0.0211 - lwlrap: 0.9842 - val_loss: 0.0298 - val_lwlrap: 0.8651
Epoch 14/60
60/60 - 9s - loss: 0.0198 - lwlrap: 0.9814 - val_loss: 0.0483 - val_lwlrap: 0.8432
Epoch 15/60
60/60 - 9s - loss: 0.0210 - lwlrap: 0.9616 - val_loss: 0.0808 - val_lwlrap: 0.8215
Epoch 16/60
60/60 - 9s - loss: 0.0090 - lwlrap: 0.9782 - val_loss: 0.0896 - val_lwlrap: 0.8315
Epoch 17/60
60/60 - 9s - loss: 0.0348 - lwlrap: 0.9861 - val_loss: 0.0335 - val_lwlrap: 0.8751
Epoch 18/60
60/60 - 9s - loss: 0.0368 - lwlrap: 0.9913 - val_loss: 0.0183 - val_lwlrap: 0.8692
Epoch 19/60
60/60 - 9s - loss: 0.0033 - lwlrap: 0.9977 - val_loss: 0.0293 - val_lwlrap: 0.8918
Epoch 20/60
60/60 - 9s - loss: 0.0044 - lwlrap: 0.9972 - val_loss: 0.0323 - val_lwlrap: 0.9013
Epoch 21/60
60/60 - 9s - loss: 0.0033 - lwlrap: 0.9962 - val_loss: 0.0268 - val_lwlrap: 0.8895
Epoch 22/60
60/60 - 9s - loss: 0.0015 - lwlrap: 0.9986 - val_loss: 0.0234 - val_lwlrap: 0.8837
Epoch 23/60
60/60 - 9s - loss: 0.0079 - lwlrap: 0.9965 - val_loss: 0.0314 - val_lwlrap: 0.8906
Epoch 24/60
60/60 - 9s - loss: 0.0046 - lwlrap: 0.9982 - val_loss: 0.0465 - val_lwlrap: 0.8702
Epoch 25/60
60/60 - 9s - loss: 0.0025 - lwlrap: 0.9976 - val_loss: 0.0221 - val_lwlrap: 0.8690
Epoch 26/60
60/60 - 9s - loss: 0.0234 - lwlrap: 0.9950 - val_loss: 0.0325 - val_lwlrap: 0.8888
Epoch 27/60
60/60 - 9s - loss: 0.0022 - lwlrap: 0.9985 - val_loss: 0.0272 - val_lwlrap: 0.8640
Epoch 28/60
60/60 - 9s - loss: 0.0015 - lwlrap: 0.9968 - val_loss: 0.0171 - val_lwlrap: 0.8711
Epoch 29/60
60/60 - 9s - loss: 0.0103 - lwlrap: 0.9995 - val_loss: 0.0314 - val_lwlrap: 0.8922
Epoch 30/60
