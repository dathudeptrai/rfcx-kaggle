
-------------   Fold 1 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-28/1/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/60
60/60 - 11s - loss: 0.0851 - lwlrap: 0.3854 - val_loss: 0.0644 - val_lwlrap: 0.5809
Epoch 2/60
60/60 - 9s - loss: 0.0371 - lwlrap: 0.7083 - val_loss: 0.0633 - val_lwlrap: 0.6631
Epoch 3/60
60/60 - 9s - loss: 0.0270 - lwlrap: 0.7759 - val_loss: 0.0500 - val_lwlrap: 0.6872
Epoch 4/60
60/60 - 9s - loss: 0.0408 - lwlrap: 0.8541 - val_loss: 0.0379 - val_lwlrap: 0.7087
Epoch 5/60
60/60 - 9s - loss: 0.0262 - lwlrap: 0.8656 - val_loss: 0.0535 - val_lwlrap: 0.7438
Epoch 6/60
60/60 - 9s - loss: 0.0115 - lwlrap: 0.8928 - val_loss: 0.0679 - val_lwlrap: 0.7792
Epoch 7/60
60/60 - 9s - loss: 0.0163 - lwlrap: 0.9296 - val_loss: 0.0551 - val_lwlrap: 0.7809
Epoch 8/60
60/60 - 9s - loss: 0.0113 - lwlrap: 0.9569 - val_loss: 0.0799 - val_lwlrap: 0.8086
Epoch 9/60
60/60 - 9s - loss: 0.0124 - lwlrap: 0.9688 - val_loss: 0.0781 - val_lwlrap: 0.8081
Epoch 10/60
60/60 - 9s - loss: 0.0060 - lwlrap: 0.9817 - val_loss: 0.0977 - val_lwlrap: 0.8000
Epoch 11/60
60/60 - 9s - loss: 0.0067 - lwlrap: 0.9837 - val_loss: 0.0999 - val_lwlrap: 0.7943
Epoch 12/60
60/60 - 9s - loss: 0.0076 - lwlrap: 0.9865 - val_loss: 0.0908 - val_lwlrap: 0.8014
Epoch 13/60
60/60 - 9s - loss: 0.0073 - lwlrap: 0.9863 - val_loss: 0.0335 - val_lwlrap: 0.8115
Epoch 14/60
60/60 - 9s - loss: 0.0108 - lwlrap: 0.9826 - val_loss: 0.0843 - val_lwlrap: 0.7828
Epoch 15/60
60/60 - 9s - loss: 0.0080 - lwlrap: 0.9860 - val_loss: 0.0495 - val_lwlrap: 0.7491
Epoch 16/60
60/60 - 9s - loss: 0.0102 - lwlrap: 0.9802 - val_loss: 0.0773 - val_lwlrap: 0.7828
Epoch 17/60
60/60 - 9s - loss: 0.0104 - lwlrap: 0.9874 - val_loss: 0.0816 - val_lwlrap: 0.7944
Epoch 18/60
60/60 - 9s - loss: 0.0037 - lwlrap: 0.9859 - val_loss: 0.0844 - val_lwlrap: 0.8144
Epoch 19/60
60/60 - 9s - loss: 0.0055 - lwlrap: 0.9964 - val_loss: 0.0620 - val_lwlrap: 0.7811
Epoch 20/60
60/60 - 9s - loss: 0.0061 - lwlrap: 0.9962 - val_loss: 0.0730 - val_lwlrap: 0.8143
Epoch 21/60
60/60 - 9s - loss: 0.0053 - lwlrap: 0.9966 - val_loss: 0.0507 - val_lwlrap: 0.7725
Epoch 22/60
60/60 - 9s - loss: 0.0067 - lwlrap: 0.9961 - val_loss: 0.0873 - val_lwlrap: 0.7801
Epoch 23/60
60/60 - 9s - loss: 0.0040 - lwlrap: 0.9967 - val_loss: 0.0877 - val_lwlrap: 0.7814
Epoch 24/60
60/60 - 9s - loss: 0.0024 - lwlrap: 0.9983 - val_loss: 0.0959 - val_lwlrap: 0.7819
Epoch 25/60
60/60 - 9s - loss: 0.0035 - lwlrap: 0.9963 - val_loss: 0.1021 - val_lwlrap: 0.7830
Epoch 26/60
60/60 - 9s - loss: 0.0043 - lwlrap: 0.9948 - val_loss: 0.1142 - val_lwlrap: 0.7705
Epoch 27/60
60/60 - 9s - loss: 0.0042 - lwlrap: 0.9979 - val_loss: 0.0724 - val_lwlrap: 0.7645
Epoch 28/60
60/60 - 9s - loss: 0.0058 - lwlrap: 0.9977 - val_loss: 0.1052 - val_lwlrap: 0.7757
Epoch 29/60
60/60 - 9s - loss: 0.0023 - lwlrap: 0.9969 - val_loss: 0.1205 - val_lwlrap: 0.7946
Epoch 30/60
60/60 - 9s - loss: 0.0029 - lwlrap: 0.9964 - val_loss: 0.0895 - val_lwlrap: 0.7992
Epoch 31/60
60/60 - 9s - loss: 0.0034 - lwlrap: 0.9980 - val_loss: 0.0983 - val_lwlrap: 0.7836
Epoch 32/60
60/60 - 9s - loss: 0.0042 - lwlrap: 0.9997 - val_loss: 0.0950 - val_lwlrap: 0.7726
Epoch 33/60
60/60 - 9s - loss: 0.0035 - lwlrap: 0.9987 - val_loss: 0.1016 - val_lwlrap: 0.7809
Epoch 34/60
60/60 - 9s - loss: 0.0041 - lwlrap: 0.9987 - val_loss: 0.1068 - val_lwlrap: 0.7667
Epoch 35/60
60/60 - 9s - loss: 0.0016 - lwlrap: 0.9983 - val_loss: 0.1244 - val_lwlrap: 0.7775
Epoch 36/60
60/60 - 9s - loss: 0.0037 - lwlrap: 0.9978 - val_loss: 0.1201 - val_lwlrap: 0.7697
Epoch 37/60
60/60 - 9s - loss: 0.0016 - lwlrap: 0.9973 - val_loss: 0.0985 - val_lwlrap: 0.7647
Epoch 38/60
60/60 - 9s - loss: 0.0012 - lwlrap: 0.9975 - val_loss: 0.1015 - val_lwlrap: 0.7731

-------------   Fold 2 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-28/1/pretrained_best_fold1.h5

 -> Training Model 

Epoch 1/60
60/60 - 11s - loss: 0.0448 - lwlrap: 0.5470 - val_loss: 0.0639 - val_lwlrap: 0.7756
Epoch 2/60
60/60 - 10s - loss: 0.0317 - lwlrap: 0.8582 - val_loss: 0.0450 - val_lwlrap: 0.8534
Epoch 3/60
60/60 - 9s - loss: 0.0293 - lwlrap: 0.9014 - val_loss: 0.0459 - val_lwlrap: 0.8053
Epoch 4/60
60/60 - 9s - loss: 0.0292 - lwlrap: 0.8814 - val_loss: 0.0446 - val_lwlrap: 0.8017
Epoch 5/60
60/60 - 9s - loss: 0.0452 - lwlrap: 0.9024 - val_loss: 0.0441 - val_lwlrap: 0.7046
Epoch 6/60
60/60 - 9s - loss: 0.0153 - lwlrap: 0.8978 - val_loss: 0.0439 - val_lwlrap: 0.7923
Epoch 7/60
60/60 - 9s - loss: 0.0128 - lwlrap: 0.9458 - val_loss: 0.0372 - val_lwlrap: 0.8183
Epoch 8/60
60/60 - 9s - loss: 0.0142 - lwlrap: 0.9635 - val_loss: 0.0497 - val_lwlrap: 0.8328
Epoch 9/60
60/60 - 10s - loss: 0.0108 - lwlrap: 0.9762 - val_loss: 0.0495 - val_lwlrap: 0.8659
Epoch 10/60
60/60 - 10s - loss: 0.0081 - lwlrap: 0.9866 - val_loss: 0.0445 - val_lwlrap: 0.8695
Epoch 11/60
60/60 - 9s - loss: 0.0061 - lwlrap: 0.9900 - val_loss: 0.0510 - val_lwlrap: 0.8681
Epoch 12/60
60/60 - 10s - loss: 0.0173 - lwlrap: 0.9855 - val_loss: 0.0584 - val_lwlrap: 0.8713
Epoch 13/60
60/60 - 9s - loss: 0.0031 - lwlrap: 0.9836 - val_loss: 0.0557 - val_lwlrap: 0.8481
Epoch 14/60
60/60 - 9s - loss: 0.0099 - lwlrap: 0.9863 - val_loss: 0.0555 - val_lwlrap: 0.8531
Epoch 15/60
60/60 - 9s - loss: 0.0066 - lwlrap: 0.9919 - val_loss: 0.0564 - val_lwlrap: 0.8494
Epoch 16/60
60/60 - 9s - loss: 0.0060 - lwlrap: 0.9864 - val_loss: 0.0716 - val_lwlrap: 0.8259
Epoch 17/60
60/60 - 9s - loss: 0.0043 - lwlrap: 0.9869 - val_loss: 0.0639 - val_lwlrap: 0.8367
Epoch 18/60
60/60 - 9s - loss: 0.0083 - lwlrap: 0.9916 - val_loss: 0.0504 - val_lwlrap: 0.8407
Epoch 19/60
60/60 - 9s - loss: 0.0031 - lwlrap: 0.9938 - val_loss: 0.0493 - val_lwlrap: 0.8487
Epoch 20/60
60/60 - 9s - loss: 0.0056 - lwlrap: 0.9953 - val_loss: 0.0577 - val_lwlrap: 0.8516
Epoch 21/60
60/60 - 9s - loss: 0.0032 - lwlrap: 0.9944 - val_loss: 0.0645 - val_lwlrap: 0.8648
Epoch 22/60
60/60 - 9s - loss: 0.0054 - lwlrap: 0.9947 - val_loss: 0.0440 - val_lwlrap: 0.8476
Epoch 23/60
Traceback (most recent call last):

