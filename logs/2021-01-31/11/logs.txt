
-------------   Fold 1 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/60
60/60 - 12s - loss: 0.2556 - lwlrap: 0.6160 - val_loss: 0.1740 - val_lwlrap: 0.6722
Epoch 2/60
60/60 - 11s - loss: 0.2128 - lwlrap: 0.7462 - val_loss: 0.1244 - val_lwlrap: 0.6815
Epoch 3/60
60/60 - 11s - loss: 0.1020 - lwlrap: 0.7973 - val_loss: 0.0782 - val_lwlrap: 0.6466
Epoch 4/60
60/60 - 11s - loss: 0.1253 - lwlrap: 0.8244 - val_loss: 0.2266 - val_lwlrap: 0.7148
Epoch 5/60
60/60 - 10s - loss: 0.0919 - lwlrap: 0.7649 - val_loss: 0.3041 - val_lwlrap: 0.6022
Epoch 6/60
60/60 - 11s - loss: 0.0825 - lwlrap: 0.8537 - val_loss: 0.1182 - val_lwlrap: 0.8091
Epoch 7/60
60/60 - 11s - loss: 0.0988 - lwlrap: 0.8874 - val_loss: 0.2164 - val_lwlrap: 0.8115
Epoch 8/60
60/60 - 11s - loss: 0.0360 - lwlrap: 0.9194 - val_loss: 0.1900 - val_lwlrap: 0.8302
Epoch 9/60
60/60 - 11s - loss: 0.0449 - lwlrap: 0.9524 - val_loss: 0.1503 - val_lwlrap: 0.8399
Epoch 10/60
60/60 - 11s - loss: 0.0231 - lwlrap: 0.9702 - val_loss: 0.1841 - val_lwlrap: 0.8672
Epoch 11/60
60/60 - 11s - loss: 0.0302 - lwlrap: 0.9825 - val_loss: 0.2396 - val_lwlrap: 0.8553
Epoch 12/60
60/60 - 11s - loss: 0.0108 - lwlrap: 0.9755 - val_loss: 0.1690 - val_lwlrap: 0.8427
Epoch 13/60
60/60 - 10s - loss: 0.0087 - lwlrap: 0.9816 - val_loss: 0.1354 - val_lwlrap: 0.8399
Epoch 14/60
60/60 - 11s - loss: 0.0085 - lwlrap: 0.9722 - val_loss: 0.1561 - val_lwlrap: 0.8570
Epoch 15/60
60/60 - 10s - loss: 0.0569 - lwlrap: 0.9630 - val_loss: 0.2638 - val_lwlrap: 0.8050
Epoch 16/60
60/60 - 10s - loss: 0.0232 - lwlrap: 0.9635 - val_loss: 0.2021 - val_lwlrap: 0.8003
Epoch 17/60
60/60 - 11s - loss: 0.0508 - lwlrap: 0.9802 - val_loss: 0.2003 - val_lwlrap: 0.8402
Epoch 18/60
60/60 - 10s - loss: 0.0092 - lwlrap: 0.9795 - val_loss: 0.1704 - val_lwlrap: 0.8172
Epoch 19/60
60/60 - 10s - loss: 0.0157 - lwlrap: 0.9919 - val_loss: 0.2059 - val_lwlrap: 0.8528
Epoch 20/60
60/60 - 11s - loss: 0.0324 - lwlrap: 0.9958 - val_loss: 0.2265 - val_lwlrap: 0.8732
Epoch 21/60
60/60 - 10s - loss: 0.0106 - lwlrap: 0.9971 - val_loss: 0.1937 - val_lwlrap: 0.8642
Epoch 22/60
60/60 - 10s - loss: 0.0172 - lwlrap: 0.9963 - val_loss: 0.2248 - val_lwlrap: 0.8687
Epoch 23/60
60/60 - 11s - loss: 0.0088 - lwlrap: 0.9969 - val_loss: 0.1393 - val_lwlrap: 0.8637
Epoch 24/60
60/60 - 11s - loss: 0.0093 - lwlrap: 0.9980 - val_loss: 0.1622 - val_lwlrap: 0.8451
Epoch 25/60
60/60 - 10s - loss: 0.0102 - lwlrap: 0.9925 - val_loss: 0.0681 - val_lwlrap: 0.8450
Epoch 26/60
60/60 - 10s - loss: 0.0053 - lwlrap: 0.9894 - val_loss: 0.2417 - val_lwlrap: 0.8418
Epoch 27/60
60/60 - 10s - loss: 0.0019 - lwlrap: 0.9962 - val_loss: 0.2324 - val_lwlrap: 0.8422
Epoch 28/60
60/60 - 10s - loss: 0.0043 - lwlrap: 0.9957 - val_loss: 0.1325 - val_lwlrap: 0.8349
Epoch 29/60
60/60 - 10s - loss: 0.0033 - lwlrap: 0.9970 - val_loss: 0.2694 - val_lwlrap: 0.8491
Epoch 30/60
60/60 - 10s - loss: 0.0016 - lwlrap: 0.9980 - val_loss: 0.1629 - val_lwlrap: 0.8669
Epoch 31/60
60/60 - 10s - loss: 0.0027 - lwlrap: 0.9983 - val_loss: 0.1716 - val_lwlrap: 0.8451
Epoch 32/60
60/60 - 10s - loss: 0.0092 - lwlrap: 1.0000 - val_loss: 0.3896 - val_lwlrap: 0.8505
Epoch 33/60
60/60 - 11s - loss: 0.0246 - lwlrap: 0.9993 - val_loss: 0.3096 - val_lwlrap: 0.8633
Epoch 34/60
60/60 - 10s - loss: 0.0012 - lwlrap: 0.9992 - val_loss: 0.3598 - val_lwlrap: 0.8223
Epoch 35/60
60/60 - 10s - loss: 0.0064 - lwlrap: 0.9976 - val_loss: 0.2801 - val_lwlrap: 0.8414
Epoch 36/60
60/60 - 10s - loss: 0.0033 - lwlrap: 0.9983 - val_loss: 0.2152 - val_lwlrap: 0.8236
Epoch 37/60
60/60 - 11s - loss: 0.0066 - lwlrap: 0.9978 - val_loss: 0.1766 - val_lwlrap: 0.8371
Epoch 38/60
60/60 - 10s - loss: 0.0054 - lwlrap: 0.9987 - val_loss: 0.3194 - val_lwlrap: 0.8475
Epoch 39/60
60/60 - 11s - loss: 8.1948e-04 - lwlrap: 0.9970 - val_loss: 0.2356 - val_lwlrap: 0.8610
Epoch 40/60
60/60 - 10s - loss: 0.0013 - lwlrap: 0.9995 - val_loss: 0.2390 - val_lwlrap: 0.8559

-------------   Fold 2 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold1.h5

 -> Training Model 

Epoch 1/60
60/60 - 12s - loss: 0.2375 - lwlrap: 0.5979 - val_loss: 0.1085 - val_lwlrap: 0.7420
Epoch 2/60
60/60 - 11s - loss: 0.0735 - lwlrap: 0.8678 - val_loss: 0.0934 - val_lwlrap: 0.7851
Epoch 3/60
60/60 - 11s - loss: 0.1157 - lwlrap: 0.8607 - val_loss: 0.1041 - val_lwlrap: 0.7618
Epoch 4/60
60/60 - 11s - loss: 0.0924 - lwlrap: 0.8689 - val_loss: 0.0904 - val_lwlrap: 0.7083
Epoch 5/60
60/60 - 11s - loss: 0.0375 - lwlrap: 0.8843 - val_loss: 0.0620 - val_lwlrap: 0.8072
Epoch 6/60
60/60 - 11s - loss: 0.0602 - lwlrap: 0.8886 - val_loss: 0.0578 - val_lwlrap: 0.8418
Epoch 7/60
60/60 - 11s - loss: 0.0327 - lwlrap: 0.9288 - val_loss: 0.0364 - val_lwlrap: 0.8716
Epoch 8/60
60/60 - 11s - loss: 0.0289 - lwlrap: 0.9537 - val_loss: 0.0544 - val_lwlrap: 0.8550
Epoch 9/60
60/60 - 11s - loss: 0.0180 - lwlrap: 0.9722 - val_loss: 0.0771 - val_lwlrap: 0.8781
Epoch 10/60
60/60 - 11s - loss: 0.0135 - lwlrap: 0.9840 - val_loss: 0.0526 - val_lwlrap: 0.9145
Epoch 11/60
60/60 - 11s - loss: 0.0146 - lwlrap: 0.9885 - val_loss: 0.0328 - val_lwlrap: 0.9041
Epoch 12/60
60/60 - 11s - loss: 0.0072 - lwlrap: 0.9900 - val_loss: 0.0388 - val_lwlrap: 0.9010
Epoch 13/60
60/60 - 11s - loss: 0.0259 - lwlrap: 0.9919 - val_loss: 0.0311 - val_lwlrap: 0.8903
Epoch 14/60
60/60 - 11s - loss: 0.0285 - lwlrap: 0.9835 - val_loss: 0.0343 - val_lwlrap: 0.8879
Epoch 15/60
60/60 - 11s - loss: 0.0728 - lwlrap: 0.9795 - val_loss: 0.0194 - val_lwlrap: 0.8076
Epoch 16/60
60/60 - 11s - loss: 0.0503 - lwlrap: 0.9799 - val_loss: 0.0360 - val_lwlrap: 0.8850
Epoch 17/60
60/60 - 11s - loss: 0.0094 - lwlrap: 0.9817 - val_loss: 0.0194 - val_lwlrap: 0.8898
Epoch 18/60
60/60 - 11s - loss: 0.0033 - lwlrap: 0.9927 - val_loss: 0.0479 - val_lwlrap: 0.8984
Epoch 19/60
60/60 - 11s - loss: 0.0035 - lwlrap: 0.9933 - val_loss: 0.0365 - val_lwlrap: 0.8950
Epoch 20/60
60/60 - 11s - loss: 0.0031 - lwlrap: 0.9955 - val_loss: 0.0348 - val_lwlrap: 0.9085
Epoch 21/60
60/60 - 11s - loss: 0.0105 - lwlrap: 0.9965 - val_loss: 0.0152 - val_lwlrap: 0.8982
Epoch 22/60
60/60 - 11s - loss: 6.2058e-04 - lwlrap: 0.9984 - val_loss: 0.0249 - val_lwlrap: 0.9077
Epoch 23/60
60/60 - 11s - loss: 0.0094 - lwlrap: 0.9974 - val_loss: 0.0162 - val_lwlrap: 0.8880
Epoch 24/60
60/60 - 11s - loss: 0.0047 - lwlrap: 0.9967 - val_loss: 0.0369 - val_lwlrap: 0.8959
Epoch 25/60
60/60 - 11s - loss: 0.0459 - lwlrap: 0.9962 - val_loss: 0.0439 - val_lwlrap: 0.9018
Epoch 26/60
60/60 - 11s - loss: 0.0023 - lwlrap: 0.9954 - val_loss: 0.0389 - val_lwlrap: 0.8804
Epoch 27/60
60/60 - 11s - loss: 0.0011 - lwlrap: 0.9974 - val_loss: 0.0245 - val_lwlrap: 0.8739
Epoch 28/60
60/60 - 11s - loss: 7.1580e-04 - lwlrap: 0.9990 - val_loss: 0.0263 - val_lwlrap: 0.8873
Epoch 29/60
60/60 - 11s - loss: 0.0019 - lwlrap: 0.9973 - val_loss: 0.0632 - val_lwlrap: 0.8781
Epoch 30/60
60/60 - 11s - loss: 0.0016 - lwlrap: 0.9988 - val_loss: 0.0450 - val_lwlrap: 0.8925

-------------   Fold 3 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold2.h5

 -> Training Model 

Epoch 1/60
60/60 - 12s - loss: 0.1446 - lwlrap: 0.5873 - val_loss: 0.1205 - val_lwlrap: 0.6998
Epoch 2/60
60/60 - 11s - loss: 0.1178 - lwlrap: 0.8091 - val_loss: 0.1102 - val_lwlrap: 0.6966
Epoch 3/60
60/60 - 11s - loss: 0.1595 - lwlrap: 0.7850 - val_loss: 0.0676 - val_lwlrap: 0.7212
Epoch 4/60
60/60 - 11s - loss: 0.0982 - lwlrap: 0.8509 - val_loss: 0.1114 - val_lwlrap: 0.6900
Epoch 5/60
60/60 - 11s - loss: 0.1673 - lwlrap: 0.8363 - val_loss: 0.1192 - val_lwlrap: 0.6911
Epoch 6/60
60/60 - 11s - loss: 0.1289 - lwlrap: 0.8456 - val_loss: 0.0499 - val_lwlrap: 0.7922
Epoch 7/60
60/60 - 11s - loss: 0.0909 - lwlrap: 0.9140 - val_loss: 0.0726 - val_lwlrap: 0.8062
Epoch 8/60
60/60 - 11s - loss: 0.0253 - lwlrap: 0.9334 - val_loss: 0.0338 - val_lwlrap: 0.8240
Epoch 9/60
60/60 - 11s - loss: 0.0359 - lwlrap: 0.9553 - val_loss: 0.0383 - val_lwlrap: 0.8689
Epoch 10/60
60/60 - 11s - loss: 0.0098 - lwlrap: 0.9725 - val_loss: 0.0384 - val_lwlrap: 0.8528
Epoch 11/60
60/60 - 11s - loss: 0.0625 - lwlrap: 0.9860 - val_loss: 0.0431 - val_lwlrap: 0.8638
Epoch 12/60
60/60 - 11s - loss: 0.0306 - lwlrap: 0.9860 - val_loss: 0.0512 - val_lwlrap: 0.8646
Epoch 13/60
60/60 - 11s - loss: 0.0482 - lwlrap: 0.9756 - val_loss: 0.0510 - val_lwlrap: 0.8438
Epoch 14/60
60/60 - 11s - loss: 0.0187 - lwlrap: 0.9720 - val_loss: 0.0187 - val_lwlrap: 0.8633
Epoch 15/60
60/60 - 11s - loss: 0.0982 - lwlrap: 0.9714 - val_loss: 0.0213 - val_lwlrap: 0.8440
Epoch 16/60
60/60 - 11s - loss: 0.0350 - lwlrap: 0.9610 - val_loss: 0.0724 - val_lwlrap: 0.8291
Epoch 17/60
60/60 - 11s - loss: 0.0105 - lwlrap: 0.9790 - val_loss: 0.0199 - val_lwlrap: 0.8464
Epoch 18/60
60/60 - 11s - loss: 0.0212 - lwlrap: 0.9850 - val_loss: 0.0379 - val_lwlrap: 0.8378
Epoch 19/60
60/60 - 11s - loss: 0.0142 - lwlrap: 0.9874 - val_loss: 0.0282 - val_lwlrap: 0.8518
Epoch 20/60
60/60 - 11s - loss: 0.0054 - lwlrap: 0.9944 - val_loss: 0.0200 - val_lwlrap: 0.8732
Epoch 21/60
60/60 - 11s - loss: 0.0040 - lwlrap: 0.9946 - val_loss: 0.0216 - val_lwlrap: 0.8642
Epoch 22/60
60/60 - 11s - loss: 0.0032 - lwlrap: 0.9957 - val_loss: 0.0373 - val_lwlrap: 0.8596
Epoch 23/60
60/60 - 11s - loss: 0.0125 - lwlrap: 0.9948 - val_loss: 0.0666 - val_lwlrap: 0.8644
Epoch 24/60
60/60 - 11s - loss: 0.0114 - lwlrap: 0.9902 - val_loss: 0.0550 - val_lwlrap: 0.8637
Epoch 25/60
60/60 - 11s - loss: 0.0080 - lwlrap: 0.9941 - val_loss: 0.0786 - val_lwlrap: 0.8465
Epoch 26/60
60/60 - 11s - loss: 0.0020 - lwlrap: 0.9962 - val_loss: 0.0718 - val_lwlrap: 0.8335
Epoch 27/60
60/60 - 11s - loss: 0.0013 - lwlrap: 0.9935 - val_loss: 0.0110 - val_lwlrap: 0.8578
Epoch 28/60
60/60 - 11s - loss: 0.0034 - lwlrap: 0.9972 - val_loss: 0.0476 - val_lwlrap: 0.8524
Epoch 29/60
60/60 - 11s - loss: 0.0095 - lwlrap: 0.9981 - val_loss: 0.0315 - val_lwlrap: 0.8499
Epoch 30/60
60/60 - 11s - loss: 0.0064 - lwlrap: 0.9981 - val_loss: 0.0355 - val_lwlrap: 0.8538
Epoch 31/60
60/60 - 11s - loss: 0.0354 - lwlrap: 0.9968 - val_loss: 0.0529 - val_lwlrap: 0.8504
Epoch 32/60
60/60 - 11s - loss: 0.0297 - lwlrap: 0.9971 - val_loss: 0.0095 - val_lwlrap: 0.8648
Epoch 33/60
60/60 - 11s - loss: 0.0028 - lwlrap: 0.9965 - val_loss: 0.0427 - val_lwlrap: 0.8428
Epoch 34/60
60/60 - 11s - loss: 0.0262 - lwlrap: 0.9983 - val_loss: 0.0613 - val_lwlrap: 0.8360
Epoch 35/60
60/60 - 11s - loss: 0.0016 - lwlrap: 0.9990 - val_loss: 0.0564 - val_lwlrap: 0.8398
Epoch 36/60
60/60 - 11s - loss: 0.0108 - lwlrap: 0.9939 - val_loss: 0.0489 - val_lwlrap: 0.8486
Epoch 37/60
60/60 - 11s - loss: 0.0019 - lwlrap: 0.9977 - val_loss: 0.0723 - val_lwlrap: 0.8645
Epoch 38/60
60/60 - 11s - loss: 0.0040 - lwlrap: 0.9957 - val_loss: 0.0369 - val_lwlrap: 0.8566
Epoch 39/60
60/60 - 11s - loss: 0.0010 - lwlrap: 0.9981 - val_loss: 0.0326 - val_lwlrap: 0.8600
Epoch 40/60
60/60 - 11s - loss: 0.0011 - lwlrap: 0.9985 - val_loss: 0.0066 - val_lwlrap: 0.8647

-------------   Fold 4 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold3.h5

 -> Training Model 

Epoch 1/60
60/60 - 12s - loss: 0.0787 - lwlrap: 0.6248 - val_loss: 0.1872 - val_lwlrap: 0.7098
Epoch 2/60
60/60 - 11s - loss: 0.1328 - lwlrap: 0.8450 - val_loss: 0.1939 - val_lwlrap: 0.7793
Epoch 3/60
60/60 - 11s - loss: 0.1863 - lwlrap: 0.7911 - val_loss: 0.1986 - val_lwlrap: 0.7528
Epoch 4/60
60/60 - 11s - loss: 0.1303 - lwlrap: 0.8596 - val_loss: 0.1925 - val_lwlrap: 0.7473
Epoch 5/60
60/60 - 11s - loss: 0.0962 - lwlrap: 0.8341 - val_loss: 0.0324 - val_lwlrap: 0.7442
Epoch 6/60
60/60 - 11s - loss: 0.0784 - lwlrap: 0.8566 - val_loss: 0.1520 - val_lwlrap: 0.7550
Epoch 7/60
60/60 - 11s - loss: 0.0458 - lwlrap: 0.9147 - val_loss: 0.1528 - val_lwlrap: 0.8569
Epoch 8/60
60/60 - 11s - loss: 0.1101 - lwlrap: 0.9371 - val_loss: 0.2092 - val_lwlrap: 0.8658
Epoch 9/60
60/60 - 11s - loss: 0.0190 - lwlrap: 0.9625 - val_loss: 0.0418 - val_lwlrap: 0.8773
Epoch 10/60
60/60 - 11s - loss: 0.0274 - lwlrap: 0.9787 - val_loss: 0.1109 - val_lwlrap: 0.8868
Epoch 11/60
60/60 - 11s - loss: 0.0176 - lwlrap: 0.9854 - val_loss: 0.0346 - val_lwlrap: 0.8758
Epoch 12/60
60/60 - 11s - loss: 0.0172 - lwlrap: 0.9830 - val_loss: 0.0950 - val_lwlrap: 0.8748
Epoch 13/60
60/60 - 11s - loss: 0.0471 - lwlrap: 0.9804 - val_loss: 0.1157 - val_lwlrap: 0.8394
Epoch 14/60
60/60 - 11s - loss: 0.0118 - lwlrap: 0.9721 - val_loss: 0.3027 - val_lwlrap: 0.8407
Epoch 15/60
60/60 - 11s - loss: 0.1293 - lwlrap: 0.9334 - val_loss: 0.2495 - val_lwlrap: 0.7815
Epoch 16/60
60/60 - 11s - loss: 0.0119 - lwlrap: 0.9618 - val_loss: 0.1469 - val_lwlrap: 0.8573
Epoch 17/60
60/60 - 11s - loss: 0.0258 - lwlrap: 0.9706 - val_loss: 0.1052 - val_lwlrap: 0.8677
Epoch 18/60
60/60 - 11s - loss: 0.0205 - lwlrap: 0.9847 - val_loss: 0.2190 - val_lwlrap: 0.8840
Epoch 19/60
60/60 - 11s - loss: 0.0077 - lwlrap: 0.9909 - val_loss: 0.2089 - val_lwlrap: 0.8754
Epoch 20/60
60/60 - 11s - loss: 0.0035 - lwlrap: 0.9951 - val_loss: 0.2474 - val_lwlrap: 0.8850
Epoch 21/60
60/60 - 11s - loss: 0.0075 - lwlrap: 0.9940 - val_loss: 0.1538 - val_lwlrap: 0.8949
Epoch 22/60
60/60 - 11s - loss: 0.0019 - lwlrap: 0.9975 - val_loss: 0.1381 - val_lwlrap: 0.8916
Epoch 23/60
60/60 - 11s - loss: 0.0030 - lwlrap: 0.9978 - val_loss: 0.2328 - val_lwlrap: 0.8843
Epoch 24/60
60/60 - 11s - loss: 0.0057 - lwlrap: 0.9958 - val_loss: 0.1464 - val_lwlrap: 0.8936
Epoch 25/60
60/60 - 11s - loss: 0.0203 - lwlrap: 0.9955 - val_loss: 0.2484 - val_lwlrap: 0.8695
Epoch 26/60
60/60 - 11s - loss: 0.0048 - lwlrap: 0.9910 - val_loss: 0.2599 - val_lwlrap: 0.8594
Epoch 27/60
60/60 - 11s - loss: 0.0181 - lwlrap: 0.9946 - val_loss: 0.3120 - val_lwlrap: 0.8806
Epoch 28/60
60/60 - 11s - loss: 0.0026 - lwlrap: 0.9965 - val_loss: 0.2926 - val_lwlrap: 0.8862
Epoch 29/60
60/60 - 11s - loss: 0.0061 - lwlrap: 0.9989 - val_loss: 0.3090 - val_lwlrap: 0.8927
Epoch 30/60
60/60 - 11s - loss: 0.0025 - lwlrap: 0.9987 - val_loss: 0.3139 - val_lwlrap: 0.8777
Epoch 31/60
60/60 - 11s - loss: 0.0250 - lwlrap: 0.9972 - val_loss: 0.2434 - val_lwlrap: 0.8972
Epoch 32/60
60/60 - 11s - loss: 0.0019 - lwlrap: 0.9967 - val_loss: 0.2113 - val_lwlrap: 0.8896
Epoch 33/60
60/60 - 11s - loss: 0.0011 - lwlrap: 0.9984 - val_loss: 0.2433 - val_lwlrap: 0.8898
Epoch 34/60
60/60 - 11s - loss: 0.0010 - lwlrap: 0.9962 - val_loss: 0.1521 - val_lwlrap: 0.8635
Epoch 35/60
60/60 - 11s - loss: 0.0017 - lwlrap: 0.9972 - val_loss: 0.3076 - val_lwlrap: 0.8711
Epoch 36/60
60/60 - 11s - loss: 0.0149 - lwlrap: 0.9979 - val_loss: 0.3260 - val_lwlrap: 0.8794
Epoch 37/60
60/60 - 11s - loss: 0.0041 - lwlrap: 0.9980 - val_loss: 0.3966 - val_lwlrap: 0.8774
Epoch 38/60
60/60 - 11s - loss: 0.0098 - lwlrap: 0.9980 - val_loss: 0.2716 - val_lwlrap: 0.8770
Epoch 39/60
60/60 - 11s - loss: 0.0040 - lwlrap: 0.9988 - val_loss: 0.2911 - val_lwlrap: 0.8660
Epoch 40/60
60/60 - 11s - loss: 0.0036 - lwlrap: 0.9982 - val_loss: 0.2775 - val_lwlrap: 0.8823
Epoch 41/60
60/60 - 11s - loss: 0.0019 - lwlrap: 0.9988 - val_loss: 0.3518 - val_lwlrap: 0.8640
Epoch 42/60
60/60 - 11s - loss: 0.0012 - lwlrap: 0.9982 - val_loss: 0.3115 - val_lwlrap: 0.8842
Epoch 43/60
60/60 - 11s - loss: 0.0012 - lwlrap: 0.9990 - val_loss: 0.2260 - val_lwlrap: 0.8730
Epoch 44/60
60/60 - 11s - loss: 5.5590e-04 - lwlrap: 0.9986 - val_loss: 0.2234 - val_lwlrap: 0.8890
Epoch 45/60
60/60 - 11s - loss: 0.0098 - lwlrap: 0.9974 - val_loss: 0.3349 - val_lwlrap: 0.8722
Epoch 46/60
60/60 - 11s - loss: 0.0016 - lwlrap: 0.9990 - val_loss: 0.3581 - val_lwlrap: 0.8742
Epoch 47/60
60/60 - 11s - loss: 0.0024 - lwlrap: 0.9988 - val_loss: 0.2718 - val_lwlrap: 0.8835
Epoch 48/60
60/60 - 11s - loss: 0.0021 - lwlrap: 0.9991 - val_loss: 0.2265 - val_lwlrap: 0.8832
Epoch 49/60
60/60 - 11s - loss: 0.0180 - lwlrap: 0.9982 - val_loss: 0.2692 - val_lwlrap: 0.8878
Epoch 50/60
60/60 - 11s - loss: 0.0020 - lwlrap: 0.9994 - val_loss: 0.1766 - val_lwlrap: 0.8854
Epoch 51/60
60/60 - 11s - loss: 0.0116 - lwlrap: 0.9980 - val_loss: 0.2543 - val_lwlrap: 0.8777

-------------   Fold 5 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold4.h5

 -> Training Model 

Epoch 1/60
61/61 - 12s - loss: 0.1284 - lwlrap: 0.4572 - val_loss: 0.1082 - val_lwlrap: 0.6591
Epoch 2/60
61/61 - 11s - loss: 0.1561 - lwlrap: 0.7830 - val_loss: 0.1186 - val_lwlrap: 0.7204
Epoch 3/60
61/61 - 11s - loss: 0.0699 - lwlrap: 0.8233 - val_loss: 0.1154 - val_lwlrap: 0.7207
Epoch 4/60
61/61 - 11s - loss: 0.1515 - lwlrap: 0.8385 - val_loss: 0.1400 - val_lwlrap: 0.5036
Epoch 5/60
61/61 - 11s - loss: 0.1144 - lwlrap: 0.8804 - val_loss: 0.0852 - val_lwlrap: 0.6478
Epoch 6/60
61/61 - 11s - loss: 0.0577 - lwlrap: 0.8885 - val_loss: 0.1254 - val_lwlrap: 0.7329
Epoch 7/60
61/61 - 11s - loss: 0.0429 - lwlrap: 0.9171 - val_loss: 0.1054 - val_lwlrap: 0.7640
Epoch 8/60
61/61 - 11s - loss: 0.0240 - lwlrap: 0.9578 - val_loss: 0.0918 - val_lwlrap: 0.8226
Epoch 9/60
61/61 - 11s - loss: 0.0087 - lwlrap: 0.9721 - val_loss: 0.0690 - val_lwlrap: 0.8733
Epoch 10/60
61/61 - 11s - loss: 0.0133 - lwlrap: 0.9829 - val_loss: 0.0735 - val_lwlrap: 0.8840
Epoch 11/60
61/61 - 11s - loss: 0.0092 - lwlrap: 0.9889 - val_loss: 0.0589 - val_lwlrap: 0.8780
Epoch 12/60
61/61 - 11s - loss: 0.0184 - lwlrap: 0.9849 - val_loss: 0.0570 - val_lwlrap: 0.8513
Epoch 13/60
61/61 - 11s - loss: 0.0061 - lwlrap: 0.9857 - val_loss: 0.0792 - val_lwlrap: 0.8490
Epoch 14/60
61/61 - 11s - loss: 0.0070 - lwlrap: 0.9877 - val_loss: 0.0752 - val_lwlrap: 0.8233
Epoch 15/60
61/61 - 11s - loss: 0.0051 - lwlrap: 0.9803 - val_loss: 0.0964 - val_lwlrap: 0.8182
Epoch 16/60
61/61 - 11s - loss: 0.0076 - lwlrap: 0.9806 - val_loss: 0.0758 - val_lwlrap: 0.8433
Epoch 17/60
61/61 - 11s - loss: 0.0309 - lwlrap: 0.9865 - val_loss: 0.0608 - val_lwlrap: 0.8757
Epoch 18/60
61/61 - 11s - loss: 0.0096 - lwlrap: 0.9924 - val_loss: 0.0727 - val_lwlrap: 0.8727
Epoch 19/60
61/61 - 11s - loss: 0.0035 - lwlrap: 0.9936 - val_loss: 0.0646 - val_lwlrap: 0.8592
Epoch 20/60
61/61 - 11s - loss: 0.0019 - lwlrap: 0.9919 - val_loss: 0.0721 - val_lwlrap: 0.8716
Epoch 21/60
61/61 - 11s - loss: 0.0034 - lwlrap: 0.9957 - val_loss: 0.0767 - val_lwlrap: 0.8695
Epoch 22/60
61/61 - 11s - loss: 0.0126 - lwlrap: 0.9974 - val_loss: 0.0487 - val_lwlrap: 0.8712
Epoch 23/60
61/61 - 11s - loss: 6.9841e-04 - lwlrap: 0.9946 - val_loss: 0.0775 - val_lwlrap: 0.8616
Epoch 24/60
61/61 - 11s - loss: 9.9640e-04 - lwlrap: 0.9978 - val_loss: 0.0830 - val_lwlrap: 0.8452
Epoch 25/60
61/61 - 11s - loss: 0.0038 - lwlrap: 0.9937 - val_loss: 0.0758 - val_lwlrap: 0.8579
Epoch 26/60
61/61 - 11s - loss: 0.0039 - lwlrap: 0.9981 - val_loss: 0.0740 - val_lwlrap: 0.8660
Epoch 27/60
61/61 - 11s - loss: 0.0055 - lwlrap: 0.9975 - val_loss: 0.1024 - val_lwlrap: 0.8565
Epoch 28/60
61/61 - 11s - loss: 0.0011 - lwlrap: 0.9971 - val_loss: 0.0803 - val_lwlrap: 0.8713
Epoch 29/60
61/61 - 11s - loss: 0.0085 - lwlrap: 0.9970 - val_loss: 0.0912 - val_lwlrap: 0.8637
Epoch 30/60
61/61 - 11s - loss: 0.0017 - lwlrap: 0.9992 - val_loss: 0.0828 - val_lwlrap: 0.8625
Traceback (most recent call last):

