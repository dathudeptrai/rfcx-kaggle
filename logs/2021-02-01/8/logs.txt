
-------------   Fold 1 / 5  -------------

 -> Using 3918 pseudo labels 

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/60
30/30 - 10s - loss: 0.2008 - lwlrap: 0.1302 - val_loss: 0.1522 - val_lwlrap: 0.5945
Epoch 2/60
30/30 - 9s - loss: 0.1057 - lwlrap: 0.2156 - val_loss: 0.1429 - val_lwlrap: 0.7699
Epoch 3/60
30/30 - 8s - loss: 0.1107 - lwlrap: 0.1783 - val_loss: 0.1409 - val_lwlrap: 0.7371
Epoch 4/60
30/30 - 8s - loss: 0.1104 - lwlrap: 0.1968 - val_loss: 0.1416 - val_lwlrap: 0.7567
Epoch 5/60
30/30 - 8s - loss: 0.1297 - lwlrap: 0.1767 - val_loss: 0.1402 - val_lwlrap: 0.7705
Epoch 6/60
30/30 - 8s - loss: 0.1618 - lwlrap: 0.1795 - val_loss: 0.1429 - val_lwlrap: 0.7765
Epoch 7/60
30/30 - 8s - loss: 0.1725 - lwlrap: 0.2183 - val_loss: 0.1307 - val_lwlrap: 0.7941
Epoch 8/60
30/30 - 8s - loss: 0.0743 - lwlrap: 0.1628 - val_loss: 0.1127 - val_lwlrap: 0.7312
Epoch 9/60
30/30 - 8s - loss: 0.1687 - lwlrap: 0.1875 - val_loss: 0.1131 - val_lwlrap: 0.7684
Epoch 10/60
30/30 - 8s - loss: 0.0865 - lwlrap: 0.1821 - val_loss: 0.1711 - val_lwlrap: 0.6468
Epoch 11/60
30/30 - 8s - loss: 0.0720 - lwlrap: 0.1687 - val_loss: 0.1094 - val_lwlrap: 0.7781
Epoch 12/60
30/30 - 8s - loss: 0.0946 - lwlrap: 0.1635 - val_loss: 0.1277 - val_lwlrap: 0.7849
Epoch 13/60
30/30 - 9s - loss: 0.1122 - lwlrap: 0.1809 - val_loss: 0.0955 - val_lwlrap: 0.8269
Epoch 14/60
30/30 - 8s - loss: 0.0908 - lwlrap: 0.2147 - val_loss: 0.1042 - val_lwlrap: 0.8004
Epoch 15/60
30/30 - 8s - loss: 0.0574 - lwlrap: 0.2253 - val_loss: 0.0928 - val_lwlrap: 0.8420
Epoch 16/60
30/30 - 8s - loss: 0.0753 - lwlrap: 0.1885 - val_loss: 0.1057 - val_lwlrap: 0.8081
Epoch 17/60
30/30 - 9s - loss: 0.0529 - lwlrap: 0.1907 - val_loss: 0.1202 - val_lwlrap: 0.8531
Epoch 18/60
30/30 - 9s - loss: 0.0512 - lwlrap: 0.1846 - val_loss: 0.1029 - val_lwlrap: 0.8555
Epoch 19/60
30/30 - 8s - loss: 0.0524 - lwlrap: 0.2053 - val_loss: 0.0978 - val_lwlrap: 0.8628
Epoch 20/60
30/30 - 8s - loss: 0.0579 - lwlrap: 0.1977 - val_loss: 0.0839 - val_lwlrap: 0.8561
Epoch 21/60
30/30 - 8s - loss: 0.0575 - lwlrap: 0.1886 - val_loss: 0.1002 - val_lwlrap: 0.8435
Epoch 22/60
30/30 - 8s - loss: 0.0161 - lwlrap: 0.2164 - val_loss: 0.0915 - val_lwlrap: 0.8645
Epoch 23/60
30/30 - 9s - loss: 0.0212 - lwlrap: 0.1816 - val_loss: 0.0958 - val_lwlrap: 0.8742
Epoch 24/60
30/30 - 8s - loss: 0.0743 - lwlrap: 0.1754 - val_loss: 0.0745 - val_lwlrap: 0.8647
Epoch 25/60
30/30 - 8s - loss: 0.0294 - lwlrap: 0.1789 - val_loss: 0.0905 - val_lwlrap: 0.8537
Epoch 26/60
30/30 - 8s - loss: 0.0641 - lwlrap: 0.1961 - val_loss: 0.0982 - val_lwlrap: 0.8660
Epoch 27/60
30/30 - 8s - loss: 0.0308 - lwlrap: 0.2019 - val_loss: 0.1031 - val_lwlrap: 0.8520
Epoch 28/60
30/30 - 8s - loss: 0.0227 - lwlrap: 0.2471 - val_loss: 0.0911 - val_lwlrap: 0.8495
Epoch 29/60
30/30 - 8s - loss: 0.0146 - lwlrap: 0.2039 - val_loss: 0.0777 - val_lwlrap: 0.8644
Epoch 30/60
30/30 - 8s - loss: 0.0829 - lwlrap: 0.1840 - val_loss: 0.0981 - val_lwlrap: 0.8672
Epoch 31/60
30/30 - 8s - loss: 0.0231 - lwlrap: 0.1712 - val_loss: 0.0887 - val_lwlrap: 0.8443
Epoch 32/60
30/30 - 8s - loss: 0.0397 - lwlrap: 0.1916 - val_loss: 0.1114 - val_lwlrap: 0.8527
Epoch 33/60
30/30 - 8s - loss: 0.0222 - lwlrap: 0.2107 - val_loss: 0.0922 - val_lwlrap: 0.8533
Epoch 34/60
30/30 - 8s - loss: 0.0708 - lwlrap: 0.1836 - val_loss: 0.0976 - val_lwlrap: 0.8530
Epoch 35/60
30/30 - 8s - loss: 0.0307 - lwlrap: 0.1827 - val_loss: 0.0643 - val_lwlrap: 0.8466
Epoch 36/60
30/30 - 8s - loss: 0.0179 - lwlrap: 0.1949 - val_loss: 0.0901 - val_lwlrap: 0.8652
Epoch 37/60
30/30 - 8s - loss: 0.0346 - lwlrap: 0.1898 - val_loss: 0.0805 - val_lwlrap: 0.8666
Epoch 38/60
30/30 - 8s - loss: 0.0124 - lwlrap: 0.1807 - val_loss: 0.0928 - val_lwlrap: 0.8420
Epoch 39/60
30/30 - 8s - loss: 0.0069 - lwlrap: 0.1859 - val_loss: 0.0891 - val_lwlrap: 0.8686
Epoch 40/60
30/30 - 8s - loss: 0.0219 - lwlrap: 0.1980 - val_loss: 0.0804 - val_lwlrap: 0.8710
Epoch 41/60
30/30 - 8s - loss: 0.0521 - lwlrap: 0.1992 - val_loss: 0.0870 - val_lwlrap: 0.8542
Epoch 42/60
30/30 - 8s - loss: 0.0205 - lwlrap: 0.2320 - val_loss: 0.0850 - val_lwlrap: 0.8645
Epoch 43/60
30/30 - 8s - loss: 0.0728 - lwlrap: 0.2148 - val_loss: 0.0949 - val_lwlrap: 0.8605

-------------   Fold 2 / 5  -------------

 -> Using 3999 pseudo labels 

 -> Preparing Data 

