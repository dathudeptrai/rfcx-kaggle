
-------------   Fold 1 / 5  -------------

 -> Using 3918 pseudo labels 

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/60
30/30 - 10s - loss: 0.2008 - lwlrap: 0.1305 - val_loss: 0.1516 - val_lwlrap: 0.6053
Epoch 2/60
30/30 - 9s - loss: 0.1110 - lwlrap: 0.2148 - val_loss: 0.1418 - val_lwlrap: 0.7746
Epoch 3/60
30/30 - 8s - loss: 0.1088 - lwlrap: 0.1783 - val_loss: 0.1320 - val_lwlrap: 0.7556
Epoch 4/60
30/30 - 8s - loss: 0.1031 - lwlrap: 0.1973 - val_loss: 0.1363 - val_lwlrap: 0.6921
Epoch 5/60
30/30 - 8s - loss: 0.1282 - lwlrap: 0.1782 - val_loss: 0.1551 - val_lwlrap: 0.7683
Epoch 6/60
30/30 - 8s - loss: 0.1460 - lwlrap: 0.1789 - val_loss: 0.1280 - val_lwlrap: 0.7869
Epoch 7/60
30/30 - 8s - loss: 0.1971 - lwlrap: 0.2139 - val_loss: 0.1181 - val_lwlrap: 0.7836
Epoch 8/60
30/30 - 8s - loss: 0.0703 - lwlrap: 0.1639 - val_loss: 0.1076 - val_lwlrap: 0.7610
Epoch 9/60
30/30 - 8s - loss: 0.1788 - lwlrap: 0.1881 - val_loss: 0.1651 - val_lwlrap: 0.6969
Epoch 10/60
30/30 - 8s - loss: 0.1054 - lwlrap: 0.1782 - val_loss: 0.1447 - val_lwlrap: 0.5994
Epoch 11/60
30/30 - 8s - loss: 0.0621 - lwlrap: 0.1662 - val_loss: 0.1261 - val_lwlrap: 0.7585
Epoch 12/60
30/30 - 8s - loss: 0.1004 - lwlrap: 0.1639 - val_loss: 0.1193 - val_lwlrap: 0.7633
Epoch 13/60
30/30 - 9s - loss: 0.1043 - lwlrap: 0.1802 - val_loss: 0.0929 - val_lwlrap: 0.8011
Epoch 14/60
30/30 - 8s - loss: 0.0755 - lwlrap: 0.2151 - val_loss: 0.0960 - val_lwlrap: 0.7977
Epoch 15/60
30/30 - 8s - loss: 0.0713 - lwlrap: 0.2239 - val_loss: 0.1046 - val_lwlrap: 0.8446
Epoch 16/60
30/30 - 8s - loss: 0.0739 - lwlrap: 0.1886 - val_loss: 0.0866 - val_lwlrap: 0.8149
Epoch 17/60
30/30 - 8s - loss: 0.0529 - lwlrap: 0.1913 - val_loss: 0.1199 - val_lwlrap: 0.8389
Epoch 18/60
30/30 - 8s - loss: 0.0450 - lwlrap: 0.1846 - val_loss: 0.0901 - val_lwlrap: 0.8410
Epoch 19/60
30/30 - 9s - loss: 0.0504 - lwlrap: 0.2064 - val_loss: 0.0944 - val_lwlrap: 0.8675
Epoch 20/60
30/30 - 8s - loss: 0.0606 - lwlrap: 0.1971 - val_loss: 0.0878 - val_lwlrap: 0.8520
Epoch 21/60
30/30 - 8s - loss: 0.0553 - lwlrap: 0.1888 - val_loss: 0.1011 - val_lwlrap: 0.8335
Epoch 22/60
30/30 - 8s - loss: 0.0175 - lwlrap: 0.2169 - val_loss: 0.0953 - val_lwlrap: 0.8512
Epoch 23/60
30/30 - 8s - loss: 0.0281 - lwlrap: 0.1825 - val_loss: 0.1160 - val_lwlrap: 0.8452
Epoch 24/60
30/30 - 8s - loss: 0.0739 - lwlrap: 0.1750 - val_loss: 0.1013 - val_lwlrap: 0.8404
Epoch 25/60
30/30 - 8s - loss: 0.0290 - lwlrap: 0.1797 - val_loss: 0.0907 - val_lwlrap: 0.8372
Epoch 26/60
30/30 - 8s - loss: 0.0708 - lwlrap: 0.1968 - val_loss: 0.1174 - val_lwlrap: 0.8508
Epoch 27/60
30/30 - 8s - loss: 0.0212 - lwlrap: 0.2015 - val_loss: 0.0940 - val_lwlrap: 0.8371
Epoch 28/60
30/30 - 8s - loss: 0.0219 - lwlrap: 0.2483 - val_loss: 0.0834 - val_lwlrap: 0.8517
Epoch 29/60
30/30 - 8s - loss: 0.0144 - lwlrap: 0.2040 - val_loss: 0.0841 - val_lwlrap: 0.8543
Epoch 30/60
30/30 - 8s - loss: 0.0889 - lwlrap: 0.1833 - val_loss: 0.0926 - val_lwlrap: 0.8614
Epoch 31/60
30/30 - 8s - loss: 0.0194 - lwlrap: 0.1717 - val_loss: 0.0987 - val_lwlrap: 0.8494
Epoch 32/60
30/30 - 8s - loss: 0.0235 - lwlrap: 0.1910 - val_loss: 0.1012 - val_lwlrap: 0.8414
Epoch 33/60
30/30 - 8s - loss: 0.0201 - lwlrap: 0.2116 - val_loss: 0.0905 - val_lwlrap: 0.8589
Epoch 34/60
30/30 - 8s - loss: 0.0734 - lwlrap: 0.1840 - val_loss: 0.0867 - val_lwlrap: 0.8573
Epoch 35/60
30/30 - 8s - loss: 0.0301 - lwlrap: 0.1835 - val_loss: 0.0843 - val_lwlrap: 0.8179
Epoch 36/60
30/30 - 8s - loss: 0.0174 - lwlrap: 0.1947 - val_loss: 0.0981 - val_lwlrap: 0.8444
Epoch 37/60
30/30 - 8s - loss: 0.0343 - lwlrap: 0.1892 - val_loss: 0.0889 - val_lwlrap: 0.8585
Epoch 38/60
30/30 - 8s - loss: 0.0130 - lwlrap: 0.1813 - val_loss: 0.0921 - val_lwlrap: 0.8388
Epoch 39/60
30/30 - 8s - loss: 0.0070 - lwlrap: 0.1857 - val_loss: 0.0924 - val_lwlrap: 0.8600

-------------   Fold 2 / 5  -------------

 -> Using 3999 pseudo labels 

 -> Preparing Data 

