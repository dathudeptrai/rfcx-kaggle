
-------------   Fold 1 / 5  -------------

 -> Using 3918 pseudo labels 

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/60
30/30 - 10s - loss: 0.1164 - lwlrap: 0.1331 - val_loss: 0.1683 - val_lwlrap: 0.6482
Epoch 2/60
30/30 - 9s - loss: 0.1006 - lwlrap: 0.1699 - val_loss: 0.1386 - val_lwlrap: 0.7199
Epoch 3/60
30/30 - 8s - loss: 0.1142 - lwlrap: 0.1688 - val_loss: 0.1491 - val_lwlrap: 0.6963
Epoch 4/60
30/30 - 8s - loss: 0.1236 - lwlrap: 0.1748 - val_loss: 0.1429 - val_lwlrap: 0.7423
Epoch 5/60
30/30 - 8s - loss: 0.0919 - lwlrap: 0.1750 - val_loss: 0.1351 - val_lwlrap: 0.7649
Epoch 6/60
30/30 - 8s - loss: 0.1308 - lwlrap: 0.1755 - val_loss: 0.1433 - val_lwlrap: 0.7031
Epoch 7/60
30/30 - 8s - loss: 0.0853 - lwlrap: 0.1810 - val_loss: 0.1495 - val_lwlrap: 0.6780
Epoch 8/60
30/30 - 8s - loss: 0.1172 - lwlrap: 0.1767 - val_loss: 0.1582 - val_lwlrap: 0.6677
Epoch 9/60
30/30 - 8s - loss: 0.0892 - lwlrap: 0.1779 - val_loss: 0.1368 - val_lwlrap: 0.8032
Epoch 10/60
30/30 - 8s - loss: 0.1145 - lwlrap: 0.1798 - val_loss: 0.1486 - val_lwlrap: 0.7618
Epoch 11/60
30/30 - 8s - loss: 0.0658 - lwlrap: 0.1827 - val_loss: 0.1399 - val_lwlrap: 0.7086
Epoch 12/60
30/30 - 8s - loss: 0.0660 - lwlrap: 0.1811 - val_loss: 0.1229 - val_lwlrap: 0.7811
Epoch 13/60
30/30 - 8s - loss: 0.0468 - lwlrap: 0.1869 - val_loss: 0.0965 - val_lwlrap: 0.8320
Epoch 14/60
30/30 - 8s - loss: 0.0655 - lwlrap: 0.1863 - val_loss: 0.1222 - val_lwlrap: 0.8294
Epoch 15/60
30/30 - 8s - loss: 0.0948 - lwlrap: 0.1864 - val_loss: 0.1027 - val_lwlrap: 0.8299
Epoch 16/60
30/30 - 8s - loss: 0.0440 - lwlrap: 0.1885 - val_loss: 0.0992 - val_lwlrap: 0.8266
Epoch 17/60
30/30 - 8s - loss: 0.0427 - lwlrap: 0.1928 - val_loss: 0.1075 - val_lwlrap: 0.8216
Epoch 18/60
30/30 - 9s - loss: 0.0511 - lwlrap: 0.1896 - val_loss: 0.1028 - val_lwlrap: 0.8334
Epoch 19/60
30/30 - 8s - loss: 0.0364 - lwlrap: 0.1938 - val_loss: 0.1069 - val_lwlrap: 0.8464
Epoch 20/60
30/30 - 8s - loss: 0.0303 - lwlrap: 0.1924 - val_loss: 0.0988 - val_lwlrap: 0.8500
Epoch 21/60
30/30 - 8s - loss: 0.0615 - lwlrap: 0.1898 - val_loss: 0.1097 - val_lwlrap: 0.8398
Epoch 22/60
30/30 - 8s - loss: 0.0341 - lwlrap: 0.1934 - val_loss: 0.0892 - val_lwlrap: 0.8544
Epoch 23/60
30/30 - 8s - loss: 0.0425 - lwlrap: 0.1890 - val_loss: 0.0941 - val_lwlrap: 0.8330
Epoch 24/60
30/30 - 8s - loss: 0.0470 - lwlrap: 0.1902 - val_loss: 0.0902 - val_lwlrap: 0.8525
Epoch 25/60
30/30 - 8s - loss: 0.0380 - lwlrap: 0.1932 - val_loss: 0.0723 - val_lwlrap: 0.8568
Epoch 26/60
30/30 - 8s - loss: 0.0469 - lwlrap: 0.1955 - val_loss: 0.0683 - val_lwlrap: 0.8456
Epoch 27/60
30/30 - 8s - loss: 0.0386 - lwlrap: 0.1911 - val_loss: 0.0779 - val_lwlrap: 0.8323
Epoch 28/60
30/30 - 8s - loss: 0.0478 - lwlrap: 0.1962 - val_loss: 0.1015 - val_lwlrap: 0.8401
Epoch 29/60
30/30 - 8s - loss: 0.0384 - lwlrap: 0.1935 - val_loss: 0.1005 - val_lwlrap: 0.8395
Epoch 30/60
30/30 - 9s - loss: 0.0768 - lwlrap: 0.1919 - val_loss: 0.0966 - val_lwlrap: 0.8568
Epoch 31/60
30/30 - 8s - loss: 0.0466 - lwlrap: 0.1894 - val_loss: 0.1081 - val_lwlrap: 0.8392
Epoch 32/60
30/30 - 8s - loss: 0.0519 - lwlrap: 0.1875 - val_loss: 0.0953 - val_lwlrap: 0.8388
Epoch 33/60
30/30 - 8s - loss: 0.0617 - lwlrap: 0.1896 - val_loss: 0.1329 - val_lwlrap: 0.8422
Epoch 34/60
30/30 - 8s - loss: 0.0435 - lwlrap: 0.1961 - val_loss: 0.0951 - val_lwlrap: 0.8531
Epoch 35/60
30/30 - 8s - loss: 0.0473 - lwlrap: 0.1940 - val_loss: 0.0900 - val_lwlrap: 0.8643
Epoch 36/60
30/30 - 8s - loss: 0.0489 - lwlrap: 0.1973 - val_loss: 0.1078 - val_lwlrap: 0.8460
Epoch 37/60
30/30 - 8s - loss: 0.0423 - lwlrap: 0.1958 - val_loss: 0.0943 - val_lwlrap: 0.8511
Epoch 38/60
30/30 - 8s - loss: 0.0383 - lwlrap: 0.1889 - val_loss: 0.1005 - val_lwlrap: 0.8590
Epoch 39/60
30/30 - 8s - loss: 0.0397 - lwlrap: 0.1939 - val_loss: 0.1037 - val_lwlrap: 0.8518
Epoch 40/60
30/30 - 8s - loss: 0.0435 - lwlrap: 0.1962 - val_loss: 0.1040 - val_lwlrap: 0.8638
Epoch 41/60
30/30 - 8s - loss: 0.0455 - lwlrap: 0.1946 - val_loss: 0.0983 - val_lwlrap: 0.8528
Epoch 42/60
30/30 - 8s - loss: 0.0332 - lwlrap: 0.1989 - val_loss: 0.0855 - val_lwlrap: 0.8481
Epoch 43/60
30/30 - 9s - loss: 0.0387 - lwlrap: 0.1932 - val_loss: 0.1108 - val_lwlrap: 0.8664
Epoch 44/60
30/30 - 8s - loss: 0.0338 - lwlrap: 0.1989 - val_loss: 0.1017 - val_lwlrap: 0.8547
Epoch 45/60
30/30 - 8s - loss: 0.0381 - lwlrap: 0.1927 - val_loss: 0.1119 - val_lwlrap: 0.8497
Epoch 46/60
30/30 - 8s - loss: 0.0454 - lwlrap: 0.1909 - val_loss: 0.0983 - val_lwlrap: 0.8417
Epoch 47/60
30/30 - 8s - loss: 0.0383 - lwlrap: 0.1972 - val_loss: 0.1286 - val_lwlrap: 0.8590
Epoch 48/60
30/30 - 9s - loss: 0.0549 - lwlrap: 0.1942 - val_loss: 0.0834 - val_lwlrap: 0.8699
Epoch 49/60
30/30 - 8s - loss: 0.0403 - lwlrap: 0.1963 - val_loss: 0.0958 - val_lwlrap: 0.8522
Epoch 50/60
30/30 - 8s - loss: 0.0284 - lwlrap: 0.1968 - val_loss: 0.0984 - val_lwlrap: 0.8553
Epoch 51/60
30/30 - 8s - loss: 0.0336 - lwlrap: 0.1964 - val_loss: 0.1095 - val_lwlrap: 0.8516
Epoch 52/60
30/30 - 8s - loss: 0.0391 - lwlrap: 0.2005 - val_loss: 0.1307 - val_lwlrap: 0.8395
Epoch 53/60
30/30 - 8s - loss: 0.0286 - lwlrap: 0.1987 - val_loss: 0.1056 - val_lwlrap: 0.8478
Epoch 54/60
30/30 - 8s - loss: 0.0348 - lwlrap: 0.1922 - val_loss: 0.0962 - val_lwlrap: 0.8588
Epoch 55/60
30/30 - 8s - loss: 0.0303 - lwlrap: 0.1963 - val_loss: 0.1072 - val_lwlrap: 0.8483
Epoch 56/60
30/30 - 8s - loss: 0.0399 - lwlrap: 0.1935 - val_loss: 0.1171 - val_lwlrap: 0.8414
Epoch 57/60
30/30 - 8s - loss: 0.0438 - lwlrap: 0.1965 - val_loss: 0.0975 - val_lwlrap: 0.8611
Epoch 58/60
30/30 - 8s - loss: 0.0312 - lwlrap: 0.1972 - val_loss: 0.1024 - val_lwlrap: 0.8347
Epoch 59/60
30/30 - 8s - loss: 0.0316 - lwlrap: 0.1930 - val_loss: 0.1258 - val_lwlrap: 0.8375
Epoch 60/60
30/30 - 8s - loss: 0.0267 - lwlrap: 0.1922 - val_loss: 0.1136 - val_lwlrap: 0.8338

-------------   Fold 2 / 5  -------------

 -> Using 3999 pseudo labels 

 -> Preparing Data 

