
-------------   Fold 1 / 5  -------------

 -> Using 2727 pseudo labels 

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/85
30/30 - 9s - loss: 0.1099 - lwlrap: 0.1408 - val_loss: 0.1718 - val_lwlrap: 0.5389
Epoch 2/85
30/30 - 7s - loss: 0.1188 - lwlrap: 0.2009 - val_loss: 0.1873 - val_lwlrap: 0.4044
Epoch 3/85
30/30 - 7s - loss: 0.1119 - lwlrap: 0.1936 - val_loss: 0.1573 - val_lwlrap: 0.5826
Epoch 4/85
30/30 - 7s - loss: 0.1300 - lwlrap: 0.1969 - val_loss: 0.1435 - val_lwlrap: 0.5157
Epoch 5/85
30/30 - 7s - loss: 0.1638 - lwlrap: 0.1805 - val_loss: 0.1631 - val_lwlrap: 0.5785
Epoch 6/85
30/30 - 7s - loss: 0.1762 - lwlrap: 0.1999 - val_loss: 0.1375 - val_lwlrap: 0.5767
Epoch 7/85
30/30 - 7s - loss: 0.1481 - lwlrap: 0.2002 - val_loss: 0.1892 - val_lwlrap: 0.3577
Epoch 8/85
30/30 - 7s - loss: 0.0850 - lwlrap: 0.1802 - val_loss: 0.1755 - val_lwlrap: 0.5624
Epoch 9/85
30/30 - 7s - loss: 0.1009 - lwlrap: 0.2237 - val_loss: 0.2297 - val_lwlrap: 0.3348
Epoch 10/85
30/30 - 7s - loss: 0.1172 - lwlrap: 0.1915 - val_loss: 0.3078 - val_lwlrap: 0.5423
Epoch 11/85
30/30 - 7s - loss: 0.1050 - lwlrap: 0.2012 - val_loss: 0.1615 - val_lwlrap: 0.5742
Epoch 12/85
30/30 - 7s - loss: 0.0676 - lwlrap: 0.2027 - val_loss: 0.1080 - val_lwlrap: 0.6325
Epoch 13/85
30/30 - 7s - loss: 0.0794 - lwlrap: 0.1963 - val_loss: 0.1631 - val_lwlrap: 0.6331
Epoch 14/85
30/30 - 7s - loss: 0.0510 - lwlrap: 0.1839 - val_loss: 0.1189 - val_lwlrap: 0.7562
Epoch 15/85
30/30 - 7s - loss: 0.0535 - lwlrap: 0.1989 - val_loss: 0.1373 - val_lwlrap: 0.6784
Epoch 16/85
30/30 - 7s - loss: 0.0421 - lwlrap: 0.2298 - val_loss: 0.0905 - val_lwlrap: 0.7957
Epoch 17/85
30/30 - 7s - loss: 0.0656 - lwlrap: 0.2311 - val_loss: 0.1082 - val_lwlrap: 0.8065
Epoch 18/85
30/30 - 7s - loss: 0.0266 - lwlrap: 0.2358 - val_loss: 0.0904 - val_lwlrap: 0.8362
Epoch 19/85
30/30 - 7s - loss: 0.0658 - lwlrap: 0.1988 - val_loss: 0.0890 - val_lwlrap: 0.8471
Epoch 20/85
30/30 - 7s - loss: 0.0646 - lwlrap: 0.2079 - val_loss: 0.0900 - val_lwlrap: 0.8463
Epoch 21/85
30/30 - 7s - loss: 0.0568 - lwlrap: 0.2288 - val_loss: 0.0972 - val_lwlrap: 0.8481
Epoch 22/85
30/30 - 7s - loss: 0.0605 - lwlrap: 0.2166 - val_loss: 0.1150 - val_lwlrap: 0.8501
Epoch 23/85
30/30 - 7s - loss: 0.0424 - lwlrap: 0.2003 - val_loss: 0.0853 - val_lwlrap: 0.8526
Epoch 24/85
30/30 - 7s - loss: 0.0902 - lwlrap: 0.2122 - val_loss: 0.1007 - val_lwlrap: 0.8565
Epoch 25/85
30/30 - 7s - loss: 0.0483 - lwlrap: 0.1948 - val_loss: 0.0841 - val_lwlrap: 0.8513
Epoch 26/85
30/30 - 7s - loss: 0.0492 - lwlrap: 0.2306 - val_loss: 0.0861 - val_lwlrap: 0.8358
Epoch 27/85
30/30 - 7s - loss: 0.0464 - lwlrap: 0.2030 - val_loss: 0.1066 - val_lwlrap: 0.7943
Epoch 28/85
30/30 - 7s - loss: 0.0383 - lwlrap: 0.2028 - val_loss: 0.1217 - val_lwlrap: 0.7916
Epoch 29/85
30/30 - 7s - loss: 0.0411 - lwlrap: 0.1877 - val_loss: 0.1012 - val_lwlrap: 0.7682
Epoch 30/85
30/30 - 7s - loss: 0.0824 - lwlrap: 0.2202 - val_loss: 0.0897 - val_lwlrap: 0.8441
Epoch 31/85
30/30 - 7s - loss: 0.0614 - lwlrap: 0.2091 - val_loss: 0.1419 - val_lwlrap: 0.6890
Epoch 32/85
30/30 - 7s - loss: 0.0265 - lwlrap: 0.2429 - val_loss: 0.0902 - val_lwlrap: 0.8306
Epoch 33/85
30/30 - 7s - loss: 0.0251 - lwlrap: 0.2373 - val_loss: 0.0974 - val_lwlrap: 0.8256
Epoch 34/85
30/30 - 7s - loss: 0.0749 - lwlrap: 0.2067 - val_loss: 0.1182 - val_lwlrap: 0.8297
Epoch 35/85
30/30 - 7s - loss: 0.0282 - lwlrap: 0.2064 - val_loss: 0.1072 - val_lwlrap: 0.8228
Epoch 36/85
30/30 - 7s - loss: 0.0216 - lwlrap: 0.2219 - val_loss: 0.0938 - val_lwlrap: 0.8605
Epoch 37/85
30/30 - 7s - loss: 0.0620 - lwlrap: 0.2176 - val_loss: 0.1016 - val_lwlrap: 0.8373
Epoch 38/85
30/30 - 7s - loss: 0.0495 - lwlrap: 0.2481 - val_loss: 0.0900 - val_lwlrap: 0.8544
Epoch 39/85
30/30 - 7s - loss: 0.0201 - lwlrap: 0.2250 - val_loss: 0.0869 - val_lwlrap: 0.8373
Epoch 40/85
30/30 - 7s - loss: 0.0530 - lwlrap: 0.2001 - val_loss: 0.0926 - val_lwlrap: 0.8723
Epoch 41/85
