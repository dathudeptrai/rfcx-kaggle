
-------------   Fold 1 / 5  -------------

 -> Using 2727 pseudo labels 

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/85
30/30 - 10s - loss: 0.1293 - lwlrap: 0.1359 - val_loss: 0.1638 - val_lwlrap: 0.5780
Epoch 2/85
30/30 - 9s - loss: 0.1305 - lwlrap: 0.1974 - val_loss: 0.1681 - val_lwlrap: 0.6436
Epoch 3/85
30/30 - 8s - loss: 0.0959 - lwlrap: 0.2006 - val_loss: 0.1569 - val_lwlrap: 0.7512
Epoch 4/85
30/30 - 9s - loss: 0.1241 - lwlrap: 0.2047 - val_loss: 0.1141 - val_lwlrap: 0.7759
Epoch 5/85
30/30 - 8s - loss: 0.1386 - lwlrap: 0.1845 - val_loss: 0.1281 - val_lwlrap: 0.7756
Epoch 6/85
30/30 - 8s - loss: 0.1510 - lwlrap: 0.2045 - val_loss: 0.1226 - val_lwlrap: 0.8011
Epoch 7/85
30/30 - 8s - loss: 0.1014 - lwlrap: 0.2147 - val_loss: 0.1229 - val_lwlrap: 0.7949
Epoch 8/85
30/30 - 8s - loss: 0.0777 - lwlrap: 0.1859 - val_loss: 0.1312 - val_lwlrap: 0.7435
Epoch 9/85
30/30 - 8s - loss: 0.1216 - lwlrap: 0.2244 - val_loss: 0.1250 - val_lwlrap: 0.6328
Epoch 10/85
30/30 - 8s - loss: 0.1069 - lwlrap: 0.1996 - val_loss: 0.1310 - val_lwlrap: 0.7858
Epoch 11/85
30/30 - 8s - loss: 0.0873 - lwlrap: 0.2071 - val_loss: 0.1085 - val_lwlrap: 0.7927
Epoch 12/85
30/30 - 8s - loss: 0.0906 - lwlrap: 0.2042 - val_loss: 0.1133 - val_lwlrap: 0.7992
Epoch 13/85
30/30 - 8s - loss: 0.1015 - lwlrap: 0.1948 - val_loss: 0.1118 - val_lwlrap: 0.7330
Epoch 14/85
30/30 - 8s - loss: 0.0526 - lwlrap: 0.1831 - val_loss: 0.1124 - val_lwlrap: 0.7741
Epoch 15/85
30/30 - 9s - loss: 0.0776 - lwlrap: 0.1962 - val_loss: 0.1008 - val_lwlrap: 0.8243
Epoch 16/85
30/30 - 8s - loss: 0.0777 - lwlrap: 0.2227 - val_loss: 0.1211 - val_lwlrap: 0.7488
Epoch 17/85
30/30 - 8s - loss: 0.0855 - lwlrap: 0.2212 - val_loss: 0.1156 - val_lwlrap: 0.7821
Epoch 18/85
30/30 - 8s - loss: 0.0261 - lwlrap: 0.2297 - val_loss: 0.0799 - val_lwlrap: 0.8378
Epoch 19/85
30/30 - 8s - loss: 0.0757 - lwlrap: 0.1957 - val_loss: 0.0908 - val_lwlrap: 0.8280
Epoch 20/85
30/30 - 8s - loss: 0.0692 - lwlrap: 0.2062 - val_loss: 0.0987 - val_lwlrap: 0.8372
Epoch 21/85
30/30 - 8s - loss: 0.0688 - lwlrap: 0.2257 - val_loss: 0.1167 - val_lwlrap: 0.8289
Epoch 22/85
30/30 - 8s - loss: 0.0679 - lwlrap: 0.2153 - val_loss: 0.0995 - val_lwlrap: 0.8261
Epoch 23/85
30/30 - 9s - loss: 0.0474 - lwlrap: 0.1987 - val_loss: 0.0883 - val_lwlrap: 0.8429
Epoch 24/85
30/30 - 8s - loss: 0.0872 - lwlrap: 0.2119 - val_loss: 0.1045 - val_lwlrap: 0.8564
Epoch 25/85
30/30 - 9s - loss: 0.0374 - lwlrap: 0.1951 - val_loss: 0.0989 - val_lwlrap: 0.8580
Epoch 26/85
30/30 - 8s - loss: 0.0415 - lwlrap: 0.2321 - val_loss: 0.1061 - val_lwlrap: 0.8505
Epoch 27/85
30/30 - 8s - loss: 0.0458 - lwlrap: 0.2043 - val_loss: 0.0958 - val_lwlrap: 0.8535
Epoch 28/85
30/30 - 8s - loss: 0.0276 - lwlrap: 0.2055 - val_loss: 0.1168 - val_lwlrap: 0.8538
Epoch 29/85
30/30 - 8s - loss: 0.0246 - lwlrap: 0.1908 - val_loss: 0.1159 - val_lwlrap: 0.8547
Epoch 30/85
30/30 - 9s - loss: 0.0579 - lwlrap: 0.2243 - val_loss: 0.1219 - val_lwlrap: 0.8679
Epoch 31/85
30/30 - 8s - loss: 0.0310 - lwlrap: 0.2158 - val_loss: 0.0956 - val_lwlrap: 0.8503
Epoch 32/85
30/30 - 8s - loss: 0.0166 - lwlrap: 0.2477 - val_loss: 0.0999 - val_lwlrap: 0.8532
Epoch 33/85
30/30 - 8s - loss: 0.0119 - lwlrap: 0.2413 - val_loss: 0.1007 - val_lwlrap: 0.8614
Epoch 34/85
30/30 - 8s - loss: 0.0688 - lwlrap: 0.2101 - val_loss: 0.0935 - val_lwlrap: 0.8556
Epoch 35/85
