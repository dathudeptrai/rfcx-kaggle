
-------------   Fold 1 / 5  -------------

 -> Using 2727 pseudo labels 

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/85
30/30 - 10s - loss: 0.1341 - lwlrap: 0.1419 - val_loss: 0.1636 - val_lwlrap: 0.5130
Epoch 2/85
30/30 - 9s - loss: 0.1235 - lwlrap: 0.1698 - val_loss: 0.1426 - val_lwlrap: 0.6230
Epoch 3/85
30/30 - 9s - loss: 0.0956 - lwlrap: 0.1651 - val_loss: 0.1419 - val_lwlrap: 0.6531
Epoch 4/85
30/30 - 9s - loss: 0.0936 - lwlrap: 0.1660 - val_loss: 0.1233 - val_lwlrap: 0.6773
Epoch 5/85
30/30 - 9s - loss: 0.0699 - lwlrap: 0.1697 - val_loss: 0.1305 - val_lwlrap: 0.7237
Epoch 6/85
30/30 - 9s - loss: 0.1153 - lwlrap: 0.1704 - val_loss: 0.1303 - val_lwlrap: 0.6482
Epoch 7/85
30/30 - 9s - loss: 0.1017 - lwlrap: 0.1793 - val_loss: 0.1261 - val_lwlrap: 0.7219
Epoch 8/85
30/30 - 9s - loss: 0.0971 - lwlrap: 0.1731 - val_loss: 0.1340 - val_lwlrap: 0.7815
Epoch 9/85
30/30 - 9s - loss: 0.0807 - lwlrap: 0.1694 - val_loss: 0.1183 - val_lwlrap: 0.7408
Epoch 10/85
30/30 - 9s - loss: 0.1108 - lwlrap: 0.1894 - val_loss: 0.1535 - val_lwlrap: 0.6110
Epoch 11/85
30/30 - 9s - loss: 0.0763 - lwlrap: 0.1768 - val_loss: 0.0858 - val_lwlrap: 0.7159
Epoch 12/85
30/30 - 9s - loss: 0.0482 - lwlrap: 0.1820 - val_loss: 0.1095 - val_lwlrap: 0.7822
Epoch 13/85
30/30 - 9s - loss: 0.1474 - lwlrap: 0.1972 - val_loss: 0.1087 - val_lwlrap: 0.7625
Epoch 14/85
30/30 - 9s - loss: 0.0729 - lwlrap: 0.1819 - val_loss: 0.1109 - val_lwlrap: 0.8060
Epoch 15/85
30/30 - 9s - loss: 0.0711 - lwlrap: 0.1865 - val_loss: 0.1123 - val_lwlrap: 0.8105
Epoch 16/85
30/30 - 9s - loss: 0.0458 - lwlrap: 0.1913 - val_loss: 0.1157 - val_lwlrap: 0.8516
Epoch 17/85
30/30 - 9s - loss: 0.0459 - lwlrap: 0.1820 - val_loss: 0.1170 - val_lwlrap: 0.8423
Epoch 18/85
30/30 - 9s - loss: 0.0604 - lwlrap: 0.1813 - val_loss: 0.1114 - val_lwlrap: 0.8335
Epoch 19/85
30/30 - 9s - loss: 0.0364 - lwlrap: 0.1886 - val_loss: 0.1032 - val_lwlrap: 0.8450
Epoch 20/85
30/30 - 9s - loss: 0.0216 - lwlrap: 0.1895 - val_loss: 0.1051 - val_lwlrap: 0.8478
Epoch 21/85
30/30 - 9s - loss: 0.0441 - lwlrap: 0.1838 - val_loss: 0.1032 - val_lwlrap: 0.8422
Epoch 22/85
30/30 - 9s - loss: 0.0625 - lwlrap: 0.1917 - val_loss: 0.0878 - val_lwlrap: 0.8483
Epoch 23/85
30/30 - 9s - loss: 0.0568 - lwlrap: 0.1906 - val_loss: 0.1176 - val_lwlrap: 0.8393
Epoch 24/85
30/30 - 9s - loss: 0.0594 - lwlrap: 0.1871 - val_loss: 0.1079 - val_lwlrap: 0.8401
Epoch 25/85
30/30 - 9s - loss: 0.0541 - lwlrap: 0.1927 - val_loss: 0.1133 - val_lwlrap: 0.8575
Epoch 26/85
30/30 - 9s - loss: 0.0877 - lwlrap: 0.1927 - val_loss: 0.1092 - val_lwlrap: 0.8391
Epoch 27/85
30/30 - 9s - loss: 0.0700 - lwlrap: 0.1867 - val_loss: 0.1032 - val_lwlrap: 0.8319
Epoch 28/85
30/30 - 9s - loss: 0.0704 - lwlrap: 0.1838 - val_loss: 0.0759 - val_lwlrap: 0.8491
Epoch 29/85
30/30 - 9s - loss: 0.0418 - lwlrap: 0.1970 - val_loss: 0.1263 - val_lwlrap: 0.8203
Epoch 30/85
30/30 - 9s - loss: 0.0724 - lwlrap: 0.1844 - val_loss: 0.1144 - val_lwlrap: 0.8052
Epoch 31/85
30/30 - 9s - loss: 0.0529 - lwlrap: 0.1887 - val_loss: 0.0844 - val_lwlrap: 0.8410
Epoch 32/85
30/30 - 9s - loss: 0.0601 - lwlrap: 0.1872 - val_loss: 0.0976 - val_lwlrap: 0.8251
Epoch 33/85
30/30 - 9s - loss: 0.0566 - lwlrap: 0.1824 - val_loss: 0.0996 - val_lwlrap: 0.8501
Epoch 34/85
30/30 - 9s - loss: 0.0662 - lwlrap: 0.1870 - val_loss: 0.0759 - val_lwlrap: 0.8443
Epoch 35/85
30/30 - 9s - loss: 0.0481 - lwlrap: 0.1934 - val_loss: 0.0971 - val_lwlrap: 0.8377
Epoch 36/85
30/30 - 9s - loss: 0.0398 - lwlrap: 0.1841 - val_loss: 0.1128 - val_lwlrap: 0.8297
Epoch 37/85
30/30 - 9s - loss: 0.0313 - lwlrap: 0.1836 - val_loss: 0.1223 - val_lwlrap: 0.8368
Epoch 38/85
30/30 - 9s - loss: 0.0652 - lwlrap: 0.1819 - val_loss: 0.0934 - val_lwlrap: 0.8540
Epoch 39/85
30/30 - 9s - loss: 0.0483 - lwlrap: 0.1827 - val_loss: 0.1051 - val_lwlrap: 0.8460
Epoch 40/85
30/30 - 9s - loss: 0.0394 - lwlrap: 0.1847 - val_loss: 0.0847 - val_lwlrap: 0.8567
Epoch 41/85
30/30 - 9s - loss: 0.0488 - lwlrap: 0.1899 - val_loss: 0.0917 - val_lwlrap: 0.8622
Epoch 42/85
30/30 - 9s - loss: 0.0551 - lwlrap: 0.2013 - val_loss: 0.0953 - val_lwlrap: 0.8516
Epoch 43/85
30/30 - 9s - loss: 0.0398 - lwlrap: 0.1934 - val_loss: 0.1031 - val_lwlrap: 0.8441
Epoch 44/85
30/30 - 9s - loss: 0.0508 - lwlrap: 0.2049 - val_loss: 0.0883 - val_lwlrap: 0.8649
Epoch 45/85
30/30 - 9s - loss: 0.0102 - lwlrap: 0.1872 - val_loss: 0.0801 - val_lwlrap: 0.8544
Epoch 46/85
30/30 - 9s - loss: 0.0513 - lwlrap: 0.1872 - val_loss: 0.0837 - val_lwlrap: 0.8585
Epoch 47/85
30/30 - 9s - loss: 0.0617 - lwlrap: 0.1867 - val_loss: 0.0990 - val_lwlrap: 0.8546
Epoch 48/85
30/30 - 9s - loss: 0.0450 - lwlrap: 0.1957 - val_loss: 0.1021 - val_lwlrap: 0.8446
Epoch 49/85
30/30 - 9s - loss: 0.0431 - lwlrap: 0.1783 - val_loss: 0.0884 - val_lwlrap: 0.8593
Epoch 50/85
30/30 - 9s - loss: 0.0477 - lwlrap: 0.1825 - val_loss: 0.1006 - val_lwlrap: 0.8324
Epoch 51/85
30/30 - 9s - loss: 0.0570 - lwlrap: 0.1849 - val_loss: 0.0974 - val_lwlrap: 0.8498
Epoch 52/85
30/30 - 9s - loss: 0.0313 - lwlrap: 0.1884 - val_loss: 0.0887 - val_lwlrap: 0.8412
Epoch 53/85
30/30 - 9s - loss: 0.0472 - lwlrap: 0.1870 - val_loss: 0.0964 - val_lwlrap: 0.8455
Epoch 54/85
30/30 - 9s - loss: 0.0179 - lwlrap: 0.1887 - val_loss: 0.1131 - val_lwlrap: 0.8484
Epoch 55/85
30/30 - 9s - loss: 0.0349 - lwlrap: 0.1789 - val_loss: 0.1057 - val_lwlrap: 0.8537
Epoch 56/85
30/30 - 9s - loss: 0.0621 - lwlrap: 0.1953 - val_loss: 0.1149 - val_lwlrap: 0.8466
Epoch 57/85
30/30 - 9s - loss: 0.0466 - lwlrap: 0.1932 - val_loss: 0.1025 - val_lwlrap: 0.8534
Epoch 58/85
30/30 - 9s - loss: 0.0416 - lwlrap: 0.1855 - val_loss: 0.1169 - val_lwlrap: 0.8489
Epoch 59/85
30/30 - 9s - loss: 0.0448 - lwlrap: 0.1975 - val_loss: 0.1097 - val_lwlrap: 0.8679
Epoch 60/85
30/30 - 9s - loss: 0.0480 - lwlrap: 0.1857 - val_loss: 0.1009 - val_lwlrap: 0.8573
Epoch 61/85
30/30 - 9s - loss: 0.0146 - lwlrap: 0.1882 - val_loss: 0.0915 - val_lwlrap: 0.8582
Epoch 62/85
30/30 - 9s - loss: 0.0445 - lwlrap: 0.1919 - val_loss: 0.0958 - val_lwlrap: 0.8420
Epoch 63/85
30/30 - 9s - loss: 0.0323 - lwlrap: 0.1810 - val_loss: 0.0842 - val_lwlrap: 0.8542
Epoch 64/85
30/30 - 9s - loss: 0.0130 - lwlrap: 0.1944 - val_loss: 0.1135 - val_lwlrap: 0.8594
Epoch 65/85
30/30 - 9s - loss: 0.0398 - lwlrap: 0.1845 - val_loss: 0.0923 - val_lwlrap: 0.8694
Epoch 66/85
30/30 - 9s - loss: 0.0421 - lwlrap: 0.1967 - val_loss: 0.1042 - val_lwlrap: 0.8559
Epoch 67/85
30/30 - 9s - loss: 0.0501 - lwlrap: 0.1865 - val_loss: 0.1008 - val_lwlrap: 0.8629
Epoch 68/85
30/30 - 9s - loss: 0.0584 - lwlrap: 0.1912 - val_loss: 0.0910 - val_lwlrap: 0.8631
Epoch 69/85
30/30 - 9s - loss: 0.0528 - lwlrap: 0.1848 - val_loss: 0.0947 - val_lwlrap: 0.8595
Epoch 70/85
30/30 - 9s - loss: 0.0353 - lwlrap: 0.1871 - val_loss: 0.1014 - val_lwlrap: 0.8460
Epoch 71/85
30/30 - 9s - loss: 0.0149 - lwlrap: 0.1814 - val_loss: 0.0963 - val_lwlrap: 0.8519
Epoch 72/85
30/30 - 9s - loss: 0.0401 - lwlrap: 0.1843 - val_loss: 0.1003 - val_lwlrap: 0.8522
Epoch 73/85
30/30 - 9s - loss: 0.0582 - lwlrap: 0.1920 - val_loss: 0.1064 - val_lwlrap: 0.8479
Epoch 74/85
30/30 - 9s - loss: 0.0495 - lwlrap: 0.1893 - val_loss: 0.1030 - val_lwlrap: 0.8663
Epoch 75/85
30/30 - 9s - loss: 0.0521 - lwlrap: 0.1816 - val_loss: 0.1112 - val_lwlrap: 0.8543
Epoch 76/85
30/30 - 9s - loss: 0.0518 - lwlrap: 0.1829 - val_loss: 0.0910 - val_lwlrap: 0.8488
Epoch 77/85
30/30 - 9s - loss: 0.0475 - lwlrap: 0.1940 - val_loss: 0.0915 - val_lwlrap: 0.8545
Epoch 78/85
30/30 - 9s - loss: 0.0429 - lwlrap: 0.1923 - val_loss: 0.0934 - val_lwlrap: 0.8610
Epoch 79/85
30/30 - 9s - loss: 0.0377 - lwlrap: 0.1906 - val_loss: 0.1019 - val_lwlrap: 0.8504
Epoch 80/85
30/30 - 9s - loss: 0.0593 - lwlrap: 0.1849 - val_loss: 0.0951 - val_lwlrap: 0.8532
Epoch 81/85
30/30 - 9s - loss: 0.0439 - lwlrap: 0.1891 - val_loss: 0.0822 - val_lwlrap: 0.8642
Epoch 82/85
30/30 - 9s - loss: 0.0417 - lwlrap: 0.2066 - val_loss: 0.0991 - val_lwlrap: 0.8598
Epoch 83/85
30/30 - 9s - loss: 0.0412 - lwlrap: 0.1941 - val_loss: 0.0716 - val_lwlrap: 0.8624
Epoch 84/85
30/30 - 9s - loss: 0.0437 - lwlrap: 0.1996 - val_loss: 0.1125 - val_lwlrap: 0.8463
Epoch 85/85
30/30 - 9s - loss: 0.0314 - lwlrap: 0.1834 - val_loss: 0.1058 - val_lwlrap: 0.8490

-------------   Fold 2 / 5  -------------

 -> Using 2921 pseudo labels 

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold1.h5

 -> Training Model 

Epoch 1/85
30/30 - 10s - loss: 0.1107 - lwlrap: 0.1443 - val_loss: 0.1018 - val_lwlrap: 0.6739
Epoch 2/85
30/30 - 9s - loss: 0.0909 - lwlrap: 0.1750 - val_loss: 0.0894 - val_lwlrap: 0.7849
Epoch 3/85
30/30 - 9s - loss: 0.0755 - lwlrap: 0.1921 - val_loss: 0.0760 - val_lwlrap: 0.8271
Epoch 4/85
30/30 - 9s - loss: 0.0708 - lwlrap: 0.1822 - val_loss: 0.0815 - val_lwlrap: 0.8308
Epoch 5/85
30/30 - 9s - loss: 0.0686 - lwlrap: 0.1833 - val_loss: 0.0700 - val_lwlrap: 0.8717
Epoch 6/85
30/30 - 9s - loss: 0.0915 - lwlrap: 0.1832 - val_loss: 0.0804 - val_lwlrap: 0.7964
Epoch 7/85
30/30 - 9s - loss: 0.0844 - lwlrap: 0.1970 - val_loss: 0.0706 - val_lwlrap: 0.8017
Epoch 8/85
30/30 - 8s - loss: 0.0851 - lwlrap: 0.1852 - val_loss: 0.0758 - val_lwlrap: 0.8258
Epoch 9/85
30/30 - 9s - loss: 0.0782 - lwlrap: 0.1854 - val_loss: 0.0635 - val_lwlrap: 0.8303
Epoch 10/85
30/30 - 8s - loss: 0.0719 - lwlrap: 0.1945 - val_loss: 0.0876 - val_lwlrap: 0.8271
Epoch 11/85
30/30 - 9s - loss: 0.0814 - lwlrap: 0.1785 - val_loss: 0.0921 - val_lwlrap: 0.8247
Epoch 12/85
30/30 - 9s - loss: 0.0674 - lwlrap: 0.1868 - val_loss: 0.0494 - val_lwlrap: 0.8908
Epoch 13/85
