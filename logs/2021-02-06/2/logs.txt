
-------------   Fold 1 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-02-04/3/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/100
15/15 - 8s - loss: 0.4203 - lwlrap: 0.2016 - val_loss: 0.2710 - val_lwlrap: 0.2688
Epoch 2/100
15/15 - 6s - loss: 0.5002 - lwlrap: 0.2372 - val_loss: 0.1974 - val_lwlrap: 0.3094
Epoch 3/100
15/15 - 6s - loss: 0.3000 - lwlrap: 0.2971 - val_loss: 0.1508 - val_lwlrap: 0.5237
Epoch 4/100
15/15 - 6s - loss: 0.1480 - lwlrap: 0.4026 - val_loss: 0.1386 - val_lwlrap: 0.7048
Epoch 5/100
15/15 - 6s - loss: 0.0977 - lwlrap: 0.5238 - val_loss: 0.1198 - val_lwlrap: 0.6987
Epoch 6/100
15/15 - 6s - loss: 0.2574 - lwlrap: 0.4679 - val_loss: 0.1101 - val_lwlrap: 0.8283
Epoch 7/100
15/15 - 6s - loss: 0.1233 - lwlrap: 0.5179 - val_loss: 0.1054 - val_lwlrap: 0.8504
Epoch 8/100
15/15 - 6s - loss: 0.2550 - lwlrap: 0.5403 - val_loss: 0.0995 - val_lwlrap: 0.8891
Epoch 9/100
15/15 - 6s - loss: 0.1026 - lwlrap: 0.5879 - val_loss: 0.1070 - val_lwlrap: 0.8492
Epoch 10/100
15/15 - 6s - loss: 0.0989 - lwlrap: 0.6084 - val_loss: 0.0898 - val_lwlrap: 0.8791
Epoch 11/100
15/15 - 6s - loss: 0.3554 - lwlrap: 0.5834 - val_loss: 0.1238 - val_lwlrap: 0.7873
Epoch 12/100
15/15 - 6s - loss: 0.0974 - lwlrap: 0.6408 - val_loss: 0.0926 - val_lwlrap: 0.8953
Epoch 13/100
15/15 - 6s - loss: 0.0682 - lwlrap: 0.7190 - val_loss: 0.0771 - val_lwlrap: 0.8956
Epoch 14/100
15/15 - 6s - loss: 0.1014 - lwlrap: 0.6750 - val_loss: 0.0713 - val_lwlrap: 0.9017
Epoch 15/100
15/15 - 6s - loss: 0.0774 - lwlrap: 0.7189 - val_loss: 0.0740 - val_lwlrap: 0.9116
Epoch 16/100
15/15 - 6s - loss: 0.0953 - lwlrap: 0.6208 - val_loss: 0.0696 - val_lwlrap: 0.9168
Epoch 17/100
15/15 - 6s - loss: 0.0640 - lwlrap: 0.7260 - val_loss: 0.0691 - val_lwlrap: 0.8760
Epoch 18/100
15/15 - 6s - loss: 0.1708 - lwlrap: 0.6538 - val_loss: 0.0719 - val_lwlrap: 0.9068
Epoch 19/100
15/15 - 6s - loss: 0.1571 - lwlrap: 0.8172 - val_loss: 0.0540 - val_lwlrap: 0.9194
Epoch 20/100
15/15 - 6s - loss: 0.0525 - lwlrap: 0.7292 - val_loss: 0.0512 - val_lwlrap: 0.9297
Epoch 21/100
15/15 - 6s - loss: 0.0671 - lwlrap: 0.7061 - val_loss: 0.0581 - val_lwlrap: 0.9233
Epoch 22/100
15/15 - 6s - loss: 0.0816 - lwlrap: 0.7027 - val_loss: 0.0626 - val_lwlrap: 0.9226
Epoch 23/100
15/15 - 6s - loss: 0.0891 - lwlrap: 0.7126 - val_loss: 0.0717 - val_lwlrap: 0.9065
Epoch 24/100
15/15 - 6s - loss: 0.1482 - lwlrap: 0.7496 - val_loss: 0.0664 - val_lwlrap: 0.9032
Epoch 25/100
15/15 - 6s - loss: 0.0874 - lwlrap: 0.7902 - val_loss: 0.0541 - val_lwlrap: 0.9206
Epoch 26/100
15/15 - 6s - loss: 0.2933 - lwlrap: 0.7558 - val_loss: 0.0606 - val_lwlrap: 0.9249
Epoch 27/100
15/15 - 6s - loss: 0.1569 - lwlrap: 0.7383 - val_loss: 0.0595 - val_lwlrap: 0.9223
Epoch 28/100
15/15 - 6s - loss: 0.1277 - lwlrap: 0.8460 - val_loss: 0.0589 - val_lwlrap: 0.9254
Epoch 29/100
15/15 - 6s - loss: 0.2811 - lwlrap: 0.7265 - val_loss: 0.0648 - val_lwlrap: 0.9213
Epoch 30/100
15/15 - 6s - loss: 0.1088 - lwlrap: 0.7544 - val_loss: 0.0725 - val_lwlrap: 0.9237
Epoch 31/100
15/15 - 6s - loss: 0.1176 - lwlrap: 0.7687 - val_loss: 0.0675 - val_lwlrap: 0.9128
Epoch 32/100
15/15 - 6s - loss: 0.2922 - lwlrap: 0.7354 - val_loss: 0.0759 - val_lwlrap: 0.9196
Epoch 33/100
15/15 - 6s - loss: 0.1195 - lwlrap: 0.7750 - val_loss: 0.0749 - val_lwlrap: 0.9191
Epoch 34/100
15/15 - 6s - loss: 0.1270 - lwlrap: 0.8554 - val_loss: 0.0671 - val_lwlrap: 0.9202
Epoch 35/100
15/15 - 6s - loss: 0.2891 - lwlrap: 0.7861 - val_loss: 0.0669 - val_lwlrap: 0.9206
Epoch 36/100
15/15 - 6s - loss: 0.1527 - lwlrap: 0.7924 - val_loss: 0.0651 - val_lwlrap: 0.9260
Epoch 37/100
15/15 - 6s - loss: 0.1565 - lwlrap: 0.7454 - val_loss: 0.0649 - val_lwlrap: 0.9245
Epoch 38/100
15/15 - 6s - loss: 0.1398 - lwlrap: 0.8243 - val_loss: 0.0721 - val_lwlrap: 0.9133
Epoch 39/100
15/15 - 6s - loss: 0.1214 - lwlrap: 0.8107 - val_loss: 0.0645 - val_lwlrap: 0.9199
Epoch 40/100
15/15 - 6s - loss: 0.1490 - lwlrap: 0.8473 - val_loss: 0.0656 - val_lwlrap: 0.9233
Epoch 41/100
15/15 - 6s - loss: 0.2573 - lwlrap: 0.7875 - val_loss: 0.0691 - val_lwlrap: 0.9276
Epoch 42/100
15/15 - 6s - loss: 0.1194 - lwlrap: 0.7921 - val_loss: 0.0706 - val_lwlrap: 0.9206
Epoch 43/100
15/15 - 6s - loss: 0.1393 - lwlrap: 0.7726 - val_loss: 0.0758 - val_lwlrap: 0.9205
Epoch 44/100
15/15 - 6s - loss: 0.1810 - lwlrap: 0.8272 - val_loss: 0.0831 - val_lwlrap: 0.9239
Epoch 45/100
15/15 - 6s - loss: 0.1718 - lwlrap: 0.7565 - val_loss: 0.0928 - val_lwlrap: 0.9108
Epoch 46/100
15/15 - 6s - loss: 0.1537 - lwlrap: 0.8457 - val_loss: 0.0847 - val_lwlrap: 0.9172
Epoch 47/100
15/15 - 6s - loss: 0.1795 - lwlrap: 0.8997 - val_loss: 0.0790 - val_lwlrap: 0.9152
Epoch 48/100
15/15 - 6s - loss: 0.1819 - lwlrap: 0.7612 - val_loss: 0.0776 - val_lwlrap: 0.9181
Epoch 49/100
15/15 - 6s - loss: 0.2897 - lwlrap: 0.7944 - val_loss: 0.0801 - val_lwlrap: 0.9065
Epoch 50/100
15/15 - 6s - loss: 0.1302 - lwlrap: 0.7871 - val_loss: 0.0833 - val_lwlrap: 0.9132

-------------   Fold 2 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-02-04/3/pretrained_best_fold1.h5

 -> Training Model 

Epoch 1/100
Traceback (most recent call last):

