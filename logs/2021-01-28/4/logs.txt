
-------------   Fold 1 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Training Model 

Epoch 1/100
15/15 - 7s - loss: 0.3636 - lwlrap: 0.2206 - val_loss: 0.3024 - val_lwlrap: 0.3007
Epoch 2/100
15/15 - 5s - loss: 0.1949 - lwlrap: 0.2394 - val_loss: 0.1958 - val_lwlrap: 0.3222
Epoch 3/100
15/15 - 5s - loss: 0.1735 - lwlrap: 0.3500 - val_loss: 0.2068 - val_lwlrap: 0.3852
Epoch 4/100
15/15 - 5s - loss: 0.2526 - lwlrap: 0.4571 - val_loss: 0.1261 - val_lwlrap: 0.6698
Epoch 5/100
15/15 - 5s - loss: 0.1229 - lwlrap: 0.5890 - val_loss: 0.1543 - val_lwlrap: 0.6184
Epoch 6/100
15/15 - 5s - loss: 0.2357 - lwlrap: 0.6110 - val_loss: 0.1114 - val_lwlrap: 0.8033
Epoch 7/100
15/15 - 5s - loss: 0.2333 - lwlrap: 0.6960 - val_loss: 0.1132 - val_lwlrap: 0.7926
Epoch 8/100
15/15 - 5s - loss: 0.1876 - lwlrap: 0.6808 - val_loss: 0.1025 - val_lwlrap: 0.8088
Epoch 9/100
15/15 - 5s - loss: 0.0909 - lwlrap: 0.7085 - val_loss: 0.1156 - val_lwlrap: 0.7857
Epoch 10/100
15/15 - 5s - loss: 0.1930 - lwlrap: 0.7384 - val_loss: 0.0966 - val_lwlrap: 0.8076
Epoch 11/100
15/15 - 5s - loss: 0.0838 - lwlrap: 0.7773 - val_loss: 0.1256 - val_lwlrap: 0.6337
Epoch 12/100
15/15 - 5s - loss: 0.1718 - lwlrap: 0.7914 - val_loss: 0.0932 - val_lwlrap: 0.8348
Epoch 13/100
15/15 - 5s - loss: 0.2356 - lwlrap: 0.8011 - val_loss: 0.0930 - val_lwlrap: 0.8188
Epoch 14/100
15/15 - 5s - loss: 0.1875 - lwlrap: 0.8444 - val_loss: 0.0845 - val_lwlrap: 0.8292
Epoch 15/100
15/15 - 5s - loss: 0.1632 - lwlrap: 0.8161 - val_loss: 0.0852 - val_lwlrap: 0.8027
Epoch 16/100
15/15 - 5s - loss: 0.0614 - lwlrap: 0.8438 - val_loss: 0.0784 - val_lwlrap: 0.8349
Epoch 17/100
15/15 - 5s - loss: 0.1560 - lwlrap: 0.8450 - val_loss: 0.0783 - val_lwlrap: 0.8351
Epoch 18/100
15/15 - 5s - loss: 0.1244 - lwlrap: 0.8408 - val_loss: 0.0761 - val_lwlrap: 0.8008
Epoch 19/100
15/15 - 5s - loss: 0.0463 - lwlrap: 0.8742 - val_loss: 0.0822 - val_lwlrap: 0.8019
Epoch 20/100
15/15 - 5s - loss: 0.0510 - lwlrap: 0.8885 - val_loss: 0.0797 - val_lwlrap: 0.8119
Epoch 21/100
15/15 - 5s - loss: 0.1197 - lwlrap: 0.8635 - val_loss: 0.0793 - val_lwlrap: 0.8240
Epoch 22/100
15/15 - 5s - loss: 0.0450 - lwlrap: 0.9226 - val_loss: 0.0805 - val_lwlrap: 0.8180
Epoch 23/100
15/15 - 5s - loss: 0.0474 - lwlrap: 0.8941 - val_loss: 0.0925 - val_lwlrap: 0.7876
Epoch 24/100
15/15 - 5s - loss: 0.0543 - lwlrap: 0.8577 - val_loss: 0.0737 - val_lwlrap: 0.8123
Epoch 25/100
15/15 - 5s - loss: 0.0422 - lwlrap: 0.8750 - val_loss: 0.0854 - val_lwlrap: 0.8286
Epoch 26/100
15/15 - 5s - loss: 0.0530 - lwlrap: 0.9013 - val_loss: 0.0788 - val_lwlrap: 0.8265
Epoch 27/100
15/15 - 5s - loss: 0.1227 - lwlrap: 0.8703 - val_loss: 0.0784 - val_lwlrap: 0.8153
Epoch 28/100
15/15 - 5s - loss: 0.0978 - lwlrap: 0.9009 - val_loss: 0.0902 - val_lwlrap: 0.8219
Epoch 29/100
15/15 - 5s - loss: 0.0394 - lwlrap: 0.9286 - val_loss: 0.0867 - val_lwlrap: 0.7905
Epoch 30/100
15/15 - 5s - loss: 0.1086 - lwlrap: 0.8960 - val_loss: 0.0887 - val_lwlrap: 0.8137
Epoch 31/100
15/15 - 5s - loss: 0.1051 - lwlrap: 0.9195 - val_loss: 0.0834 - val_lwlrap: 0.8209
Epoch 32/100
15/15 - 5s - loss: 0.0887 - lwlrap: 0.9176 - val_loss: 0.0844 - val_lwlrap: 0.8007
Epoch 33/100
15/15 - 5s - loss: 0.1057 - lwlrap: 0.9303 - val_loss: 0.0836 - val_lwlrap: 0.8403
Epoch 34/100
15/15 - 5s - loss: 0.0906 - lwlrap: 0.9349 - val_loss: 0.0824 - val_lwlrap: 0.8218
Epoch 35/100
15/15 - 5s - loss: 0.1015 - lwlrap: 0.9338 - val_loss: 0.0731 - val_lwlrap: 0.8352
Epoch 36/100
15/15 - 5s - loss: 0.0314 - lwlrap: 0.9379 - val_loss: 0.0795 - val_lwlrap: 0.8289
Epoch 37/100
15/15 - 5s - loss: 0.1063 - lwlrap: 0.9422 - val_loss: 0.0884 - val_lwlrap: 0.8217
Epoch 38/100
15/15 - 5s - loss: 0.0316 - lwlrap: 0.9321 - val_loss: 0.0771 - val_lwlrap: 0.8282
Epoch 39/100
15/15 - 5s - loss: 0.0932 - lwlrap: 0.9229 - val_loss: 0.0730 - val_lwlrap: 0.8148
Epoch 40/100
15/15 - 5s - loss: 0.0303 - lwlrap: 0.9494 - val_loss: 0.0834 - val_lwlrap: 0.8284
Epoch 41/100
15/15 - 5s - loss: 0.0265 - lwlrap: 0.9553 - val_loss: 0.0731 - val_lwlrap: 0.8263
Epoch 42/100
15/15 - 5s - loss: 0.0274 - lwlrap: 0.9440 - val_loss: 0.0786 - val_lwlrap: 0.8074
Epoch 43/100
15/15 - 5s - loss: 0.0274 - lwlrap: 0.9547 - val_loss: 0.0891 - val_lwlrap: 0.8021
Epoch 44/100
15/15 - 5s - loss: 0.0203 - lwlrap: 0.9540 - val_loss: 0.0813 - val_lwlrap: 0.8155
Epoch 45/100
15/15 - 5s - loss: 0.0253 - lwlrap: 0.9630 - val_loss: 0.0806 - val_lwlrap: 0.8220
Epoch 46/100
15/15 - 5s - loss: 0.0336 - lwlrap: 0.9440 - val_loss: 0.0884 - val_lwlrap: 0.8129
Epoch 47/100
15/15 - 5s - loss: 0.0280 - lwlrap: 0.9573 - val_loss: 0.0947 - val_lwlrap: 0.8266
Epoch 48/100
15/15 - 5s - loss: 0.0272 - lwlrap: 0.9514 - val_loss: 0.0864 - val_lwlrap: 0.8293
Epoch 49/100
15/15 - 5s - loss: 0.0259 - lwlrap: 0.9527 - val_loss: 0.0959 - val_lwlrap: 0.8106
Epoch 50/100
15/15 - 5s - loss: 0.0768 - lwlrap: 0.9611 - val_loss: 0.1054 - val_lwlrap: 0.8087
Epoch 51/100
15/15 - 5s - loss: 0.0783 - lwlrap: 0.9576 - val_loss: 0.0824 - val_lwlrap: 0.8300
Epoch 52/100
15/15 - 5s - loss: 0.0229 - lwlrap: 0.9651 - val_loss: 0.0851 - val_lwlrap: 0.8281
Epoch 53/100
15/15 - 5s - loss: 0.0806 - lwlrap: 0.9713 - val_loss: 0.0787 - val_lwlrap: 0.8310
Epoch 54/100
15/15 - 5s - loss: 0.0675 - lwlrap: 0.9502 - val_loss: 0.0866 - val_lwlrap: 0.8081
Epoch 55/100
15/15 - 5s - loss: 0.0268 - lwlrap: 0.9648 - val_loss: 0.0899 - val_lwlrap: 0.8298
Epoch 56/100
15/15 - 5s - loss: 0.0907 - lwlrap: 0.9595 - val_loss: 0.0859 - val_lwlrap: 0.8201
Epoch 57/100
15/15 - 5s - loss: 0.0709 - lwlrap: 0.9597 - val_loss: 0.0901 - val_lwlrap: 0.8254
Epoch 58/100
15/15 - 5s - loss: 0.1166 - lwlrap: 0.9452 - val_loss: 0.0892 - val_lwlrap: 0.8327
Epoch 59/100
15/15 - 5s - loss: 0.0661 - lwlrap: 0.9607 - val_loss: 0.0877 - val_lwlrap: 0.8477
Epoch 60/100
15/15 - 5s - loss: 0.0676 - lwlrap: 0.9566 - val_loss: 0.0904 - val_lwlrap: 0.8405
Epoch 61/100
15/15 - 5s - loss: 0.0640 - lwlrap: 0.9673 - val_loss: 0.1006 - val_lwlrap: 0.8300
Epoch 62/100
15/15 - 5s - loss: 0.0226 - lwlrap: 0.9662 - val_loss: 0.0951 - val_lwlrap: 0.8580
Epoch 63/100
15/15 - 5s - loss: 0.0218 - lwlrap: 0.9775 - val_loss: 0.0717 - val_lwlrap: 0.8372
Epoch 64/100
15/15 - 5s - loss: 0.0756 - lwlrap: 0.9729 - val_loss: 0.0865 - val_lwlrap: 0.8384
Epoch 65/100
15/15 - 5s - loss: 0.0841 - lwlrap: 0.9695 - val_loss: 0.0891 - val_lwlrap: 0.8180
Epoch 66/100
15/15 - 5s - loss: 0.0154 - lwlrap: 0.9731 - val_loss: 0.0887 - val_lwlrap: 0.8282
Epoch 67/100
15/15 - 5s - loss: 0.0180 - lwlrap: 0.9729 - val_loss: 0.0897 - val_lwlrap: 0.8113
Epoch 68/100
15/15 - 5s - loss: 0.0179 - lwlrap: 0.9681 - val_loss: 0.1074 - val_lwlrap: 0.8333
Epoch 69/100
15/15 - 5s - loss: 0.0189 - lwlrap: 0.9686 - val_loss: 0.1029 - val_lwlrap: 0.8154
Epoch 70/100
15/15 - 5s - loss: 0.0739 - lwlrap: 0.9650 - val_loss: 0.0870 - val_lwlrap: 0.8263
Epoch 71/100
15/15 - 5s - loss: 0.0602 - lwlrap: 0.9684 - val_loss: 0.1065 - val_lwlrap: 0.8397
Epoch 72/100
15/15 - 5s - loss: 0.0511 - lwlrap: 0.9653 - val_loss: 0.0871 - val_lwlrap: 0.8401
Epoch 73/100
15/15 - 5s - loss: 0.0256 - lwlrap: 0.9767 - val_loss: 0.0961 - val_lwlrap: 0.8129
Epoch 74/100
15/15 - 5s - loss: 0.0259 - lwlrap: 0.9639 - val_loss: 0.0980 - val_lwlrap: 0.8342
Epoch 75/100
15/15 - 5s - loss: 0.0712 - lwlrap: 0.9734 - val_loss: 0.0840 - val_lwlrap: 0.8338
Epoch 76/100
15/15 - 5s - loss: 0.0585 - lwlrap: 0.9799 - val_loss: 0.0936 - val_lwlrap: 0.8225
Epoch 77/100
15/15 - 5s - loss: 0.0529 - lwlrap: 0.9789 - val_loss: 0.0923 - val_lwlrap: 0.8477
Epoch 78/100
15/15 - 5s - loss: 0.0537 - lwlrap: 0.9749 - val_loss: 0.0926 - val_lwlrap: 0.8290
Epoch 79/100
15/15 - 5s - loss: 0.0524 - lwlrap: 0.9779 - val_loss: 0.0854 - val_lwlrap: 0.8330
Epoch 80/100
15/15 - 5s - loss: 0.0168 - lwlrap: 0.9773 - val_loss: 0.0930 - val_lwlrap: 0.8225
Epoch 81/100
15/15 - 5s - loss: 0.0236 - lwlrap: 0.9724 - val_loss: 0.0793 - val_lwlrap: 0.8078
Epoch 82/100
15/15 - 5s - loss: 0.0187 - lwlrap: 0.9765 - val_loss: 0.0985 - val_lwlrap: 0.8204
Epoch 83/100
15/15 - 5s - loss: 0.0534 - lwlrap: 0.9701 - val_loss: 0.0971 - val_lwlrap: 0.8370
Epoch 84/100
15/15 - 5s - loss: 0.0638 - lwlrap: 0.9734 - val_loss: 0.1002 - val_lwlrap: 0.8373
Epoch 85/100
15/15 - 5s - loss: 0.0223 - lwlrap: 0.9720 - val_loss: 0.0910 - val_lwlrap: 0.8145
Epoch 86/100
15/15 - 5s - loss: 0.0491 - lwlrap: 0.9829 - val_loss: 0.0775 - val_lwlrap: 0.8194
Epoch 87/100
15/15 - 5s - loss: 0.0139 - lwlrap: 0.9793 - val_loss: 0.0993 - val_lwlrap: 0.8323
Epoch 88/100
15/15 - 5s - loss: 0.0394 - lwlrap: 0.9773 - val_loss: 0.0905 - val_lwlrap: 0.8230
Epoch 89/100
15/15 - 5s - loss: 0.0222 - lwlrap: 0.9762 - val_loss: 0.1169 - val_lwlrap: 0.8157
Epoch 90/100
15/15 - 5s - loss: 0.0225 - lwlrap: 0.9828 - val_loss: 0.1011 - val_lwlrap: 0.8359
Epoch 91/100
15/15 - 5s - loss: 0.0193 - lwlrap: 0.9863 - val_loss: 0.0975 - val_lwlrap: 0.8327
Epoch 92/100
15/15 - 5s - loss: 0.0236 - lwlrap: 0.9860 - val_loss: 0.1000 - val_lwlrap: 0.8298

-------------   Fold 2 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Training Model 

Epoch 1/100
15/15 - 6s - loss: 0.4324 - lwlrap: 0.1881 - val_loss: 0.2660 - val_lwlrap: 0.2977
Epoch 2/100
15/15 - 5s - loss: 0.3667 - lwlrap: 0.2477 - val_loss: 0.2003 - val_lwlrap: 0.4856
Epoch 3/100
15/15 - 5s - loss: 0.2952 - lwlrap: 0.3470 - val_loss: 0.1523 - val_lwlrap: 0.5072
Epoch 4/100
15/15 - 5s - loss: 0.2662 - lwlrap: 0.4925 - val_loss: 0.1399 - val_lwlrap: 0.6894
Epoch 5/100
15/15 - 5s - loss: 0.2280 - lwlrap: 0.5098 - val_loss: 0.1534 - val_lwlrap: 0.6622
Epoch 6/100
15/15 - 5s - loss: 0.1115 - lwlrap: 0.6082 - val_loss: 0.1121 - val_lwlrap: 0.8302
Epoch 7/100
15/15 - 5s - loss: 0.0924 - lwlrap: 0.6813 - val_loss: 0.0993 - val_lwlrap: 0.8393
Epoch 8/100
15/15 - 5s - loss: 0.0804 - lwlrap: 0.6527 - val_loss: 0.0970 - val_lwlrap: 0.8572
Epoch 9/100
15/15 - 5s - loss: 0.0835 - lwlrap: 0.6658 - val_loss: 0.0936 - val_lwlrap: 0.7972
Epoch 10/100
15/15 - 5s - loss: 0.2122 - lwlrap: 0.6602 - val_loss: 0.1072 - val_lwlrap: 0.8563
Epoch 11/100
15/15 - 5s - loss: 0.2081 - lwlrap: 0.7242 - val_loss: 0.1050 - val_lwlrap: 0.8435
Epoch 12/100
15/15 - 5s - loss: 0.2065 - lwlrap: 0.7645 - val_loss: 0.0859 - val_lwlrap: 0.8510
Epoch 13/100
15/15 - 5s - loss: 0.1588 - lwlrap: 0.7568 - val_loss: 0.0849 - val_lwlrap: 0.8740
Epoch 14/100
15/15 - 5s - loss: 0.0765 - lwlrap: 0.8082 - val_loss: 0.0825 - val_lwlrap: 0.8817
Epoch 15/100
15/15 - 5s - loss: 0.0650 - lwlrap: 0.7936 - val_loss: 0.0860 - val_lwlrap: 0.8709
Epoch 16/100
15/15 - 5s - loss: 0.0630 - lwlrap: 0.8575 - val_loss: 0.0695 - val_lwlrap: 0.8839
Epoch 17/100
15/15 - 5s - loss: 0.0625 - lwlrap: 0.7960 - val_loss: 0.1221 - val_lwlrap: 0.7609
Epoch 18/100
15/15 - 5s - loss: 0.0602 - lwlrap: 0.8568 - val_loss: 0.0686 - val_lwlrap: 0.8864
Epoch 19/100
15/15 - 5s - loss: 0.0498 - lwlrap: 0.8718 - val_loss: 0.0743 - val_lwlrap: 0.8743
Epoch 20/100
15/15 - 5s - loss: 0.1491 - lwlrap: 0.8642 - val_loss: 0.0644 - val_lwlrap: 0.8712
Epoch 21/100
15/15 - 5s - loss: 0.1465 - lwlrap: 0.8287 - val_loss: 0.0738 - val_lwlrap: 0.8845
Epoch 22/100
15/15 - 5s - loss: 0.0492 - lwlrap: 0.9083 - val_loss: 0.0754 - val_lwlrap: 0.8877
Epoch 23/100
15/15 - 5s - loss: 0.1249 - lwlrap: 0.8705 - val_loss: 0.0666 - val_lwlrap: 0.8744
Epoch 24/100
15/15 - 5s - loss: 0.1408 - lwlrap: 0.8751 - val_loss: 0.0794 - val_lwlrap: 0.8840
Epoch 25/100
15/15 - 5s - loss: 0.0454 - lwlrap: 0.8904 - val_loss: 0.0807 - val_lwlrap: 0.8585
Epoch 26/100
15/15 - 5s - loss: 0.0400 - lwlrap: 0.8955 - val_loss: 0.0738 - val_lwlrap: 0.8782
Epoch 27/100
15/15 - 5s - loss: 0.0465 - lwlrap: 0.8796 - val_loss: 0.0627 - val_lwlrap: 0.8820
Epoch 28/100
15/15 - 5s - loss: 0.0406 - lwlrap: 0.9028 - val_loss: 0.0643 - val_lwlrap: 0.8875
Epoch 29/100
15/15 - 5s - loss: 0.0389 - lwlrap: 0.9155 - val_loss: 0.0776 - val_lwlrap: 0.8886
Epoch 30/100
15/15 - 5s - loss: 0.0359 - lwlrap: 0.9186 - val_loss: 0.0715 - val_lwlrap: 0.8778
Epoch 31/100
15/15 - 5s - loss: 0.0498 - lwlrap: 0.9009 - val_loss: 0.0799 - val_lwlrap: 0.8897
Epoch 32/100
15/15 - 5s - loss: 0.0359 - lwlrap: 0.9305 - val_loss: 0.0712 - val_lwlrap: 0.8875
Epoch 33/100
15/15 - 5s - loss: 0.0299 - lwlrap: 0.9312 - val_loss: 0.0700 - val_lwlrap: 0.8807
Epoch 34/100
15/15 - 5s - loss: 0.0396 - lwlrap: 0.8944 - val_loss: 0.0784 - val_lwlrap: 0.8951
Epoch 35/100
15/15 - 5s - loss: 0.1226 - lwlrap: 0.9115 - val_loss: 0.0932 - val_lwlrap: 0.8788
Epoch 36/100
15/15 - 5s - loss: 0.0370 - lwlrap: 0.9428 - val_loss: 0.0852 - val_lwlrap: 0.8804
Epoch 37/100
15/15 - 5s - loss: 0.0356 - lwlrap: 0.9361 - val_loss: 0.0815 - val_lwlrap: 0.8830
Epoch 38/100
15/15 - 5s - loss: 0.0274 - lwlrap: 0.9316 - val_loss: 0.0719 - val_lwlrap: 0.8857
Epoch 39/100
15/15 - 5s - loss: 0.0327 - lwlrap: 0.9387 - val_loss: 0.0765 - val_lwlrap: 0.8889
Epoch 40/100
15/15 - 5s - loss: 0.0952 - lwlrap: 0.9188 - val_loss: 0.0904 - val_lwlrap: 0.8719
Epoch 41/100
15/15 - 5s - loss: 0.0997 - lwlrap: 0.9310 - val_loss: 0.1029 - val_lwlrap: 0.8718
Epoch 42/100
15/15 - 5s - loss: 0.0374 - lwlrap: 0.9145 - val_loss: 0.0889 - val_lwlrap: 0.8881
Epoch 43/100
15/15 - 5s - loss: 0.0872 - lwlrap: 0.9437 - val_loss: 0.0814 - val_lwlrap: 0.8789
Epoch 44/100
15/15 - 5s - loss: 0.0359 - lwlrap: 0.9352 - val_loss: 0.0766 - val_lwlrap: 0.8856
Epoch 45/100
15/15 - 5s - loss: 0.0312 - lwlrap: 0.9659 - val_loss: 0.0871 - val_lwlrap: 0.8739
Epoch 46/100
15/15 - 5s - loss: 0.0937 - lwlrap: 0.9404 - val_loss: 0.0952 - val_lwlrap: 0.8726
Epoch 47/100
15/15 - 5s - loss: 0.0900 - lwlrap: 0.9492 - val_loss: 0.0909 - val_lwlrap: 0.8710
Epoch 48/100
15/15 - 5s - loss: 0.0257 - lwlrap: 0.9367 - val_loss: 0.1039 - val_lwlrap: 0.8735
Epoch 49/100
15/15 - 5s - loss: 0.0849 - lwlrap: 0.9529 - val_loss: 0.1117 - val_lwlrap: 0.8743
Epoch 50/100
15/15 - 5s - loss: 0.1123 - lwlrap: 0.9536 - val_loss: 0.0781 - val_lwlrap: 0.8859
Epoch 51/100
15/15 - 5s - loss: 0.0253 - lwlrap: 0.9428 - val_loss: 0.1072 - val_lwlrap: 0.8684
Epoch 52/100
15/15 - 5s - loss: 0.0244 - lwlrap: 0.9489 - val_loss: 0.1042 - val_lwlrap: 0.8769
Epoch 53/100
15/15 - 5s - loss: 0.0283 - lwlrap: 0.9438 - val_loss: 0.0818 - val_lwlrap: 0.9037
Epoch 54/100
15/15 - 5s - loss: 0.0721 - lwlrap: 0.9657 - val_loss: 0.0803 - val_lwlrap: 0.8950
Epoch 55/100
15/15 - 5s - loss: 0.0207 - lwlrap: 0.9580 - val_loss: 0.0924 - val_lwlrap: 0.8797
Epoch 56/100
15/15 - 5s - loss: 0.0870 - lwlrap: 0.9424 - val_loss: 0.0921 - val_lwlrap: 0.8727
Epoch 57/100
15/15 - 5s - loss: 0.0828 - lwlrap: 0.9500 - val_loss: 0.0915 - val_lwlrap: 0.8795
Epoch 58/100
15/15 - 5s - loss: 0.0314 - lwlrap: 0.9629 - val_loss: 0.0951 - val_lwlrap: 0.8797
Epoch 59/100
15/15 - 5s - loss: 0.0343 - lwlrap: 0.9511 - val_loss: 0.0959 - val_lwlrap: 0.8661
Epoch 60/100
15/15 - 5s - loss: 0.0721 - lwlrap: 0.9630 - val_loss: 0.0884 - val_lwlrap: 0.8895
Epoch 61/100
15/15 - 5s - loss: 0.0738 - lwlrap: 0.9657 - val_loss: 0.0955 - val_lwlrap: 0.8773
Epoch 62/100
15/15 - 5s - loss: 0.0307 - lwlrap: 0.9607 - val_loss: 0.0966 - val_lwlrap: 0.8741
Epoch 63/100
15/15 - 5s - loss: 0.0207 - lwlrap: 0.9581 - val_loss: 0.0988 - val_lwlrap: 0.8654
Epoch 64/100
15/15 - 5s - loss: 0.0234 - lwlrap: 0.9780 - val_loss: 0.0885 - val_lwlrap: 0.8816
Epoch 65/100
15/15 - 5s - loss: 0.0206 - lwlrap: 0.9521 - val_loss: 0.0935 - val_lwlrap: 0.8859
Epoch 66/100
15/15 - 5s - loss: 0.0863 - lwlrap: 0.9572 - val_loss: 0.0923 - val_lwlrap: 0.8967
Epoch 67/100
15/15 - 5s - loss: 0.0767 - lwlrap: 0.9552 - val_loss: 0.1076 - val_lwlrap: 0.8998
Epoch 68/100
15/15 - 5s - loss: 0.0248 - lwlrap: 0.9783 - val_loss: 0.0999 - val_lwlrap: 0.8836
Epoch 69/100
15/15 - 5s - loss: 0.0753 - lwlrap: 0.9622 - val_loss: 0.0871 - val_lwlrap: 0.8816
Epoch 70/100
15/15 - 5s - loss: 0.0234 - lwlrap: 0.9539 - val_loss: 0.0955 - val_lwlrap: 0.8832
Epoch 71/100
15/15 - 5s - loss: 0.0660 - lwlrap: 0.9540 - val_loss: 0.1041 - val_lwlrap: 0.8973
Epoch 72/100
15/15 - 5s - loss: 0.0771 - lwlrap: 0.9607 - val_loss: 0.1024 - val_lwlrap: 0.9019
Epoch 73/100
15/15 - 5s - loss: 0.0287 - lwlrap: 0.9767 - val_loss: 0.1080 - val_lwlrap: 0.8870
Epoch 74/100
15/15 - 5s - loss: 0.0724 - lwlrap: 0.9661 - val_loss: 0.0892 - val_lwlrap: 0.8876
Epoch 75/100
15/15 - 5s - loss: 0.0794 - lwlrap: 0.9804 - val_loss: 0.0815 - val_lwlrap: 0.8894
Epoch 76/100
15/15 - 5s - loss: 0.0645 - lwlrap: 0.9714 - val_loss: 0.0915 - val_lwlrap: 0.8779
Epoch 77/100
15/15 - 5s - loss: 0.0154 - lwlrap: 0.9598 - val_loss: 0.0998 - val_lwlrap: 0.8818
Epoch 78/100
15/15 - 5s - loss: 0.0697 - lwlrap: 0.9708 - val_loss: 0.1018 - val_lwlrap: 0.8741
Epoch 79/100
15/15 - 5s - loss: 0.0256 - lwlrap: 0.9703 - val_loss: 0.0913 - val_lwlrap: 0.8826
Epoch 80/100
15/15 - 5s - loss: 0.0204 - lwlrap: 0.9813 - val_loss: 0.1019 - val_lwlrap: 0.8773
Epoch 81/100
15/15 - 5s - loss: 0.0564 - lwlrap: 0.9790 - val_loss: 0.1043 - val_lwlrap: 0.8682
Epoch 82/100
15/15 - 5s - loss: 0.0561 - lwlrap: 0.9796 - val_loss: 0.0867 - val_lwlrap: 0.8938
Epoch 83/100
15/15 - 5s - loss: 0.0166 - lwlrap: 0.9662 - val_loss: 0.0998 - val_lwlrap: 0.8862

-------------   Fold 3 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Training Model 

Epoch 1/100
15/15 - 6s - loss: 0.3830 - lwlrap: 0.2060 - val_loss: 0.2863 - val_lwlrap: 0.3016
Epoch 2/100
15/15 - 5s - loss: 0.3146 - lwlrap: 0.2678 - val_loss: 0.1933 - val_lwlrap: 0.3978
Epoch 3/100
15/15 - 5s - loss: 0.2772 - lwlrap: 0.3538 - val_loss: 0.1723 - val_lwlrap: 0.3960
Epoch 4/100
15/15 - 5s - loss: 0.1146 - lwlrap: 0.5223 - val_loss: 0.1597 - val_lwlrap: 0.6350
Epoch 5/100
15/15 - 5s - loss: 0.1264 - lwlrap: 0.5770 - val_loss: 0.1584 - val_lwlrap: 0.6675
Epoch 6/100
15/15 - 5s - loss: 0.0919 - lwlrap: 0.6436 - val_loss: 0.1394 - val_lwlrap: 0.7395
Epoch 7/100
15/15 - 5s - loss: 0.2006 - lwlrap: 0.6769 - val_loss: 0.1142 - val_lwlrap: 0.7962
Epoch 8/100
15/15 - 5s - loss: 0.2033 - lwlrap: 0.6950 - val_loss: 0.1085 - val_lwlrap: 0.8064
Epoch 9/100
15/15 - 5s - loss: 0.0784 - lwlrap: 0.7675 - val_loss: 0.0866 - val_lwlrap: 0.8101
Epoch 10/100
15/15 - 5s - loss: 0.1049 - lwlrap: 0.7085 - val_loss: 0.0862 - val_lwlrap: 0.8214
Epoch 11/100
15/15 - 5s - loss: 0.1580 - lwlrap: 0.7372 - val_loss: 0.0984 - val_lwlrap: 0.7318
Epoch 12/100
15/15 - 5s - loss: 0.1653 - lwlrap: 0.7926 - val_loss: 0.0909 - val_lwlrap: 0.8373
Epoch 13/100
15/15 - 5s - loss: 0.1338 - lwlrap: 0.8002 - val_loss: 0.0882 - val_lwlrap: 0.8394
Epoch 14/100
15/15 - 5s - loss: 0.1644 - lwlrap: 0.8043 - val_loss: 0.0845 - val_lwlrap: 0.8559
Epoch 15/100
15/15 - 5s - loss: 0.0483 - lwlrap: 0.8636 - val_loss: 0.0864 - val_lwlrap: 0.8446
Epoch 16/100
15/15 - 5s - loss: 0.0597 - lwlrap: 0.8689 - val_loss: 0.0733 - val_lwlrap: 0.8382
Epoch 17/100
15/15 - 5s - loss: 0.1306 - lwlrap: 0.8325 - val_loss: 0.0836 - val_lwlrap: 0.8336
Epoch 18/100
15/15 - 5s - loss: 0.0345 - lwlrap: 0.8922 - val_loss: 0.0787 - val_lwlrap: 0.8527
Epoch 19/100
15/15 - 5s - loss: 0.1542 - lwlrap: 0.8573 - val_loss: 0.0655 - val_lwlrap: 0.8431
Epoch 20/100
15/15 - 5s - loss: 0.1276 - lwlrap: 0.8899 - val_loss: 0.0642 - val_lwlrap: 0.8577
Epoch 21/100
15/15 - 5s - loss: 0.0407 - lwlrap: 0.8823 - val_loss: 0.0614 - val_lwlrap: 0.8646
Epoch 22/100
15/15 - 5s - loss: 0.1027 - lwlrap: 0.8918 - val_loss: 0.0638 - val_lwlrap: 0.8520
Epoch 23/100
15/15 - 5s - loss: 0.1070 - lwlrap: 0.9073 - val_loss: 0.0668 - val_lwlrap: 0.8518
Epoch 24/100
15/15 - 5s - loss: 0.0644 - lwlrap: 0.8972 - val_loss: 0.0733 - val_lwlrap: 0.8543
Epoch 25/100
15/15 - 5s - loss: 0.1013 - lwlrap: 0.9006 - val_loss: 0.0747 - val_lwlrap: 0.8407
Epoch 26/100
15/15 - 5s - loss: 0.1289 - lwlrap: 0.9064 - val_loss: 0.0675 - val_lwlrap: 0.8507
Epoch 27/100
15/15 - 5s - loss: 0.1088 - lwlrap: 0.9120 - val_loss: 0.0621 - val_lwlrap: 0.8487
Epoch 28/100
15/15 - 5s - loss: 0.0378 - lwlrap: 0.9450 - val_loss: 0.0679 - val_lwlrap: 0.8511
Epoch 29/100
15/15 - 5s - loss: 0.1002 - lwlrap: 0.9120 - val_loss: 0.0614 - val_lwlrap: 0.8577
Epoch 30/100
15/15 - 5s - loss: 0.1044 - lwlrap: 0.9180 - val_loss: 0.0517 - val_lwlrap: 0.8686
Epoch 31/100
15/15 - 5s - loss: 0.0324 - lwlrap: 0.9456 - val_loss: 0.0676 - val_lwlrap: 0.8533
Epoch 32/100
15/15 - 5s - loss: 0.1144 - lwlrap: 0.9268 - val_loss: 0.0603 - val_lwlrap: 0.8470
Epoch 33/100
15/15 - 5s - loss: 0.0928 - lwlrap: 0.9265 - val_loss: 0.0678 - val_lwlrap: 0.8569
Epoch 34/100
15/15 - 5s - loss: 0.1043 - lwlrap: 0.9190 - val_loss: 0.0665 - val_lwlrap: 0.8717
Epoch 35/100
15/15 - 5s - loss: 0.0396 - lwlrap: 0.9513 - val_loss: 0.0679 - val_lwlrap: 0.8434
Epoch 36/100
15/15 - 5s - loss: 0.0934 - lwlrap: 0.9429 - val_loss: 0.0616 - val_lwlrap: 0.8488
Epoch 37/100
15/15 - 5s - loss: 0.0312 - lwlrap: 0.9406 - val_loss: 0.0662 - val_lwlrap: 0.8346
Epoch 38/100
15/15 - 5s - loss: 0.0315 - lwlrap: 0.9438 - val_loss: 0.0604 - val_lwlrap: 0.8529
Epoch 39/100
15/15 - 5s - loss: 0.0315 - lwlrap: 0.9498 - val_loss: 0.0579 - val_lwlrap: 0.8321
Epoch 40/100
15/15 - 5s - loss: 0.0362 - lwlrap: 0.9426 - val_loss: 0.0625 - val_lwlrap: 0.8500
Epoch 41/100
15/15 - 5s - loss: 0.0263 - lwlrap: 0.9557 - val_loss: 0.0612 - val_lwlrap: 0.8527
Epoch 42/100
15/15 - 5s - loss: 0.0359 - lwlrap: 0.9489 - val_loss: 0.0678 - val_lwlrap: 0.8558
Epoch 43/100
15/15 - 5s - loss: 0.0901 - lwlrap: 0.9390 - val_loss: 0.0608 - val_lwlrap: 0.8427
Epoch 44/100
15/15 - 5s - loss: 0.1024 - lwlrap: 0.9521 - val_loss: 0.0629 - val_lwlrap: 0.8408
Epoch 45/100
15/15 - 5s - loss: 0.0829 - lwlrap: 0.9562 - val_loss: 0.0692 - val_lwlrap: 0.8415
Epoch 46/100
15/15 - 5s - loss: 0.0774 - lwlrap: 0.9441 - val_loss: 0.0641 - val_lwlrap: 0.8351
Epoch 47/100
15/15 - 5s - loss: 0.0613 - lwlrap: 0.9539 - val_loss: 0.0772 - val_lwlrap: 0.8508
Epoch 48/100
15/15 - 5s - loss: 0.0302 - lwlrap: 0.9581 - val_loss: 0.0649 - val_lwlrap: 0.8486
Epoch 49/100
15/15 - 5s - loss: 0.0726 - lwlrap: 0.9556 - val_loss: 0.0743 - val_lwlrap: 0.8472
Epoch 50/100
15/15 - 5s - loss: 0.0798 - lwlrap: 0.9636 - val_loss: 0.0639 - val_lwlrap: 0.8655
Epoch 51/100
15/15 - 5s - loss: 0.0880 - lwlrap: 0.9715 - val_loss: 0.0669 - val_lwlrap: 0.8431
Epoch 52/100
15/15 - 5s - loss: 0.0907 - lwlrap: 0.9620 - val_loss: 0.0712 - val_lwlrap: 0.8479
Epoch 53/100
15/15 - 5s - loss: 0.0727 - lwlrap: 0.9634 - val_loss: 0.0685 - val_lwlrap: 0.8428
Epoch 54/100
15/15 - 5s - loss: 0.0240 - lwlrap: 0.9619 - val_loss: 0.0742 - val_lwlrap: 0.8483
Epoch 55/100
15/15 - 5s - loss: 0.0698 - lwlrap: 0.9730 - val_loss: 0.0721 - val_lwlrap: 0.8345
Epoch 56/100
15/15 - 5s - loss: 0.0263 - lwlrap: 0.9638 - val_loss: 0.0636 - val_lwlrap: 0.8411
Epoch 57/100
15/15 - 5s - loss: 0.0774 - lwlrap: 0.9593 - val_loss: 0.0735 - val_lwlrap: 0.8497
Epoch 58/100
15/15 - 5s - loss: 0.0314 - lwlrap: 0.9649 - val_loss: 0.0717 - val_lwlrap: 0.8506
Epoch 59/100
15/15 - 5s - loss: 0.0580 - lwlrap: 0.9680 - val_loss: 0.0743 - val_lwlrap: 0.8420
Epoch 60/100
15/15 - 5s - loss: 0.0548 - lwlrap: 0.9661 - val_loss: 0.0573 - val_lwlrap: 0.8489
Epoch 61/100
15/15 - 5s - loss: 0.0209 - lwlrap: 0.9718 - val_loss: 0.0829 - val_lwlrap: 0.8596
Epoch 62/100
15/15 - 5s - loss: 0.0852 - lwlrap: 0.9702 - val_loss: 0.0750 - val_lwlrap: 0.8559
Epoch 63/100
15/15 - 5s - loss: 0.0752 - lwlrap: 0.9730 - val_loss: 0.0793 - val_lwlrap: 0.8425
Epoch 64/100
15/15 - 5s - loss: 0.0740 - lwlrap: 0.9732 - val_loss: 0.0696 - val_lwlrap: 0.8417

-------------   Fold 4 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Training Model 

Epoch 1/100
15/15 - 6s - loss: 0.3896 - lwlrap: 0.2000 - val_loss: 0.2129 - val_lwlrap: 0.2209
Epoch 2/100
15/15 - 5s - loss: 0.3370 - lwlrap: 0.2471 - val_loss: 0.1668 - val_lwlrap: 0.3357
Epoch 3/100
15/15 - 5s - loss: 0.1946 - lwlrap: 0.3704 - val_loss: 0.1492 - val_lwlrap: 0.3832
Epoch 4/100
15/15 - 5s - loss: 0.1372 - lwlrap: 0.4944 - val_loss: 0.1229 - val_lwlrap: 0.7298
Epoch 5/100
15/15 - 5s - loss: 0.2196 - lwlrap: 0.5865 - val_loss: 0.1306 - val_lwlrap: 0.6484
Epoch 6/100
15/15 - 5s - loss: 0.2215 - lwlrap: 0.6139 - val_loss: 0.1133 - val_lwlrap: 0.8420
Epoch 7/100
15/15 - 5s - loss: 0.1096 - lwlrap: 0.6849 - val_loss: 0.1099 - val_lwlrap: 0.8398
Epoch 8/100
15/15 - 5s - loss: 0.0842 - lwlrap: 0.7003 - val_loss: 0.1028 - val_lwlrap: 0.8427
Epoch 9/100
15/15 - 5s - loss: 0.0883 - lwlrap: 0.6946 - val_loss: 0.1220 - val_lwlrap: 0.7696
Epoch 10/100
15/15 - 5s - loss: 0.2205 - lwlrap: 0.7208 - val_loss: 0.0963 - val_lwlrap: 0.8389
Epoch 11/100
15/15 - 5s - loss: 0.1560 - lwlrap: 0.7494 - val_loss: 0.0884 - val_lwlrap: 0.7858
Epoch 12/100
15/15 - 5s - loss: 0.0572 - lwlrap: 0.7751 - val_loss: 0.0886 - val_lwlrap: 0.8545
Epoch 13/100
15/15 - 5s - loss: 0.0730 - lwlrap: 0.7942 - val_loss: 0.0791 - val_lwlrap: 0.8385
Epoch 14/100
15/15 - 5s - loss: 0.1654 - lwlrap: 0.8409 - val_loss: 0.0783 - val_lwlrap: 0.8455
Epoch 15/100
15/15 - 5s - loss: 0.0499 - lwlrap: 0.8477 - val_loss: 0.0847 - val_lwlrap: 0.8128
Epoch 16/100
15/15 - 5s - loss: 0.1660 - lwlrap: 0.8657 - val_loss: 0.0680 - val_lwlrap: 0.8527
Epoch 17/100
15/15 - 5s - loss: 0.0482 - lwlrap: 0.8670 - val_loss: 0.0816 - val_lwlrap: 0.8354
Epoch 18/100
15/15 - 5s - loss: 0.0566 - lwlrap: 0.8382 - val_loss: 0.0638 - val_lwlrap: 0.8583
Epoch 19/100
15/15 - 5s - loss: 0.1474 - lwlrap: 0.8586 - val_loss: 0.0607 - val_lwlrap: 0.8752
Epoch 20/100
15/15 - 5s - loss: 0.0497 - lwlrap: 0.8915 - val_loss: 0.0648 - val_lwlrap: 0.8686
Epoch 21/100
15/15 - 5s - loss: 0.0556 - lwlrap: 0.9026 - val_loss: 0.0577 - val_lwlrap: 0.8476
Epoch 22/100
15/15 - 5s - loss: 0.0485 - lwlrap: 0.8889 - val_loss: 0.0563 - val_lwlrap: 0.8518
Epoch 23/100
15/15 - 5s - loss: 0.0479 - lwlrap: 0.9114 - val_loss: 0.0715 - val_lwlrap: 0.8464
Epoch 24/100
15/15 - 5s - loss: 0.0410 - lwlrap: 0.8999 - val_loss: 0.0601 - val_lwlrap: 0.8682
Epoch 25/100
15/15 - 5s - loss: 0.1127 - lwlrap: 0.8953 - val_loss: 0.0589 - val_lwlrap: 0.8583
Epoch 26/100
15/15 - 5s - loss: 0.1367 - lwlrap: 0.9078 - val_loss: 0.0582 - val_lwlrap: 0.8658
Epoch 27/100
15/15 - 5s - loss: 0.0323 - lwlrap: 0.9107 - val_loss: 0.0558 - val_lwlrap: 0.8669
Epoch 28/100
15/15 - 5s - loss: 0.0877 - lwlrap: 0.9286 - val_loss: 0.0571 - val_lwlrap: 0.8642
Epoch 29/100
15/15 - 5s - loss: 0.1127 - lwlrap: 0.9175 - val_loss: 0.0603 - val_lwlrap: 0.8688
Epoch 30/100
15/15 - 5s - loss: 0.0401 - lwlrap: 0.9274 - val_loss: 0.0609 - val_lwlrap: 0.8570
Epoch 31/100
15/15 - 5s - loss: 0.0307 - lwlrap: 0.9352 - val_loss: 0.0553 - val_lwlrap: 0.8680
Epoch 32/100
15/15 - 5s - loss: 0.0278 - lwlrap: 0.9401 - val_loss: 0.0548 - val_lwlrap: 0.8660
Epoch 33/100
15/15 - 5s - loss: 0.1045 - lwlrap: 0.9279 - val_loss: 0.0531 - val_lwlrap: 0.8774
Epoch 34/100
15/15 - 5s - loss: 0.0911 - lwlrap: 0.9224 - val_loss: 0.0567 - val_lwlrap: 0.8674
Epoch 35/100
15/15 - 5s - loss: 0.1026 - lwlrap: 0.9474 - val_loss: 0.0474 - val_lwlrap: 0.8624
Epoch 36/100
15/15 - 5s - loss: 0.0951 - lwlrap: 0.9417 - val_loss: 0.0604 - val_lwlrap: 0.8707
Epoch 37/100
15/15 - 5s - loss: 0.0260 - lwlrap: 0.9527 - val_loss: 0.0596 - val_lwlrap: 0.8523
Epoch 38/100
15/15 - 5s - loss: 0.0318 - lwlrap: 0.9433 - val_loss: 0.0606 - val_lwlrap: 0.8520
Epoch 39/100
15/15 - 5s - loss: 0.0722 - lwlrap: 0.9730 - val_loss: 0.0510 - val_lwlrap: 0.8487
Epoch 40/100
15/15 - 5s - loss: 0.0898 - lwlrap: 0.9227 - val_loss: 0.0588 - val_lwlrap: 0.8712
Epoch 41/100
15/15 - 5s - loss: 0.0805 - lwlrap: 0.9388 - val_loss: 0.0459 - val_lwlrap: 0.8676
Epoch 42/100
15/15 - 5s - loss: 0.0846 - lwlrap: 0.9463 - val_loss: 0.0557 - val_lwlrap: 0.8743
Epoch 43/100
15/15 - 5s - loss: 0.0685 - lwlrap: 0.9471 - val_loss: 0.0495 - val_lwlrap: 0.8798
Epoch 44/100
15/15 - 5s - loss: 0.0280 - lwlrap: 0.9483 - val_loss: 0.0612 - val_lwlrap: 0.8683
Epoch 45/100
15/15 - 5s - loss: 0.0776 - lwlrap: 0.9537 - val_loss: 0.0820 - val_lwlrap: 0.8430
Epoch 46/100
15/15 - 5s - loss: 0.0301 - lwlrap: 0.9659 - val_loss: 0.0600 - val_lwlrap: 0.8547
Epoch 47/100
15/15 - 5s - loss: 0.0215 - lwlrap: 0.9683 - val_loss: 0.0642 - val_lwlrap: 0.8522
Epoch 48/100
15/15 - 5s - loss: 0.0263 - lwlrap: 0.9441 - val_loss: 0.0576 - val_lwlrap: 0.8673
Epoch 49/100
15/15 - 5s - loss: 0.0305 - lwlrap: 0.9588 - val_loss: 0.0558 - val_lwlrap: 0.8666
Epoch 50/100
15/15 - 5s - loss: 0.0898 - lwlrap: 0.9694 - val_loss: 0.0606 - val_lwlrap: 0.8564
Epoch 51/100
15/15 - 5s - loss: 0.0279 - lwlrap: 0.9562 - val_loss: 0.0644 - val_lwlrap: 0.8703
Epoch 52/100
15/15 - 5s - loss: 0.0888 - lwlrap: 0.9621 - val_loss: 0.0604 - val_lwlrap: 0.8664
Epoch 53/100
15/15 - 5s - loss: 0.0262 - lwlrap: 0.9650 - val_loss: 0.0657 - val_lwlrap: 0.8622
Epoch 54/100
15/15 - 5s - loss: 0.0858 - lwlrap: 0.9694 - val_loss: 0.0668 - val_lwlrap: 0.8535
Epoch 55/100
15/15 - 5s - loss: 0.0219 - lwlrap: 0.9665 - val_loss: 0.0654 - val_lwlrap: 0.8546
Epoch 56/100
15/15 - 5s - loss: 0.0705 - lwlrap: 0.9526 - val_loss: 0.0545 - val_lwlrap: 0.8621
Epoch 57/100
15/15 - 5s - loss: 0.0736 - lwlrap: 0.9562 - val_loss: 0.0570 - val_lwlrap: 0.8831
Epoch 58/100
15/15 - 5s - loss: 0.0240 - lwlrap: 0.9684 - val_loss: 0.0628 - val_lwlrap: 0.8646
Epoch 59/100
15/15 - 5s - loss: 0.0190 - lwlrap: 0.9721 - val_loss: 0.0573 - val_lwlrap: 0.8562
Epoch 60/100
15/15 - 5s - loss: 0.0171 - lwlrap: 0.9672 - val_loss: 0.0608 - val_lwlrap: 0.8581
Epoch 61/100
15/15 - 5s - loss: 0.0807 - lwlrap: 0.9688 - val_loss: 0.0707 - val_lwlrap: 0.8477
Epoch 62/100
15/15 - 5s - loss: 0.0563 - lwlrap: 0.9707 - val_loss: 0.0577 - val_lwlrap: 0.8474
Epoch 63/100
15/15 - 5s - loss: 0.0694 - lwlrap: 0.9575 - val_loss: 0.0671 - val_lwlrap: 0.8605
Epoch 64/100
15/15 - 5s - loss: 0.0201 - lwlrap: 0.9660 - val_loss: 0.0654 - val_lwlrap: 0.8519
Epoch 65/100
15/15 - 5s - loss: 0.0250 - lwlrap: 0.9755 - val_loss: 0.0608 - val_lwlrap: 0.8654
Epoch 66/100
15/15 - 5s - loss: 0.0681 - lwlrap: 0.9762 - val_loss: 0.0589 - val_lwlrap: 0.8694
Epoch 67/100
15/15 - 5s - loss: 0.0553 - lwlrap: 0.9778 - val_loss: 0.0617 - val_lwlrap: 0.8524
Epoch 68/100
15/15 - 5s - loss: 0.0777 - lwlrap: 0.9753 - val_loss: 0.0757 - val_lwlrap: 0.8479
Epoch 69/100
15/15 - 5s - loss: 0.0693 - lwlrap: 0.9732 - val_loss: 0.0689 - val_lwlrap: 0.8569
Epoch 70/100
15/15 - 5s - loss: 0.0265 - lwlrap: 0.9712 - val_loss: 0.0601 - val_lwlrap: 0.8521
Epoch 71/100
15/15 - 5s - loss: 0.0597 - lwlrap: 0.9779 - val_loss: 0.0588 - val_lwlrap: 0.8716
Epoch 72/100
15/15 - 5s - loss: 0.0176 - lwlrap: 0.9849 - val_loss: 0.0633 - val_lwlrap: 0.8610
Epoch 73/100
15/15 - 5s - loss: 0.0156 - lwlrap: 0.9758 - val_loss: 0.0616 - val_lwlrap: 0.8708
Epoch 74/100
15/15 - 5s - loss: 0.0160 - lwlrap: 0.9784 - val_loss: 0.0522 - val_lwlrap: 0.8644
Epoch 75/100
15/15 - 5s - loss: 0.0202 - lwlrap: 0.9820 - val_loss: 0.0540 - val_lwlrap: 0.8711
Epoch 76/100
15/15 - 5s - loss: 0.0206 - lwlrap: 0.9717 - val_loss: 0.0708 - val_lwlrap: 0.8539
Epoch 77/100
15/15 - 5s - loss: 0.0162 - lwlrap: 0.9803 - val_loss: 0.0607 - val_lwlrap: 0.8464
Epoch 78/100
15/15 - 5s - loss: 0.0144 - lwlrap: 0.9769 - val_loss: 0.0687 - val_lwlrap: 0.8648
Epoch 79/100
15/15 - 5s - loss: 0.0400 - lwlrap: 0.9847 - val_loss: 0.0519 - val_lwlrap: 0.8678
Epoch 80/100
15/15 - 5s - loss: 0.0198 - lwlrap: 0.9708 - val_loss: 0.0610 - val_lwlrap: 0.8506
Epoch 81/100
15/15 - 5s - loss: 0.0662 - lwlrap: 0.9789 - val_loss: 0.0634 - val_lwlrap: 0.8541
Epoch 82/100
15/15 - 5s - loss: 0.0222 - lwlrap: 0.9746 - val_loss: 0.0731 - val_lwlrap: 0.8651
Epoch 83/100
15/15 - 5s - loss: 0.0573 - lwlrap: 0.9806 - val_loss: 0.0554 - val_lwlrap: 0.8693
Epoch 84/100
15/15 - 5s - loss: 0.0208 - lwlrap: 0.9752 - val_loss: 0.0514 - val_lwlrap: 0.8563
Epoch 85/100
15/15 - 5s - loss: 0.0512 - lwlrap: 0.9774 - val_loss: 0.0581 - val_lwlrap: 0.8609
Epoch 86/100
15/15 - 5s - loss: 0.0710 - lwlrap: 0.9812 - val_loss: 0.0629 - val_lwlrap: 0.8562
Epoch 87/100
15/15 - 5s - loss: 0.0196 - lwlrap: 0.9870 - val_loss: 0.0677 - val_lwlrap: 0.8532

-------------   Fold 5 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Training Model 

Epoch 1/100
15/15 - 6s - loss: 0.3164 - lwlrap: 0.2102 - val_loss: 0.3056 - val_lwlrap: 0.3252
Epoch 2/100
15/15 - 5s - loss: 0.3383 - lwlrap: 0.2745 - val_loss: 0.1858 - val_lwlrap: 0.4619
Epoch 3/100
15/15 - 5s - loss: 0.3255 - lwlrap: 0.3747 - val_loss: 0.1357 - val_lwlrap: 0.4905
Epoch 4/100
15/15 - 5s - loss: 0.2775 - lwlrap: 0.4666 - val_loss: 0.1488 - val_lwlrap: 0.6664
Epoch 5/100
15/15 - 5s - loss: 0.2430 - lwlrap: 0.5345 - val_loss: 0.1179 - val_lwlrap: 0.7039
Epoch 6/100
15/15 - 5s - loss: 0.1094 - lwlrap: 0.6618 - val_loss: 0.1097 - val_lwlrap: 0.7807
Epoch 7/100
15/15 - 5s - loss: 0.2049 - lwlrap: 0.6762 - val_loss: 0.0995 - val_lwlrap: 0.8106
Epoch 8/100
15/15 - 5s - loss: 0.1113 - lwlrap: 0.6591 - val_loss: 0.0972 - val_lwlrap: 0.8187
Epoch 9/100
15/15 - 5s - loss: 0.2205 - lwlrap: 0.6568 - val_loss: 0.0908 - val_lwlrap: 0.7692
Epoch 10/100
15/15 - 5s - loss: 0.1180 - lwlrap: 0.6799 - val_loss: 0.0765 - val_lwlrap: 0.8344
Epoch 11/100
15/15 - 5s - loss: 0.0745 - lwlrap: 0.7436 - val_loss: 0.0789 - val_lwlrap: 0.8118
Epoch 12/100
15/15 - 5s - loss: 0.1696 - lwlrap: 0.7349 - val_loss: 0.0755 - val_lwlrap: 0.8344
Epoch 13/100
15/15 - 5s - loss: 0.1480 - lwlrap: 0.7634 - val_loss: 0.0798 - val_lwlrap: 0.8280
Epoch 14/100
15/15 - 5s - loss: 0.1607 - lwlrap: 0.8001 - val_loss: 0.0799 - val_lwlrap: 0.8453
Epoch 15/100
15/15 - 5s - loss: 0.1598 - lwlrap: 0.7864 - val_loss: 0.0818 - val_lwlrap: 0.8578
Epoch 16/100
15/15 - 5s - loss: 0.0612 - lwlrap: 0.8530 - val_loss: 0.0719 - val_lwlrap: 0.8335
Epoch 17/100
15/15 - 5s - loss: 0.1471 - lwlrap: 0.8193 - val_loss: 0.0946 - val_lwlrap: 0.8062
Epoch 18/100
15/15 - 5s - loss: 0.1473 - lwlrap: 0.8273 - val_loss: 0.0769 - val_lwlrap: 0.8555
Epoch 19/100
15/15 - 5s - loss: 0.1601 - lwlrap: 0.8432 - val_loss: 0.0666 - val_lwlrap: 0.8497
Epoch 20/100
15/15 - 5s - loss: 0.0480 - lwlrap: 0.8899 - val_loss: 0.0680 - val_lwlrap: 0.8682
Epoch 21/100
15/15 - 5s - loss: 0.0485 - lwlrap: 0.8899 - val_loss: 0.0707 - val_lwlrap: 0.8577
Epoch 22/100
15/15 - 5s - loss: 0.1529 - lwlrap: 0.8672 - val_loss: 0.0652 - val_lwlrap: 0.8526
Epoch 23/100
15/15 - 5s - loss: 0.1399 - lwlrap: 0.8576 - val_loss: 0.0713 - val_lwlrap: 0.8734
Epoch 24/100
15/15 - 5s - loss: 0.1193 - lwlrap: 0.8628 - val_loss: 0.0767 - val_lwlrap: 0.8466
Epoch 25/100
15/15 - 5s - loss: 0.0498 - lwlrap: 0.8975 - val_loss: 0.0824 - val_lwlrap: 0.8533
Epoch 26/100
15/15 - 5s - loss: 0.0493 - lwlrap: 0.8996 - val_loss: 0.0796 - val_lwlrap: 0.8514
Epoch 27/100
15/15 - 5s - loss: 0.1086 - lwlrap: 0.8867 - val_loss: 0.0755 - val_lwlrap: 0.8551
Epoch 28/100
15/15 - 5s - loss: 0.0420 - lwlrap: 0.9419 - val_loss: 0.0748 - val_lwlrap: 0.8466
Epoch 29/100
15/15 - 5s - loss: 0.0430 - lwlrap: 0.9126 - val_loss: 0.0728 - val_lwlrap: 0.8448
Epoch 30/100
15/15 - 5s - loss: 0.1208 - lwlrap: 0.8812 - val_loss: 0.0656 - val_lwlrap: 0.8528
Epoch 31/100
15/15 - 5s - loss: 0.0358 - lwlrap: 0.9125 - val_loss: 0.0777 - val_lwlrap: 0.8425
Epoch 32/100
15/15 - 5s - loss: 0.1148 - lwlrap: 0.9133 - val_loss: 0.0724 - val_lwlrap: 0.8590
Epoch 33/100
15/15 - 5s - loss: 0.1096 - lwlrap: 0.8953 - val_loss: 0.0823 - val_lwlrap: 0.8385
Epoch 34/100
15/15 - 5s - loss: 0.0395 - lwlrap: 0.9232 - val_loss: 0.0822 - val_lwlrap: 0.8495
Epoch 35/100
15/15 - 5s - loss: 0.0273 - lwlrap: 0.9358 - val_loss: 0.0822 - val_lwlrap: 0.8572
Epoch 36/100
15/15 - 5s - loss: 0.1022 - lwlrap: 0.9339 - val_loss: 0.0774 - val_lwlrap: 0.8505
Epoch 37/100
15/15 - 5s - loss: 0.1008 - lwlrap: 0.9239 - val_loss: 0.0783 - val_lwlrap: 0.8359
Epoch 38/100
15/15 - 5s - loss: 0.0944 - lwlrap: 0.9223 - val_loss: 0.0836 - val_lwlrap: 0.8473
Epoch 39/100
15/15 - 5s - loss: 0.0283 - lwlrap: 0.9199 - val_loss: 0.0853 - val_lwlrap: 0.8360
Epoch 40/100
15/15 - 5s - loss: 0.0983 - lwlrap: 0.9355 - val_loss: 0.0895 - val_lwlrap: 0.8307
Epoch 41/100
15/15 - 5s - loss: 0.0298 - lwlrap: 0.9333 - val_loss: 0.0720 - val_lwlrap: 0.8530
Epoch 42/100
15/15 - 5s - loss: 0.0306 - lwlrap: 0.9373 - val_loss: 0.0790 - val_lwlrap: 0.8405
Epoch 43/100
15/15 - 5s - loss: 0.0340 - lwlrap: 0.9433 - val_loss: 0.0792 - val_lwlrap: 0.8374
Epoch 44/100
15/15 - 5s - loss: 0.0315 - lwlrap: 0.9437 - val_loss: 0.0795 - val_lwlrap: 0.8457
Epoch 45/100
15/15 - 5s - loss: 0.0815 - lwlrap: 0.9457 - val_loss: 0.0781 - val_lwlrap: 0.8366
Epoch 46/100
15/15 - 5s - loss: 0.0867 - lwlrap: 0.9411 - val_loss: 0.0775 - val_lwlrap: 0.8537
Epoch 47/100
15/15 - 5s - loss: 0.0280 - lwlrap: 0.9504 - val_loss: 0.0967 - val_lwlrap: 0.8543
Epoch 48/100
15/15 - 5s - loss: 0.0338 - lwlrap: 0.9582 - val_loss: 0.0850 - val_lwlrap: 0.8438
Epoch 49/100
15/15 - 5s - loss: 0.0242 - lwlrap: 0.9598 - val_loss: 0.0811 - val_lwlrap: 0.8331
Epoch 50/100
15/15 - 5s - loss: 0.0697 - lwlrap: 0.9507 - val_loss: 0.0867 - val_lwlrap: 0.8373
Epoch 51/100
15/15 - 5s - loss: 0.0228 - lwlrap: 0.9581 - val_loss: 0.0754 - val_lwlrap: 0.8495
Epoch 52/100
15/15 - 5s - loss: 0.0245 - lwlrap: 0.9732 - val_loss: 0.0787 - val_lwlrap: 0.8540
Epoch 53/100
15/15 - 5s - loss: 0.0950 - lwlrap: 0.9499 - val_loss: 0.0807 - val_lwlrap: 0.8524
Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)
Requirement already satisfied: iterative-stratification in /usr/local/lib/python3.6/dist-packages (0.1.6)
Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.6/dist-packages (0.12.0)
Requirement already satisfied: nlpaug==0.0.20 in /usr/local/lib/python3.6/dist-packages (0.0.20)
Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.56.0)
Collecting click
  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
[?25l[K     |â–ˆâ–ˆâ–ˆâ–ˆ                            | 10 kB 43.4 MB/s eta 0:00:01[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 20 kB 47.4 MB/s eta 0:00:01[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 30 kB 23.4 MB/s eta 0:00:01[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 40 kB 18.6 MB/s eta 0:00:01[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 51 kB 19.5 MB/s eta 0:00:01[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 61 kB 16.2 MB/s eta 0:00:01[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 71 kB 15.8 MB/s eta 0:00:01[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 81 kB 15.9 MB/s eta 0:00:01[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82 kB 999 kB/s 
[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)
Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)
Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2020.5)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (0.24.1)
Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.5.4)
Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow_addons) (2.10.0)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)
Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->iterative-stratification) (1.0.0)
Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->iterative-stratification) (2.1.0)
Installing collected packages: click
Successfully installed click-7.1.2
[33mWARNING: You are using pip version 20.2.4; however, version 21.0 is available.
You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.[0m
