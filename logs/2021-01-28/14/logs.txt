
-------------   Fold 1 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-28/1/pretrained_best_fold0.h5

 -> Training Model 

Epoch 1/60
60/60 - 11s - loss: 0.2669 - lwlrap: 0.3813 - val_loss: 0.1718 - val_lwlrap: 0.5215
Epoch 2/60
60/60 - 9s - loss: 0.1550 - lwlrap: 0.7123 - val_loss: 0.1806 - val_lwlrap: 0.6757
Epoch 3/60
60/60 - 10s - loss: 0.1077 - lwlrap: 0.8369 - val_loss: 0.1715 - val_lwlrap: 0.7365
Epoch 4/60
60/60 - 9s - loss: 0.1353 - lwlrap: 0.8949 - val_loss: 0.1883 - val_lwlrap: 0.7308
Epoch 5/60
60/60 - 10s - loss: 0.0578 - lwlrap: 0.9117 - val_loss: 0.1720 - val_lwlrap: 0.7626
Epoch 6/60
60/60 - 9s - loss: 0.0425 - lwlrap: 0.9029 - val_loss: 0.1279 - val_lwlrap: 0.7539
Epoch 7/60
60/60 - 9s - loss: 0.0677 - lwlrap: 0.9087 - val_loss: 0.1854 - val_lwlrap: 0.7705
Epoch 8/60
60/60 - 9s - loss: 0.0186 - lwlrap: 0.9553 - val_loss: 0.1158 - val_lwlrap: 0.7975
Epoch 9/60
60/60 - 10s - loss: 0.0163 - lwlrap: 0.9772 - val_loss: 0.1815 - val_lwlrap: 0.8295
Epoch 10/60
60/60 - 9s - loss: 0.0202 - lwlrap: 0.9876 - val_loss: 0.2151 - val_lwlrap: 0.8469
Epoch 11/60
60/60 - 9s - loss: 0.0139 - lwlrap: 0.9914 - val_loss: 0.2124 - val_lwlrap: 0.8379
Epoch 12/60
60/60 - 9s - loss: 0.0070 - lwlrap: 0.9903 - val_loss: 0.1514 - val_lwlrap: 0.8454
Epoch 13/60
60/60 - 9s - loss: 0.0030 - lwlrap: 0.9948 - val_loss: 0.0209 - val_lwlrap: 0.8380
Epoch 14/60
60/60 - 9s - loss: 0.0205 - lwlrap: 0.9913 - val_loss: 0.0751 - val_lwlrap: 0.8415
Epoch 15/60
60/60 - 9s - loss: 0.0121 - lwlrap: 0.9814 - val_loss: 0.2037 - val_lwlrap: 0.8124
Epoch 16/60
60/60 - 9s - loss: 0.0140 - lwlrap: 0.9894 - val_loss: 0.1154 - val_lwlrap: 0.8271
Epoch 17/60
60/60 - 9s - loss: 0.0136 - lwlrap: 0.9932 - val_loss: 0.2190 - val_lwlrap: 0.8349
Epoch 18/60
60/60 - 9s - loss: 0.0099 - lwlrap: 0.9944 - val_loss: 0.3280 - val_lwlrap: 0.8211
Epoch 19/60
60/60 - 9s - loss: 0.0212 - lwlrap: 0.9977 - val_loss: 0.2321 - val_lwlrap: 0.8346
Epoch 20/60
60/60 - 10s - loss: 0.0051 - lwlrap: 0.9982 - val_loss: 0.2115 - val_lwlrap: 0.8750
Epoch 21/60
60/60 - 9s - loss: 0.0242 - lwlrap: 0.9985 - val_loss: 0.1442 - val_lwlrap: 0.8550
Epoch 22/60
60/60 - 9s - loss: 0.0048 - lwlrap: 0.9983 - val_loss: 0.1645 - val_lwlrap: 0.8372
Epoch 23/60
60/60 - 9s - loss: 0.0045 - lwlrap: 0.9976 - val_loss: 0.1275 - val_lwlrap: 0.8405
Epoch 24/60
60/60 - 9s - loss: 0.0023 - lwlrap: 0.9991 - val_loss: 0.1532 - val_lwlrap: 0.8426
Epoch 25/60
60/60 - 9s - loss: 0.0023 - lwlrap: 0.9991 - val_loss: 0.2868 - val_lwlrap: 0.8315
Epoch 26/60
60/60 - 9s - loss: 0.0253 - lwlrap: 0.9934 - val_loss: 0.1638 - val_lwlrap: 0.8381
Epoch 27/60
60/60 - 9s - loss: 0.0030 - lwlrap: 0.9958 - val_loss: 0.1552 - val_lwlrap: 0.8402
Epoch 28/60
60/60 - 9s - loss: 0.0144 - lwlrap: 0.9985 - val_loss: 0.2940 - val_lwlrap: 0.8530
Epoch 29/60
60/60 - 9s - loss: 9.9311e-04 - lwlrap: 0.9961 - val_loss: 0.2042 - val_lwlrap: 0.8217
Epoch 30/60
60/60 - 9s - loss: 7.1057e-04 - lwlrap: 0.9975 - val_loss: 0.1837 - val_lwlrap: 0.8448
Epoch 31/60
60/60 - 9s - loss: 0.0011 - lwlrap: 0.9985 - val_loss: 0.1505 - val_lwlrap: 0.8434
Epoch 32/60
60/60 - 9s - loss: 7.1419e-04 - lwlrap: 0.9991 - val_loss: 0.1732 - val_lwlrap: 0.8454
Epoch 33/60
60/60 - 9s - loss: 0.0066 - lwlrap: 0.9985 - val_loss: 0.1529 - val_lwlrap: 0.8551
Epoch 34/60
60/60 - 9s - loss: 0.0011 - lwlrap: 0.9995 - val_loss: 0.3155 - val_lwlrap: 0.8272
Epoch 35/60
60/60 - 9s - loss: 4.4640e-04 - lwlrap: 0.9979 - val_loss: 0.2165 - val_lwlrap: 0.8471
Epoch 36/60
60/60 - 9s - loss: 0.0014 - lwlrap: 0.9984 - val_loss: 0.3751 - val_lwlrap: 0.8367
Epoch 37/60
60/60 - 9s - loss: 0.0025 - lwlrap: 0.9970 - val_loss: 0.3409 - val_lwlrap: 0.8203
Epoch 38/60
60/60 - 9s - loss: 4.4493e-04 - lwlrap: 0.9980 - val_loss: 0.2336 - val_lwlrap: 0.8487
Epoch 39/60
60/60 - 9s - loss: 7.9475e-04 - lwlrap: 0.9981 - val_loss: 0.1202 - val_lwlrap: 0.8396
Epoch 40/60
60/60 - 9s - loss: 0.0072 - lwlrap: 0.9988 - val_loss: 0.0551 - val_lwlrap: 0.8469

-------------   Fold 2 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-28/1/pretrained_best_fold1.h5

 -> Training Model 

Epoch 1/60
60/60 - 11s - loss: 0.1836 - lwlrap: 0.4878 - val_loss: 0.1290 - val_lwlrap: 0.6806
Epoch 2/60
60/60 - 9s - loss: 0.0543 - lwlrap: 0.9005 - val_loss: 0.0637 - val_lwlrap: 0.8099
Epoch 3/60
60/60 - 9s - loss: 0.0880 - lwlrap: 0.9195 - val_loss: 0.1138 - val_lwlrap: 0.7828
Epoch 4/60
60/60 - 9s - loss: 0.0523 - lwlrap: 0.9111 - val_loss: 0.0964 - val_lwlrap: 0.7963
Epoch 5/60
60/60 - 9s - loss: 0.0404 - lwlrap: 0.9132 - val_loss: 0.1120 - val_lwlrap: 0.7354
Epoch 6/60
60/60 - 9s - loss: 0.0792 - lwlrap: 0.9191 - val_loss: 0.0581 - val_lwlrap: 0.8109
Epoch 7/60
60/60 - 9s - loss: 0.0384 - lwlrap: 0.9358 - val_loss: 0.1112 - val_lwlrap: 0.8617
Epoch 8/60
60/60 - 10s - loss: 0.0242 - lwlrap: 0.9702 - val_loss: 0.0472 - val_lwlrap: 0.8700
Epoch 9/60
60/60 - 10s - loss: 0.0241 - lwlrap: 0.9797 - val_loss: 0.0719 - val_lwlrap: 0.8729
Epoch 10/60
60/60 - 9s - loss: 0.0042 - lwlrap: 0.9897 - val_loss: 0.0749 - val_lwlrap: 0.8855
Epoch 11/60
60/60 - 9s - loss: 0.0084 - lwlrap: 0.9904 - val_loss: 0.0887 - val_lwlrap: 0.8861
Epoch 12/60
60/60 - 9s - loss: 0.0092 - lwlrap: 0.9925 - val_loss: 0.0656 - val_lwlrap: 0.8997
Epoch 13/60
60/60 - 9s - loss: 0.0107 - lwlrap: 0.9952 - val_loss: 0.0687 - val_lwlrap: 0.8850
Epoch 14/60
60/60 - 9s - loss: 0.0276 - lwlrap: 0.9919 - val_loss: 0.0542 - val_lwlrap: 0.8819
Epoch 15/60
60/60 - 9s - loss: 0.0851 - lwlrap: 0.9893 - val_loss: 0.0831 - val_lwlrap: 0.8532
Epoch 16/60
60/60 - 9s - loss: 0.0119 - lwlrap: 0.9868 - val_loss: 0.1341 - val_lwlrap: 0.8678
Epoch 17/60
60/60 - 9s - loss: 0.0044 - lwlrap: 0.9900 - val_loss: 0.0789 - val_lwlrap: 0.8814
Epoch 18/60
60/60 - 9s - loss: 0.0029 - lwlrap: 0.9965 - val_loss: 0.0677 - val_lwlrap: 0.8949
Epoch 19/60
60/60 - 9s - loss: 0.0101 - lwlrap: 0.9932 - val_loss: 0.0404 - val_lwlrap: 0.8819
Epoch 20/60
60/60 - 9s - loss: 0.0040 - lwlrap: 0.9957 - val_loss: 0.0397 - val_lwlrap: 0.8815
Epoch 21/60
60/60 - 9s - loss: 0.0145 - lwlrap: 0.9975 - val_loss: 0.0730 - val_lwlrap: 0.8915
Epoch 22/60
60/60 - 9s - loss: 0.0010 - lwlrap: 0.9984 - val_loss: 0.0724 - val_lwlrap: 0.8834
Epoch 23/60
60/60 - 9s - loss: 0.0059 - lwlrap: 0.9982 - val_loss: 0.0848 - val_lwlrap: 0.8810
Epoch 24/60
60/60 - 9s - loss: 0.0093 - lwlrap: 0.9976 - val_loss: 0.0976 - val_lwlrap: 0.8724
Epoch 25/60
60/60 - 9s - loss: 0.0358 - lwlrap: 0.9987 - val_loss: 0.0487 - val_lwlrap: 0.8669
Epoch 26/60
60/60 - 9s - loss: 0.0013 - lwlrap: 0.9966 - val_loss: 0.1491 - val_lwlrap: 0.8742
Epoch 27/60
60/60 - 9s - loss: 0.0049 - lwlrap: 0.9983 - val_loss: 0.0437 - val_lwlrap: 0.8932
Epoch 28/60
60/60 - 9s - loss: 0.0023 - lwlrap: 0.9981 - val_loss: 0.0372 - val_lwlrap: 0.8798
Epoch 29/60
60/60 - 9s - loss: 0.0015 - lwlrap: 0.9978 - val_loss: 0.0579 - val_lwlrap: 0.8836
Epoch 30/60
60/60 - 9s - loss: 0.0021 - lwlrap: 1.0000 - val_loss: 0.0810 - val_lwlrap: 0.8715
Epoch 31/60
60/60 - 9s - loss: 0.0013 - lwlrap: 0.9979 - val_loss: 0.1007 - val_lwlrap: 0.8681
Epoch 32/60
60/60 - 9s - loss: 0.0039 - lwlrap: 0.9986 - val_loss: 0.1211 - val_lwlrap: 0.8817

-------------   Fold 3 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-28/1/pretrained_best_fold2.h5

 -> Training Model 

Epoch 1/60
60/60 - 11s - loss: 0.1070 - lwlrap: 0.4848 - val_loss: 0.1100 - val_lwlrap: 0.6615
Epoch 2/60
60/60 - 9s - loss: 0.0808 - lwlrap: 0.9000 - val_loss: 0.0840 - val_lwlrap: 0.8048
Epoch 3/60
60/60 - 9s - loss: 0.0547 - lwlrap: 0.9130 - val_loss: 0.0774 - val_lwlrap: 0.7696
Epoch 4/60
60/60 - 9s - loss: 0.0645 - lwlrap: 0.9113 - val_loss: 0.0867 - val_lwlrap: 0.7526
Epoch 5/60
60/60 - 9s - loss: 0.0650 - lwlrap: 0.9164 - val_loss: 0.0490 - val_lwlrap: 0.7774
Epoch 6/60
60/60 - 9s - loss: 0.0511 - lwlrap: 0.9317 - val_loss: 0.0611 - val_lwlrap: 0.7840
Epoch 7/60
60/60 - 9s - loss: 0.0229 - lwlrap: 0.9618 - val_loss: 0.0269 - val_lwlrap: 0.8101
Epoch 8/60
60/60 - 9s - loss: 0.0227 - lwlrap: 0.9839 - val_loss: 0.0504 - val_lwlrap: 0.8241
Epoch 9/60
60/60 - 9s - loss: 0.0155 - lwlrap: 0.9858 - val_loss: 0.0375 - val_lwlrap: 0.8305
Epoch 10/60
60/60 - 9s - loss: 0.0027 - lwlrap: 0.9949 - val_loss: 0.0283 - val_lwlrap: 0.8340
Epoch 11/60
60/60 - 10s - loss: 0.0023 - lwlrap: 0.9914 - val_loss: 0.0253 - val_lwlrap: 0.8456
Epoch 12/60
60/60 - 9s - loss: 0.0058 - lwlrap: 0.9963 - val_loss: 0.0314 - val_lwlrap: 0.8447
Epoch 13/60
60/60 - 9s - loss: 0.0293 - lwlrap: 0.9931 - val_loss: 0.0430 - val_lwlrap: 0.8098
Epoch 14/60
60/60 - 9s - loss: 0.0039 - lwlrap: 0.9948 - val_loss: 0.0244 - val_lwlrap: 0.7923
Epoch 15/60
60/60 - 9s - loss: 0.0170 - lwlrap: 0.9890 - val_loss: 0.0327 - val_lwlrap: 0.7675
Epoch 16/60
60/60 - 9s - loss: 0.0210 - lwlrap: 0.9913 - val_loss: 0.0541 - val_lwlrap: 0.7901
Epoch 17/60
60/60 - 9s - loss: 0.0315 - lwlrap: 0.9852 - val_loss: 0.0084 - val_lwlrap: 0.8113
Epoch 18/60
60/60 - 9s - loss: 0.0191 - lwlrap: 0.9948 - val_loss: 0.0430 - val_lwlrap: 0.8270
Epoch 19/60
60/60 - 9s - loss: 0.0020 - lwlrap: 0.9963 - val_loss: 0.0541 - val_lwlrap: 0.8259
Epoch 20/60
60/60 - 10s - loss: 0.0034 - lwlrap: 0.9979 - val_loss: 0.0714 - val_lwlrap: 0.8507
Epoch 21/60
60/60 - 9s - loss: 0.0032 - lwlrap: 0.9971 - val_loss: 0.0537 - val_lwlrap: 0.8456
Epoch 22/60
60/60 - 9s - loss: 0.0038 - lwlrap: 0.9993 - val_loss: 0.0129 - val_lwlrap: 0.8402
Epoch 23/60
60/60 - 9s - loss: 0.0024 - lwlrap: 0.9984 - val_loss: 0.0102 - val_lwlrap: 0.8227
Epoch 24/60
60/60 - 9s - loss: 0.0073 - lwlrap: 0.9990 - val_loss: 0.0506 - val_lwlrap: 0.8328
Epoch 25/60
60/60 - 9s - loss: 0.0201 - lwlrap: 0.9985 - val_loss: 0.0581 - val_lwlrap: 0.8212
Epoch 26/60
60/60 - 9s - loss: 0.0134 - lwlrap: 0.9956 - val_loss: 0.0565 - val_lwlrap: 0.8110
Epoch 27/60
60/60 - 9s - loss: 0.0019 - lwlrap: 0.9972 - val_loss: 0.0432 - val_lwlrap: 0.8381
Epoch 28/60
60/60 - 9s - loss: 0.0094 - lwlrap: 0.9974 - val_loss: 0.0447 - val_lwlrap: 0.8217
Epoch 29/60
60/60 - 9s - loss: 0.0022 - lwlrap: 0.9988 - val_loss: 0.0333 - val_lwlrap: 0.8277
Epoch 30/60
60/60 - 9s - loss: 0.0174 - lwlrap: 0.9959 - val_loss: 0.0386 - val_lwlrap: 0.8259
Epoch 31/60
60/60 - 9s - loss: 2.1256e-04 - lwlrap: 0.9979 - val_loss: 0.0333 - val_lwlrap: 0.8325
Epoch 32/60
60/60 - 9s - loss: 0.0079 - lwlrap: 0.9981 - val_loss: 0.0419 - val_lwlrap: 0.8263
Epoch 33/60
60/60 - 9s - loss: 8.4943e-04 - lwlrap: 0.9974 - val_loss: 0.0465 - val_lwlrap: 0.8321
Epoch 34/60
60/60 - 9s - loss: 7.2115e-04 - lwlrap: 0.9998 - val_loss: 0.0555 - val_lwlrap: 0.8346
Epoch 35/60
60/60 - 9s - loss: 0.0011 - lwlrap: 0.9977 - val_loss: 0.0373 - val_lwlrap: 0.8252
Epoch 36/60
60/60 - 9s - loss: 2.6839e-04 - lwlrap: 0.9990 - val_loss: 0.0777 - val_lwlrap: 0.8209
Epoch 37/60
60/60 - 9s - loss: 7.3841e-04 - lwlrap: 0.9992 - val_loss: 0.0496 - val_lwlrap: 0.8602
Epoch 38/60
60/60 - 9s - loss: 0.0014 - lwlrap: 0.9997 - val_loss: 0.0350 - val_lwlrap: 0.8258
Epoch 39/60
60/60 - 9s - loss: 3.9033e-04 - lwlrap: 0.9987 - val_loss: 0.0720 - val_lwlrap: 0.8302
Epoch 40/60
60/60 - 9s - loss: 0.0057 - lwlrap: 0.9982 - val_loss: 0.0672 - val_lwlrap: 0.8366
Epoch 41/60
60/60 - 9s - loss: 1.8190e-04 - lwlrap: 0.9996 - val_loss: 0.0472 - val_lwlrap: 0.8417
Epoch 42/60
60/60 - 9s - loss: 9.4100e-04 - lwlrap: 0.9979 - val_loss: 0.0235 - val_lwlrap: 0.8244
Epoch 43/60
60/60 - 9s - loss: 0.0030 - lwlrap: 0.9994 - val_loss: 0.0155 - val_lwlrap: 0.8278
Epoch 44/60
60/60 - 9s - loss: 0.0014 - lwlrap: 0.9991 - val_loss: 0.0577 - val_lwlrap: 0.8263
Epoch 45/60
60/60 - 9s - loss: 3.9299e-04 - lwlrap: 1.0000 - val_loss: 0.0222 - val_lwlrap: 0.8283
Epoch 46/60
60/60 - 9s - loss: 0.0045 - lwlrap: 0.9994 - val_loss: 0.0384 - val_lwlrap: 0.8375
Epoch 47/60
60/60 - 9s - loss: 2.0885e-04 - lwlrap: 0.9982 - val_loss: 0.0238 - val_lwlrap: 0.8196
Epoch 48/60
60/60 - 9s - loss: 0.0119 - lwlrap: 0.9986 - val_loss: 0.0051 - val_lwlrap: 0.8270
Epoch 49/60
60/60 - 9s - loss: 4.0031e-04 - lwlrap: 0.9996 - val_loss: 0.0112 - val_lwlrap: 0.8400
Epoch 50/60
60/60 - 9s - loss: 7.4738e-04 - lwlrap: 1.0000 - val_loss: 0.0064 - val_lwlrap: 0.8393
Epoch 51/60
60/60 - 9s - loss: 0.0015 - lwlrap: 0.9992 - val_loss: 0.0443 - val_lwlrap: 0.8350
Epoch 52/60
60/60 - 9s - loss: 0.0069 - lwlrap: 0.9995 - val_loss: 0.0120 - val_lwlrap: 0.8307
Epoch 53/60
60/60 - 9s - loss: 0.0019 - lwlrap: 0.9990 - val_loss: 0.0461 - val_lwlrap: 0.8235
Epoch 54/60
60/60 - 9s - loss: 4.5747e-04 - lwlrap: 0.9986 - val_loss: 0.0435 - val_lwlrap: 0.8280
Epoch 55/60
60/60 - 9s - loss: 0.0013 - lwlrap: 0.9977 - val_loss: 0.0520 - val_lwlrap: 0.8336
Epoch 56/60
60/60 - 9s - loss: 0.0196 - lwlrap: 0.9992 - val_loss: 0.0047 - val_lwlrap: 0.8414
Epoch 57/60
60/60 - 9s - loss: 4.2595e-04 - lwlrap: 0.9980 - val_loss: 0.0181 - val_lwlrap: 0.8287

-------------   Fold 4 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-28/1/pretrained_best_fold3.h5

 -> Training Model 

Epoch 1/60
60/60 - 11s - loss: 0.1637 - lwlrap: 0.5345 - val_loss: 0.1778 - val_lwlrap: 0.7221
Epoch 2/60
60/60 - 10s - loss: 0.0859 - lwlrap: 0.8952 - val_loss: 0.1716 - val_lwlrap: 0.7958
Epoch 3/60
60/60 - 10s - loss: 0.0744 - lwlrap: 0.9264 - val_loss: 0.1620 - val_lwlrap: 0.7877
Epoch 4/60
60/60 - 10s - loss: 0.1004 - lwlrap: 0.9059 - val_loss: 0.1629 - val_lwlrap: 0.7966
Epoch 5/60
60/60 - 10s - loss: 0.1000 - lwlrap: 0.9242 - val_loss: 0.2090 - val_lwlrap: 0.7822
Epoch 6/60
60/60 - 10s - loss: 0.0755 - lwlrap: 0.9442 - val_loss: 0.1435 - val_lwlrap: 0.8158
Epoch 7/60
60/60 - 10s - loss: 0.0088 - lwlrap: 0.9635 - val_loss: 0.1362 - val_lwlrap: 0.8214
Epoch 8/60
60/60 - 10s - loss: 0.0822 - lwlrap: 0.9691 - val_loss: 0.1844 - val_lwlrap: 0.8603
Epoch 9/60
60/60 - 10s - loss: 0.0100 - lwlrap: 0.9818 - val_loss: 0.1288 - val_lwlrap: 0.8619
Epoch 10/60
60/60 - 10s - loss: 0.0077 - lwlrap: 0.9915 - val_loss: 0.0331 - val_lwlrap: 0.8579
Epoch 11/60
60/60 - 10s - loss: 0.0162 - lwlrap: 0.9907 - val_loss: 0.1014 - val_lwlrap: 0.8630
Epoch 12/60
60/60 - 10s - loss: 0.0224 - lwlrap: 0.9961 - val_loss: 0.1588 - val_lwlrap: 0.8732
Epoch 13/60
60/60 - 10s - loss: 0.0523 - lwlrap: 0.9944 - val_loss: 0.2974 - val_lwlrap: 0.8517
Epoch 14/60
60/60 - 10s - loss: 0.0120 - lwlrap: 0.9934 - val_loss: 0.3621 - val_lwlrap: 0.8446
Epoch 15/60
60/60 - 10s - loss: 0.0113 - lwlrap: 0.9960 - val_loss: 0.2691 - val_lwlrap: 0.8693
Epoch 16/60
60/60 - 10s - loss: 0.0237 - lwlrap: 0.9907 - val_loss: 0.2557 - val_lwlrap: 0.8754
Epoch 17/60
60/60 - 10s - loss: 0.0035 - lwlrap: 0.9927 - val_loss: 0.3517 - val_lwlrap: 0.8574
Epoch 18/60
60/60 - 10s - loss: 0.0044 - lwlrap: 0.9958 - val_loss: 0.3127 - val_lwlrap: 0.8738
Epoch 19/60
60/60 - 10s - loss: 0.0050 - lwlrap: 0.9970 - val_loss: 0.2852 - val_lwlrap: 0.8686
Epoch 20/60
60/60 - 10s - loss: 0.0012 - lwlrap: 0.9978 - val_loss: 0.1951 - val_lwlrap: 0.8704
Epoch 21/60
60/60 - 10s - loss: 0.0071 - lwlrap: 0.9986 - val_loss: 0.1918 - val_lwlrap: 0.8721
Epoch 22/60
60/60 - 10s - loss: 0.0026 - lwlrap: 0.9994 - val_loss: 0.2822 - val_lwlrap: 0.8641
Epoch 23/60
60/60 - 10s - loss: 0.0018 - lwlrap: 0.9967 - val_loss: 0.3105 - val_lwlrap: 0.8497
Epoch 24/60
60/60 - 10s - loss: 0.0135 - lwlrap: 0.9963 - val_loss: 0.3238 - val_lwlrap: 0.8571
Epoch 25/60
60/60 - 10s - loss: 8.2640e-04 - lwlrap: 0.9982 - val_loss: 0.3326 - val_lwlrap: 0.8684
Epoch 26/60
60/60 - 10s - loss: 0.0043 - lwlrap: 0.9993 - val_loss: 0.3314 - val_lwlrap: 0.8707
Epoch 27/60
60/60 - 10s - loss: 0.0012 - lwlrap: 0.9979 - val_loss: 0.3081 - val_lwlrap: 0.8668
Epoch 28/60
60/60 - 10s - loss: 0.0377 - lwlrap: 0.9948 - val_loss: 0.2667 - val_lwlrap: 0.8562
Epoch 29/60
60/60 - 10s - loss: 0.0012 - lwlrap: 0.9993 - val_loss: 0.2198 - val_lwlrap: 0.8658
Epoch 30/60
60/60 - 10s - loss: 2.4148e-04 - lwlrap: 0.9991 - val_loss: 0.1995 - val_lwlrap: 0.8544
Epoch 31/60
60/60 - 10s - loss: 5.4928e-04 - lwlrap: 0.9992 - val_loss: 0.2436 - val_lwlrap: 0.8766
Epoch 32/60
60/60 - 10s - loss: 0.0023 - lwlrap: 0.9985 - val_loss: 0.1630 - val_lwlrap: 0.8562
Epoch 33/60
60/60 - 10s - loss: 0.0039 - lwlrap: 0.9985 - val_loss: 0.2958 - val_lwlrap: 0.8494
Epoch 34/60
60/60 - 10s - loss: 0.0264 - lwlrap: 0.9988 - val_loss: 0.1857 - val_lwlrap: 0.8650
Epoch 35/60
60/60 - 10s - loss: 0.0098 - lwlrap: 0.9981 - val_loss: 0.2765 - val_lwlrap: 0.8649
Epoch 36/60
60/60 - 10s - loss: 4.0972e-04 - lwlrap: 0.9996 - val_loss: 0.3979 - val_lwlrap: 0.8475
Epoch 37/60
60/60 - 10s - loss: 7.4046e-04 - lwlrap: 0.9987 - val_loss: 0.2818 - val_lwlrap: 0.8553
Epoch 38/60
60/60 - 10s - loss: 4.6615e-04 - lwlrap: 0.9989 - val_loss: 0.2041 - val_lwlrap: 0.8599
Epoch 39/60
60/60 - 10s - loss: 4.8716e-04 - lwlrap: 0.9979 - val_loss: 0.3129 - val_lwlrap: 0.8770
Epoch 40/60
60/60 - 10s - loss: 0.0031 - lwlrap: 0.9998 - val_loss: 0.1837 - val_lwlrap: 0.8680
Epoch 41/60
60/60 - 10s - loss: 3.0005e-04 - lwlrap: 0.9982 - val_loss: 0.2531 - val_lwlrap: 0.8560
Epoch 42/60
60/60 - 10s - loss: 5.8138e-04 - lwlrap: 0.9970 - val_loss: 0.2538 - val_lwlrap: 0.8428
Epoch 43/60
60/60 - 10s - loss: 0.0021 - lwlrap: 0.9988 - val_loss: 0.3646 - val_lwlrap: 0.8532
Epoch 44/60
60/60 - 10s - loss: 0.0091 - lwlrap: 1.0000 - val_loss: 0.3598 - val_lwlrap: 0.8484
Epoch 45/60
60/60 - 10s - loss: 3.9671e-04 - lwlrap: 0.9987 - val_loss: 0.3780 - val_lwlrap: 0.8428
Epoch 46/60
60/60 - 10s - loss: 6.5921e-04 - lwlrap: 0.9978 - val_loss: 0.2807 - val_lwlrap: 0.8583
Epoch 47/60
60/60 - 10s - loss: 2.5881e-04 - lwlrap: 0.9982 - val_loss: 0.4128 - val_lwlrap: 0.8513
Epoch 48/60
60/60 - 10s - loss: 9.6001e-04 - lwlrap: 0.9983 - val_loss: 0.3995 - val_lwlrap: 0.8625
Epoch 49/60
60/60 - 10s - loss: 5.8796e-04 - lwlrap: 1.0000 - val_loss: 0.3139 - val_lwlrap: 0.8456
Epoch 50/60
60/60 - 10s - loss: 0.0100 - lwlrap: 0.9995 - val_loss: 0.2925 - val_lwlrap: 0.8502
Epoch 51/60
60/60 - 10s - loss: 6.9034e-04 - lwlrap: 0.9986 - val_loss: 0.3741 - val_lwlrap: 0.8562
Epoch 52/60
60/60 - 10s - loss: 0.0011 - lwlrap: 0.9973 - val_loss: 0.4029 - val_lwlrap: 0.8471
Epoch 53/60
60/60 - 10s - loss: 0.0018 - lwlrap: 1.0000 - val_loss: 0.3897 - val_lwlrap: 0.8556
Epoch 54/60
60/60 - 10s - loss: 7.8334e-04 - lwlrap: 0.9994 - val_loss: 0.3018 - val_lwlrap: 0.8694
Epoch 55/60
60/60 - 10s - loss: 5.3006e-04 - lwlrap: 0.9985 - val_loss: 0.3702 - val_lwlrap: 0.8677
Epoch 56/60
60/60 - 10s - loss: 0.0029 - lwlrap: 0.9979 - val_loss: 0.3711 - val_lwlrap: 0.8705
Epoch 57/60
60/60 - 10s - loss: 3.8019e-04 - lwlrap: 0.9988 - val_loss: 0.3629 - val_lwlrap: 0.8521
Epoch 58/60
60/60 - 10s - loss: 4.4209e-04 - lwlrap: 0.9995 - val_loss: 0.3684 - val_lwlrap: 0.8509
Epoch 59/60
60/60 - 10s - loss: 0.0014 - lwlrap: 0.9996 - val_loss: 0.3596 - val_lwlrap: 0.8579

-------------   Fold 5 / 5  -------------

 -> Preparing Data 

 -> Preparing Model 

 -> Loading weights from ../logs/2021-01-28/1/pretrained_best_fold4.h5

 -> Training Model 

Epoch 1/60
61/61 - 11s - loss: 0.1817 - lwlrap: 0.4862 - val_loss: 0.1231 - val_lwlrap: 0.6715
Epoch 2/60
61/61 - 10s - loss: 0.0807 - lwlrap: 0.8724 - val_loss: 0.1073 - val_lwlrap: 0.7538
Epoch 3/60
61/61 - 10s - loss: 0.0570 - lwlrap: 0.9238 - val_loss: 0.1045 - val_lwlrap: 0.8164
Epoch 4/60
61/61 - 9s - loss: 0.0805 - lwlrap: 0.8862 - val_loss: 0.0957 - val_lwlrap: 0.7103
Epoch 5/60
61/61 - 9s - loss: 0.0598 - lwlrap: 0.9089 - val_loss: 0.0952 - val_lwlrap: 0.7408
Epoch 6/60
61/61 - 10s - loss: 0.1050 - lwlrap: 0.9032 - val_loss: 0.0718 - val_lwlrap: 0.7753
Epoch 7/60
61/61 - 10s - loss: 0.0602 - lwlrap: 0.9566 - val_loss: 0.0652 - val_lwlrap: 0.8381
Epoch 8/60
61/61 - 10s - loss: 0.0244 - lwlrap: 0.9751 - val_loss: 0.0599 - val_lwlrap: 0.8385
Epoch 9/60
61/61 - 10s - loss: 0.0137 - lwlrap: 0.9793 - val_loss: 0.0518 - val_lwlrap: 0.8348
Epoch 10/60
61/61 - 10s - loss: 0.0098 - lwlrap: 0.9903 - val_loss: 0.0685 - val_lwlrap: 0.8559
Epoch 11/60
61/61 - 10s - loss: 0.0308 - lwlrap: 0.9885 - val_loss: 0.0601 - val_lwlrap: 0.8628
Epoch 12/60
61/61 - 10s - loss: 0.0158 - lwlrap: 0.9904 - val_loss: 0.1005 - val_lwlrap: 0.8554
Epoch 13/60
61/61 - 9s - loss: 0.0168 - lwlrap: 0.9904 - val_loss: 0.0790 - val_lwlrap: 0.8412
Epoch 14/60
61/61 - 10s - loss: 0.0483 - lwlrap: 0.9898 - val_loss: 0.0841 - val_lwlrap: 0.8320
Epoch 15/60
61/61 - 9s - loss: 0.0182 - lwlrap: 0.9872 - val_loss: 0.1197 - val_lwlrap: 0.8393
Epoch 16/60
61/61 - 9s - loss: 0.0224 - lwlrap: 0.9901 - val_loss: 0.0888 - val_lwlrap: 0.8492
Epoch 17/60
61/61 - 10s - loss: 0.0120 - lwlrap: 0.9913 - val_loss: 0.0971 - val_lwlrap: 0.8459
Epoch 18/60
61/61 - 9s - loss: 0.0167 - lwlrap: 0.9909 - val_loss: 0.0848 - val_lwlrap: 0.8338
Epoch 19/60
61/61 - 10s - loss: 0.0037 - lwlrap: 0.9985 - val_loss: 0.0993 - val_lwlrap: 0.8527
Epoch 20/60
61/61 - 10s - loss: 0.0026 - lwlrap: 0.9950 - val_loss: 0.0755 - val_lwlrap: 0.8478
Epoch 21/60
61/61 - 10s - loss: 0.0123 - lwlrap: 0.9955 - val_loss: 0.0827 - val_lwlrap: 0.8500
Epoch 22/60
61/61 - 9s - loss: 0.0108 - lwlrap: 0.9995 - val_loss: 0.0780 - val_lwlrap: 0.8536
Epoch 23/60
61/61 - 10s - loss: 0.0017 - lwlrap: 0.9994 - val_loss: 0.0889 - val_lwlrap: 0.8612
Epoch 24/60
61/61 - 10s - loss: 0.0057 - lwlrap: 0.9972 - val_loss: 0.1690 - val_lwlrap: 0.8499
Epoch 25/60
61/61 - 9s - loss: 0.0105 - lwlrap: 0.9969 - val_loss: 0.1714 - val_lwlrap: 0.8384
Epoch 26/60
61/61 - 9s - loss: 0.0086 - lwlrap: 0.9971 - val_loss: 0.1382 - val_lwlrap: 0.8517
Epoch 27/60
61/61 - 10s - loss: 0.0046 - lwlrap: 0.9987 - val_loss: 0.1551 - val_lwlrap: 0.8460
Epoch 28/60
61/61 - 9s - loss: 0.0036 - lwlrap: 0.9991 - val_loss: 0.1461 - val_lwlrap: 0.8557
Epoch 29/60
61/61 - 9s - loss: 3.4858e-04 - lwlrap: 0.9981 - val_loss: 0.1192 - val_lwlrap: 0.8513
Epoch 30/60
61/61 - 10s - loss: 9.9764e-04 - lwlrap: 0.9976 - val_loss: 0.1418 - val_lwlrap: 0.8477
Epoch 31/60
61/61 - 10s - loss: 0.0068 - lwlrap: 0.9973 - val_loss: 0.1151 - val_lwlrap: 0.8638
Epoch 32/60
61/61 - 10s - loss: 8.6841e-04 - lwlrap: 0.9983 - val_loss: 0.1270 - val_lwlrap: 0.8669
Epoch 33/60
61/61 - 9s - loss: 0.0022 - lwlrap: 0.9978 - val_loss: 0.1197 - val_lwlrap: 0.8574
Epoch 34/60
61/61 - 9s - loss: 0.0028 - lwlrap: 0.9988 - val_loss: 0.1369 - val_lwlrap: 0.8512
Epoch 35/60
61/61 - 9s - loss: 7.8192e-04 - lwlrap: 0.9982 - val_loss: 0.1520 - val_lwlrap: 0.8435
Epoch 36/60
61/61 - 10s - loss: 0.0028 - lwlrap: 0.9978 - val_loss: 0.1386 - val_lwlrap: 0.8642
Epoch 37/60
61/61 - 10s - loss: 0.0031 - lwlrap: 0.9980 - val_loss: 0.1281 - val_lwlrap: 0.8550
Epoch 38/60
61/61 - 9s - loss: 0.0011 - lwlrap: 0.9982 - val_loss: 0.1193 - val_lwlrap: 0.8598
Epoch 39/60
61/61 - 10s - loss: 5.3224e-04 - lwlrap: 0.9987 - val_loss: 0.1084 - val_lwlrap: 0.8506
Epoch 40/60
61/61 - 9s - loss: 7.1813e-04 - lwlrap: 0.9981 - val_loss: 0.1354 - val_lwlrap: 0.8626
Epoch 41/60
61/61 - 10s - loss: 0.0012 - lwlrap: 0.9988 - val_loss: 0.0897 - val_lwlrap: 0.8545
Epoch 42/60
61/61 - 10s - loss: 9.8966e-04 - lwlrap: 0.9984 - val_loss: 0.1181 - val_lwlrap: 0.8624
Epoch 43/60
61/61 - 10s - loss: 4.9286e-04 - lwlrap: 0.9997 - val_loss: 0.1354 - val_lwlrap: 0.8640
Epoch 44/60
61/61 - 10s - loss: 0.0016 - lwlrap: 0.9993 - val_loss: 0.1484 - val_lwlrap: 0.8370
Epoch 45/60
61/61 - 10s - loss: 6.5859e-04 - lwlrap: 0.9984 - val_loss: 0.1580 - val_lwlrap: 0.8468
Epoch 46/60
61/61 - 10s - loss: 9.0112e-04 - lwlrap: 0.9989 - val_loss: 0.1208 - val_lwlrap: 0.8774
Epoch 47/60
61/61 - 9s - loss: 5.0294e-04 - lwlrap: 0.9994 - val_loss: 0.1520 - val_lwlrap: 0.8612
Epoch 48/60
61/61 - 9s - loss: 0.0012 - lwlrap: 0.9988 - val_loss: 0.1681 - val_lwlrap: 0.8669
Epoch 49/60
61/61 - 9s - loss: 2.1063e-04 - lwlrap: 0.9993 - val_loss: 0.1508 - val_lwlrap: 0.8550
Epoch 50/60
61/61 - 9s - loss: 0.0011 - lwlrap: 0.9992 - val_loss: 0.1511 - val_lwlrap: 0.8519
Epoch 51/60
61/61 - 10s - loss: 4.0950e-04 - lwlrap: 1.0000 - val_loss: 0.1556 - val_lwlrap: 0.8543
Epoch 52/60
61/61 - 10s - loss: 6.5695e-04 - lwlrap: 0.9998 - val_loss: 0.1558 - val_lwlrap: 0.8709
Epoch 53/60
61/61 - 10s - loss: 2.3489e-04 - lwlrap: 0.9988 - val_loss: 0.1262 - val_lwlrap: 0.8718
Epoch 54/60
61/61 - 10s - loss: 3.0971e-04 - lwlrap: 0.9985 - val_loss: 0.1067 - val_lwlrap: 0.8541
Epoch 55/60
61/61 - 10s - loss: 4.3162e-04 - lwlrap: 0.9997 - val_loss: 0.1248 - val_lwlrap: 0.8404
Epoch 56/60
61/61 - 9s - loss: 0.0075 - lwlrap: 0.9991 - val_loss: 0.1220 - val_lwlrap: 0.8488
Epoch 57/60
61/61 - 10s - loss: 0.0010 - lwlrap: 0.9995 - val_loss: 0.1073 - val_lwlrap: 0.8513
Epoch 58/60
61/61 - 10s - loss: 0.0013 - lwlrap: 0.9995 - val_loss: 0.0881 - val_lwlrap: 0.8497
Epoch 59/60
61/61 - 9s - loss: 3.6421e-04 - lwlrap: 0.9974 - val_loss: 0.1412 - val_lwlrap: 0.8432
Epoch 60/60
61/61 - 9s - loss: 0.0048 - lwlrap: 0.9989 - val_loss: 0.1265 - val_lwlrap: 0.8468
Traceback (most recent call last):

