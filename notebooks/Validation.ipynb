{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas\n",
    "except:\n",
    "    !pip install pandas seaborn iterative-stratification nlpaug==0.0.20 tqdm click tensorflow_probability==0.11.1 tf2_resnets tensorflow_addons==0.11.1 image-classifiers==0.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from train import get_model\n",
    "from split_data import get_split\n",
    "from metrics import LwlrapAccumulator\n",
    "from dataloaders.val import MelSampler\n",
    "from dataloaders.utils import csv_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.metric import lwlrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_scale_eval(model_name, checkpoints_path, fold, scales):\n",
    "    \"\"\"\n",
    "    This function will compute each species's lrap at different scale.\n",
    "    The idea is, for each species in test-set, we will use its predicted\n",
    "    value at the scale that maximize its lrap in eval set. in the case\n",
    "    that the maximum lrap value is achieved at many different scales, let take a\n",
    "    maximum scale because the smaller scale, the more false positive samples.\n",
    "    \"\"\"\n",
    "    train_data = pd.read_csv(\"../data/new_train_tp.csv\")\n",
    "    _, val_index = get_split(fold=fold)\n",
    "    valid_dataset_csv = train_data.iloc[val_index]\n",
    "\n",
    "    valid_data_loader = MelSampler(\n",
    "        csv_to_dict(valid_dataset_csv),\n",
    "        cache=True,\n",
    "        batch_size=64,\n",
    "        n_classes=24,\n",
    "        is_train=False,\n",
    "        use_cutmix=False,\n",
    "        shuffle_aug=False,\n",
    "        max_length=384,\n",
    "    )\n",
    "    all_checkpoints = sorted(\n",
    "        glob.glob(os.path.join(checkpoints_path, f\"fold{fold}\", \"model-*.h5\"))\n",
    "    )\n",
    "\n",
    "    model = get_model(\n",
    "        model_name=model_name,\n",
    "        saved_path=checkpoints_path,\n",
    "        pretrained_with_contrastive=False,\n",
    "        pretrained_path=all_checkpoints[-1],\n",
    "    )\n",
    "    \n",
    "    lwlrap_at_scale = np.zeros((len(scales), NUM_CLASSES))\n",
    "    preds = []\n",
    "\n",
    "    for s, max_length in enumerate(scales):\n",
    "        valid_data_loader.max_length = max_length\n",
    "        clip_preds = model.predict(valid_data_loader, verbose=0)  # [B, 24]\n",
    "        clip_preds = tf.nn.sigmoid(clip_preds).numpy()\n",
    "        \n",
    "        preds.append(clip_preds)\n",
    "\n",
    "        # compute gts\n",
    "        gts = []\n",
    "        for i in range(len(valid_dataset_csv)):\n",
    "            gts.append(valid_dataset_csv.iloc[i][\"species_id\"])\n",
    "        gts = tf.keras.utils.to_categorical(gts, 24)\n",
    "\n",
    "        class_lwlrap, _ , score = lwlrap(gts, clip_preds)\n",
    "        \n",
    "        lwlrap_at_scale[s] = class_lwlrap\n",
    "        print(f\"Scale {scales[s]}:\\t{score:.3f}\")                     \n",
    "\n",
    "    np.save(\n",
    "        os.path.join(checkpoints_path, f\"lwlrap_at_scale_{fold}.npy\"),\n",
    "        lwlrap_at_scale,\n",
    "    )\n",
    "    \n",
    "    return lwlrap_at_scale, np.array(preds), gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_FOLDER = LOG_PATH + \"2021-02-04/9/\"\n",
    "CP_FOLDER = LOG_PATH + \"2021-02-04/12/\"\n",
    "# CP_FOLDER = \"../data/densenet121_pretrained/\"  # 0.897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_FOLDERS = [\n",
    "    LOG_PATH + \"2021-02-04/9/\"\n",
    "]\n",
    "\n",
    "MODELS = [\n",
    "    'densenet121',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "   'densenet121',\n",
    "#     'resnet18',\n",
    "#     'resnet34',\n",
    "#     'resnext50',\n",
    "#     'efficientnetb2',\n",
    "#     \"xception\",\n",
    "#     'resnest50',\n",
    "#     'efficientnetb3',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_FOLDERS = [\n",
    "#     \"../logs/2021-02-14/8/\",\n",
    "#     \"../logs/2021-02-14/9/\",\n",
    "#     \"../logs/2021-02-14/10/\",\n",
    "#     \"../logs/2021-02-15/0/\",\n",
    "#     \"../logs/2021-02-15/1/\",\n",
    "#     \"../logs/2021-02-15/2/\",\n",
    "    \"../logs/2021-02-15/3/\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################\n",
      " -> Log folder : ../logs/2021-02-16/1/\n",
      "########################\n",
      "\n",
      "\n",
      "-------------   Fold 1 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-16/1/fold0/model-0.820-0.130.h5\n",
      "\n",
      "Scale 32:\t0.549\n",
      "Scale 64:\t0.716\n",
      "Scale 128:\t0.814\n",
      "Scale 192:\t0.852\n",
      "Scale 256:\t0.856\n",
      "Scale 320:\t0.850\n",
      "Scale 384:\t0.840\n",
      "Scale 448:\t0.820\n",
      "Scale 512:\t0.811\n",
      "\n",
      "Multi-scale : 0.832\n",
      "\n",
      "-------------   Fold 2 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-16/1/fold1/model-0.860-0.116.h5\n",
      "\n",
      "Scale 32:\t0.605\n",
      "Scale 64:\t0.795\n",
      "Scale 128:\t0.869\n",
      "Scale 192:\t0.886\n",
      "Scale 256:\t0.892\n",
      "Scale 320:\t0.882\n",
      "Scale 384:\t0.862\n",
      "Scale 448:\t0.855\n",
      "Scale 512:\t0.859\n",
      "\n",
      "Multi-scale : 0.894\n",
      "\n",
      "-------------   Fold 3 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-16/1/fold2/model-0.796-0.125.h5\n",
      "\n",
      "Scale 32:\t0.549\n",
      "Scale 64:\t0.723\n",
      "Scale 128:\t0.814\n",
      "Scale 192:\t0.830\n",
      "Scale 256:\t0.837\n",
      "Scale 320:\t0.827\n",
      "Scale 384:\t0.805\n",
      "Scale 448:\t0.798\n",
      "Scale 512:\t0.796\n",
      "\n",
      "Multi-scale : 0.839\n",
      "\n",
      "-------------   Fold 4 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-16/1/fold3/model-0.851-0.116.h5\n",
      "\n",
      "Scale 32:\t0.540\n",
      "Scale 64:\t0.769\n",
      "Scale 128:\t0.865\n",
      "Scale 192:\t0.876\n",
      "Scale 256:\t0.869\n",
      "Scale 320:\t0.867\n",
      "Scale 384:\t0.859\n",
      "Scale 448:\t0.851\n",
      "Scale 512:\t0.853\n",
      "\n",
      "Multi-scale : 0.871\n",
      "\n",
      "-------------   Fold 5 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-16/1/fold4/model-0.860-0.128.h5\n",
      "\n",
      "Scale 32:\t0.542\n",
      "Scale 64:\t0.713\n",
      "Scale 128:\t0.841\n",
      "Scale 192:\t0.869\n",
      "Scale 256:\t0.868\n",
      "Scale 320:\t0.868\n",
      "Scale 384:\t0.856\n",
      "Scale 448:\t0.858\n",
      "Scale 512:\t0.858\n",
      "\n",
      "Multi-scale : 0.877\n",
      "\n",
      "########################\n",
      "Local CV score 0.863\n",
      "########################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, CP_FOLDER in zip(MODELS, CP_FOLDERS):\n",
    "    \n",
    "    print(f'\\n########################\\n -> Log folder : {CP_FOLDER}\\n########################\\n')\n",
    "    lwlraps = []\n",
    "    preds = []\n",
    "    best_preds = []\n",
    "    ys = []\n",
    "\n",
    "    for fold_idx in range(5):\n",
    "        tf.keras.backend.clear_session()\n",
    "        print(f\"\\n-------------   Fold {fold_idx + 1} / {5}  -------------\\n\")\n",
    "\n",
    "        lwlrap_at_scale, pred, y = run_multi_scale_eval(model_name, CP_FOLDER, fold_idx, SCALES)\n",
    "\n",
    "        best_pred = []\n",
    "        for c in range(NUM_CLASSES):  # extended argmax\n",
    "            best_score = lwlrap_at_scale[:, c].max()\n",
    "            best_indexes = [i for i, j in enumerate(lwlrap_at_scale[:, c]) if j == best_score]\n",
    "            class_preds = [pred[idx, :, c] for idx in best_indexes]\n",
    "    #         best_pred.append(np.mean(class_preds, 0))\n",
    "            best_pred.append(class_preds[-1])\n",
    "        best_pred = np.array(best_pred).T\n",
    "\n",
    "    #     best_pred = np.array([pred[lwlrap_at_scale[:, i].argmax(), :, i] for i in range(NUM_CLASSES)]).T  # argmax\n",
    "\n",
    "        score = lwlrap(y, best_pred)[-1]\n",
    "\n",
    "        print(f'\\nMulti-scale : {score:.3f}')\n",
    "\n",
    "        lwlraps.append(lwlrap_at_scale)\n",
    "        best_preds.append(best_pred)\n",
    "        preds.append(pred)\n",
    "        ys.append(y)\n",
    "        \n",
    "    score = lwlrap(np.concatenate(ys), np.concatenate(best_preds))[-1]\n",
    "\n",
    "    print(f'\\n########################\\nLocal CV score {score:.3f}\\n########################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local CV score 0.904\n"
     ]
    }
   ],
   "source": [
    "score = lwlrap(np.concatenate(ys), np.concatenate(best_preds))[-1]\n",
    "\n",
    "print(f'Local CV score {score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/new_train_tp.csv')\n",
    "\n",
    "pred_oof = np.zeros((len(df), NUM_CLASSES))\n",
    "\n",
    "for i in range(5):\n",
    "    _, val_index = get_split(fold=i)\n",
    "    \n",
    "    pred_val = preds[i]\n",
    "    lwlrap_at_scale = lwlraps[i]\n",
    "    \n",
    "    best_pred = []\n",
    "    for c in range(NUM_CLASSES):  # extended argmax\n",
    "#         best_score = lwlrap_at_scale[:, c].max()\n",
    "#         best_indexes = [i for i, j in enumerate(lwlrap_at_scale[:, c]) if j == best_score]\n",
    "\n",
    "        best_indexes = [-1] # only 512\n",
    "        class_preds = [pred_val[idx, :, c] for idx in best_indexes]\n",
    "        best_pred.append(class_preds[-1])\n",
    "    best_pred = np.array(best_pred).T\n",
    "    pred_oof[val_index] = best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confidences = []\n",
    "has_others = []\n",
    "for i in range(len(df)):\n",
    "    pred = pred_oof[i].copy()\n",
    "    \n",
    "#     print(pred, df['species_id'][i], pred[df['species_id'][i]], pred.max())\n",
    "    confidences.append(pred[df['species_id'][i]])\n",
    "    \n",
    "    pred[df['species_id'][i]] = 0\n",
    "    has_others.append(int(pred.max() > 0.5))\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['confidence'] = confidences\n",
    "df['has_other'] = has_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAADCCAYAAACYGsyXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAd8UlEQVR4nO3deZwddZnv8c+312wkZGlCyEJYohBZBBsIA4Mg4GXTICICAgHjBBW9sryuoqKi3hnRQbigXjSsAQHZIaOAw6YoQiQBhJBAEvbELA2ErGTp7mf+qGo4aXo5nZxT53T39/161av2ep7TOal++ldVv1JEYGZmZmbFV1HqBMzMzMx6CxdeZmZmZhlx4WVmZmaWERdeZmZmZhlx4WVmZmaWERdeZmZmZhmpKnUC+Rg2bFiMHTu21GmYWYZmzZr1ZkTUlTqPLeXzl1nv09H5q1sUXmPHjmXmzJmlTsPMMiTptVLnUAg+f5n1Ph2dv3yp0czMzCwjLrzMzMzMMuLCy8zMzCwjLrzMzMzMMuLCy8zMzCwj3eKpRjPr3E0zXt9k/uT9xpQoE9tSH/s/15c6BWtl1n+eVuoUrIdwi5eZmZlZRlx4mZmZmWXEhZeZmZlZRopWeEkaLekRSXMkPS/pG+nyCyUtkvRMOhxVrBzMzMzMykkxb65vBM6LiKckbQXMkvRAuu7SiLi4iLHNzMzMyk7RCq+IWAwsTqdXSZoLjCxWPDMzM7Nyl8k9XpLGAnsBM9JFX5P0rKRrJA3OIgczs7ZIOie9HWK2pJsl9ZG0g6QZkhZIukVSTbptbTq/IF0/tsTpm1k3U/TCS9IA4A7g7IhYCVwB7AR8lKRF7Oft7DdF0kxJMxsaGoqdppn1QpJGAv8bqI+I3YBK4ETgpyS3ROwMLAcmp7tMBpanyy9NtzMzy1tRCy9J1SRF140RcSdARCyNiKaIaAauBPZta9+ImBoR9RFRX1dXV8w0zax3qwL6SqoC+pH8QfgJ4PZ0/TTg2HR6YjpPuv5QScouVTPr7or5VKOAq4G5EXFJzvIROZt9BphdrBzMzDoSEYuAi4HXSQquFcAs4J2IaEw3W8j796eOBN5I921Mtx/a+rhusTez9hSzxesA4FTgE626jviZpOckPQscApxTxBzMzNqV3mM6EdgB2A7oDxyxpcd1i72ZtaeYTzX+FWirCf7eYsU0M+uiw4BXIqIBQNKdJH80bi2pKm3VGgUsSrdfBIwGFqaXJgcBb2Wftpl1V+653sx6s9eBCZL6pbdHHArMAR4Bjk+3mQTck05PT+dJ1z8cEZFhvmbWzbnwMrNeKyJmkNwk/xTwHMk5cSrwLeBcSQtI7uG6Ot3lamBouvxc4PzMkzazbq2YPdebmZW9iPgB8INWi1+mjSeuI2Id8Lks8jKznsktXmZmZmYZceFlZmZmlhEXXmZmZmYZceFlZmZmlhEXXmZmZmYZceFlZmZmlhEXXmZmZmYZceFlZmZmlhEXXmZmZmYZceFlZmZmlhEXXmZmZmYZceFlZmZmlhEXXmZmZmYZceFlZmZmlhEXXmZmZmYZceFlZmZmlhEXXmZmZmYZceFlZmZmlpGiFV6SRkt6RNIcSc9L+ka6fIikByTNT8eDi5WDmZmZWTkpZotXI3BeRIwHJgBnSRoPnA88FBHjgIfSeTMzM7Mer2iFV0Qsjoin0ulVwFxgJDARmJZuNg04tlg5mJmZmZWTTO7xkjQW2AuYAQyPiMXpqiXA8CxyMDMzMyu1ohdekgYAdwBnR8TK3HUREUC0s98USTMlzWxoaCh2mmZmZmZFV9TCS1I1SdF1Y0TcmS5eKmlEun4EsKytfSNiakTUR0R9XV1dMdM0MzMzy0Qxn2oUcDUwNyIuyVk1HZiUTk8C7ilWDmZmZmblpKqIxz4AOBV4TtIz6bLvABcBt0qaDLwGnFDEHMzMzMzKRtEKr4j4K6B2Vh9arLhmZmZm5co915tZryZpa0m3S3pB0lxJ+7fX0bMSl0taIOlZSXuXOn8z615ceJlZb3cZcH9E7ALsSdLnYHsdPR8JjEuHKcAV2adrZt2ZCy8z67UkDQIOInkQiIjYEBHv0H5HzxOB6yPxBLB1y1PaZmb5cOFlZr3ZDkADcK2kpyVdJak/7Xf0PBJ4I2f/hekyM7O8uPAys96sCtgbuCIi9gLW0Or9sR119NwedwBtZu1x4WVmvdlCYGFEzEjnbycpxNrr6HkRMDpn/1Hpsk24A2gza48LLzPrtSJiCfCGpA+niw4F5tB+R8/TgdPSpxsnACtyLkmamXWqmB2ompl1B18HbpRUA7wMnEHyR2lbHT3fCxwFLADWptuameXNhZeZ9WoR8QxQ38aqD3T0nN7vdVaxczKznsuXGs3MzMwy4sLLzMzMLCMuvMzMzMwy4sLLzMzMLCMuvMzMzMwy4sLLzMzMLCN5FV6S7pR0tCQXamZmZmabKd9C6v8DJwPzJV2U08uzmZmZmeUpr8IrIh6MiC+QvMPsVeBBSX+TdIak6mImaGZmZtZT5H3pUNJQ4HTgS8DTwGUkhdgDRcnMzMzMrIfJ65VBku4CPgzcAHwq56Wwt0iaWazkzMzMzHqSfFu8royI8RHxk5aiS1ItQES09Y4zM7NMSXoon2VmZqWUb+H1f9tY9nhHO0i6RtIySbNzll0oaZGkZ9LhqK4ka2bWmqQ+koYAwyQNljQkHcYCI0ucnpnZJjq81ChpW5ITV19JewFKVw0E+nVy7OuAXwLXt1p+aURc3PVUzczadCZwNrAdMIv3z1MrSc5BZmZlo7N7vP4XyQ31o4BLcpavAr7T0Y4R8Wj6F6eZWdFExGXAZZK+HhG/KHU+ZmYd6bDwiohpwDRJn42IOwoU82uSTgNmAudFxPK2NpI0BZgCMGbMmAKFNrOeKiJ+IelfgLHknNsionWru5lZyXR2qfGUiPgtMFbSua3XR8QlbezWkSuAHwORjn8OfLGtDSNiKjAVoL6+ProYx8x6GUk3ADsBzwBN6eLgg7c7mJmVTGeXGvun4wGFCBYRS1umJV0J/L4QxzUzA+qB8RHhP9TMrGx1dqnxN+n4h4UIJmlETh9gnwFmd7S9mVkXzAa2BRZ3tqGZWank24Hqz0i6lHgXuB/YAzgnvQzZ3j43AweTPOK9EPgBcLCkj5I0/79K8jSSmVkhDAPmSPo7sL5lYUR8unQpmZltKq/CC/hkRHxT0mdICqbjgEeBdguviDipjcVXdzlDM7P8XFjqBMzMOpNv4dWy3dHAbRGxQlJH25uZZSoi/lzqHMzMOpNv4fV7SS+QXGr8iqQ6YF3x0jIz6xpJq0huYwCoAaqBNRExsHRZmZltKq/CKyLOT+/zWhERTZLWABOLm5qZWf4iYquWaSVN8hOBCaXLyMzsg/Jt8QLYhaQ/r9x93D+OmZWdtEuJuyX9ADi/1PmYmbXI96lGd0xoZmVN0nE5sxUk/Xr5lggzKyv5tni5Y0IzK3efypluJHkC27dEmFlZybfwcseEZlbWIuKMUudgZtaZijy3a+mY8I+SprcMxUzMzKwrJI2SdJekZelwh6RRee5bKelpSb9P53eQNEPSAkm3SKpJl9em8wvS9WOL+JHMrAfKt8XrwmImYWZWANcCNwGfS+dPSZcdnse+3wDmAi1dT/wUuDQififp18Bk4Ip0vDwidpZ0Yrrd5wv3Ecysp8urxSvtmPBVoDqdfhJ4qoh5mZl1VV1EXBsRjelwHVDX2U5pq9jRwFXpvIBPALenm0wDjk2nJ6bzpOsPlXuTNrMuyKvwkvRvJCeZ36SLRgJ3FyknM7PN8ZakU9LLhpWSTgHeymO//wd8E2hO54cC70REYzq/kOScRzp+AyBdvyLdfhOSpkiaKWlmQ0PDZn8gM+t58r3H6yzgAGAlQETMB7YpVlJmZpvhi8AJwBKSB4GOB07vaAdJxwDLImJWIROJiKkRUR8R9XV1nTa6mVkvku89XusjYkNLi3raiaq7ljCzcvIjYFJELAeQNAS4mKQga88BwKclHQX0IbnH6zJga0lVaavWKGBRuv0iYDSwMD0PDiK/VjUzMyD/Fq8/S/oO0FfS4cBtwH8VLy0zsy7bo6XoAoiIt4G9OtohIr4dEaMiYixwIvBwRHwBeISkxQxgEnBPOj09nSdd/7D7NzSzrsi38DofaACeA84E7gUuKFZSZmaboULS4JaZtMWrK69Fy/Ut4FxJC0ju4bo6XX41MDRdfi5+HZGZdVG+L8lulnQ3cHdE+E5RMytHPwcel3RbOv854N/z3Tki/gT8KZ1+Gdi3jW3W8X53FWZmXdZhi5cSF0p6E3gReFFSg6TvZ5OemVl+IuJ64DhgaTocFxE3lDYrM7NNddbidQ7Jzaf7RMQrAJJ2BK6QdE5EXFrsBM3M8hURc4A5pc7DbHO9/qPdS52CtTLm+88V9Hid3eN1KnBSS9EF7zXBnwKcVtBMzMzMzHq4zgqv6oh4s/XC9D6v6uKkZGZmZtYzdVZ4bdjMdUi6Jn1R7eycZUMkPSBpfjoe3NExzMzMzHqSzgqvPSWtbGNYBXR2Ifo64IhWy84HHoqIccBD+FFsMzMz60U6vLk+Iio398AR8aiksa0WTwQOTqenkTy6/a3NjWFmZmbWneTbgWqhDI+Ixen0EmB4xvHNzMzMSibrwus96Ws22n3VhqQpkmZKmtnQ4D5bzczMrPvLuvBaKmkEQDpe1t6GETE1Iuojor6uri6zBM3MzMyKJevCK/cFs7kvnjUzMzPr8YpWeEm6GXgc+LCkhZImAxcBh0uaDxyWzpuZmZn1Cnm9JHtzRMRJ7aw6tFgxzczMzMpZyW6uNzMzM+ttXHiZmZmZZcSFl5mZmVlGXHiZmZmZZcSFl5mZmVlGXHiZmZmZZcSFl5mZmVlGXHiZmZmZZcSFl5mZmVlGXHiZmZmZZcSFl5mZmVlGXHiZmZmZZcSFl5mZmVlGXHiZmZmZZcSFl5n1WpJGS3pE0hxJz0v6Rrp8iKQHJM1Px4PT5ZJ0uaQFkp6VtHdpP4GZdTcuvMysN2sEzouI8cAE4CxJ44HzgYciYhzwUDoPcCQwLh2mAFdkn7KZdWcuvMys14qIxRHxVDq9CpgLjAQmAtPSzaYBx6bTE4HrI/EEsLWkEdlmbWbdmQsvMzNA0lhgL2AGMDwiFqerlgDD0+mRwBs5uy1Ml7U+1hRJMyXNbGhoKF7SZtbtuPAys15P0gDgDuDsiFiZuy4iAoiuHC8ipkZEfUTU19XVFTBTM+vuXHiZWa8mqZqk6LoxIu5MFy9tuYSYjpelyxcBo3N2H5UuMzPLiwsvM+u1JAm4GpgbEZfkrJoOTEqnJwH35Cw/LX26cQKwIueSpJlZp6pKEVTSq8AqoAlojIj6UuRhZr3eAcCpwHOSnkmXfQe4CLhV0mTgNeCEdN29wFHAAmAtcEam2ZpZt1eSwit1SES8WcL4ZtbLRcRfAbWz+tA2tg/grKImZWY9mi81mpmZmWWkVIVXAP8taZakKW1t4MexzczMrKcpVeF1YETsTdIL9FmSDmq9gR/HNjMzs56mJIVXRCxKx8uAu4B9S5GHmZmZWZYyL7wk9Ze0Vcs08ElgdtZ5mJmZmWWtFE81DgfuSrrPoQq4KSLuL0EeZmZmZpnKvPCKiJeBPbOOa2ZmZlZqpezHy8wK5LW31vDwC8t4/e01rF7fSE1lBXMWr+CwXYdz0Lg6Kira66rKzMyy5MLLrBtbuHwtF933Ar9/djEChg/sw6C+1axvbOKupxbx2ydeZ+dtBnDB0bty8Ie3KXW6Zma9ngsvs27qjlkL+f49s2kOOOuQnRhQW82gvtXvrf/sx0Zy/+wlXPbgfE6/9klO2397vnfMeKor3W+ymVmpuPAy62aamoOL7pvLlX95hQk7DuHiz+3JqMH9uGnG65tsV1tVycSPjuSI3bblP+9/kav++grzlq7iVyfvzdABtSXK3sysd/OfvmbdyLqNTUy5fiZX/uUVJu2/PTdM3o9Rg/t1uE9tVSUXHDOeSz+/J0+9/g6f+83jLFu5LqOMzcwslwsvs25ifWMTX/ntLB56YRk/nvgRfjhxty5dNvzMXqO48Uv7sWTFOk668gmWrXLxZWaWNRdeZt3AhsZmzrrxKR55sYH/+MzunLr/2M06zj5jh3DdGfuyeMU6Tr5yBm+v2VDYRM3MrEMuvMzK3MamZs666SkenLuMHx+7GyfvN2aLjrfvDkO45vR9eOPttZxx3ZOsWd9YoEzNzKwzLrzMytjGpma+ftPTPDBnKT+a+BFOnbB9QY47Yceh/PLkvZm9aAVf/u0sNjQ2F+S4ZmbWMRdeZmWqsamZs3/3DPc/v4TvHzOe0zbz8mJ7Dh8/nJ8ctzt/mf8m5976DM3NUdDjm5nZB7k7CbMy1NjUzDm3/oM/PLeYC47elS8euENR4pxQP5rlazbwk/teYEj/Gn746Y+QvkfVzMyKwIWXWZlpbGrmvNv+wX/94598+8hd+NK/7ljUeGd+fCfeWrOBqY++zND+tXzjsHFFjWdm1pu58DIrI+sbm/j6TU/z33OW8s0jPsyZH9+pw+1bd5q6ub595C68vWYDlz44jyEDagp2L5mZmW3KhZdZmVi9vpGv3vgUj85r4MJPjef0A4pzebEtkrjouN15Z+0Gvn/PbAb3q+aYPbbLLL6ZWW/hm+vNysDC5Ws5/oq/8diCN/nZZ/fItOhqUVVZwS9P3pv67Qdzzi3P8Jf5DZnnYGbW07nwMiuxx196i2N/9RiL3nmX687YhxP2GV2yXPpUV3LVpH3YqW4AZ94wi0fnufgyMyskF15mJbK+sYn/uHcuJ1/1BAP7VHPXVw/gX8fVlTotBvWt5vrJ+zJmSD++eN2T3DFrYalTMjPrMXyPl1nGIoI/vdjAv987lwXLVnPyfmO44Ohd6VfT+X/HQt1M35ltturDrV/en6/8dhbn3fYP5i9bzXmf/FCX3g1pZmYf5MKryFr/otzS171Y9xURPLbgLX7955f464I32WFYf649fR8O2WWbUqfWpoF9qrn29H35wfTn+fWfX+KJl9/i8hP3YszQfqVOzcys23LhVWZcqPU8b7y9lvtmL+b2WQuZt3Q1wwbU8L1jxnPqhO2pqeq4BSmrFq721FRV8JPjdufAnYdx/h3Pcvilf+bMg3bkywfvlFcLnZmZbaokZ05JRwCXAZXAVRFxUSnyyEpTc7BmfSMr123ke3fPZu2GRtZtbGZ9YxM71g1g9fpGGpuaaQ54adlqWl7cUlUhXlyykj7VldRWV9KnuoK+1ZX0r6mif20V/WpbppNxv9pKBtRW0be60r2Pl8i7G5p4qWE185etYtZry/n7K28zb+lqAPYcNYjj9x7FHqMGUVVZwe2zFnabwvroPUaw15ituei+F7j84QXc/OQbnDZhe07abwzDBtSWOr3M9bZzmJkVTuaFl6RK4FfA4cBC4ElJ0yNiTta5FMKqdRtZsmIdS1auY/GKdSxZkYyXrVzH0lXreO3Ntaxe30h7b8GrntdAbVUllRVCgJT0qRQRNDYHs/+5gsamZDpfEvSrrqR/bVqg1aTTNZX0q61iQE6R1i+ncOtbU0lVhaiqFJUVFVRXiMqc+ZZ1VRWiqqKCirS4a13jtcy3FH9qvZxN92uOoDmSS3ERm85vMiZobk7WR8t8tMy37Nuyf0Cr+SA9VssxeP/YzTmx2x3n5NrU1Mw7727kzdXreWv1Bt5avYF/rniXRe+8S6T/VANqq9h7+8Ec/7FRHLnbCEYP6ddpC1apW7g6st3Wfbn8pL04bf/tueyh+fz8gXn84uEFHDhuGIePH86BOw9j1OC+Pb7o72nnMDPLVilavPYFFkTEywCSfgdMBIp20sr95dryi7SpOd77JdrY1My6xmbe3dDEuo1NvLux6b3p1esbWb52I8vXbGD52nRYs5GG1etZsmIdq9c3fiDe0P41bDOwD9sOrKVPVSVb9almYN8qBvapZqs+SbHTp7rivYIrH80RNDUHGxqb2dDUzPrG5mS6MWk5S8bNOeOmZNyULGtYtZ53a6tY8/Za1qxvZO36JtZsaMTvRd4yg/tVU1VZwYDaKob2r+GE+tHsVDeAnbcZwE51/bl1ZvJE4F/mv9nm/uVcaLWnfuwQbpi8HwuWrebmv7/OH59fwsMvLAOS7/747QYyZkg/Rg3ux8jBfRnWv4aBfasZOqCGEYP6ljj7gsj8HGZmPUcpCq+RwBs58wuB/Qpx4McWvMmXps2kKW0ByW3J2FIVgq371TC4XzWD+9WwU11/Dtx5GCMG9WHbQX0YMagv2w7swzYDa+lTXfnefoX6xVohUVEpqisr6F+QIyYF6cameK8429DY/F5xmhSm5EwnLUVN0TKdtAC1NOW9/yOO9NitYrWaiPdmgwrltPahTVrMkmXpdKttclsIaXNd7j7vH48Oj7dpy6MAWu3fMt23uu3CecW7G5n12nJmvba8i/8i3cvO2wzge8eM54Kjd+XFpat48tXlPPvGO8xdspLZi1awfO3GTbbfZdutuP/sg0qUbUEV7RxmZj1f2d4dK2kKMCWdXS3pxc081DCg7eaGbDh+741f0s/+hTL72b8G6Jwu7d9tXxhZwPNXT1Dq72FB6OJJpU6hO+oR//b8YLNun2j3/FWKwmsRkNs196h02SYiYiowdUuDSZoZEfVbehzHd/zuFNvxi6rTc1ihzl89QQ/+Hlgn/G/ftlL0hvgkME7SDpJqgBOB6SXIw8xsc/gcZmabLfMWr4holPQ14I8kj2JfExHPZ52Hmdnm8DnMzLZESe7xioh7gXszClfq5n7H773xe/NnL4f4RZPxOay767HfA+uU/+3boCjEI39mZmZm1im/8dbMzMwsIz2u8JI0RNIDkuan48FtbPNRSY9Lel7Ss5I+X4C4R0h6UdICSee3sb5W0i3p+hmSxm5pzC7GP1fSnPTzPiSpYI/qdxY7Z7vPSgpJBX3KJZ/4kk5IP//zkm7KMr6kMZIekfR0+vM/qsDxr5G0TNLsdtZL0uVpfs9K2jvD2F9IYz4n6W+S9ixUbCtv+Z4XrGfp7JxgtLympecMwM+A89Pp84GftrHNh4Bx6fR2wGJg6y2IWQm8BOwI1AD/AMa32uarwK/T6ROBWwr4mfOJfwjQL53+SqHi5xM73W4r4FHgCaA+488+DngaGJzOb5Nx/KnAV9Lp8cCrhYqfHvMgYG9gdjvrjwLuI+n7dQIwI8PY/5Lzcz+ykLE9lO+Q73nBQ88bOjsneIie1+JF8uqOaen0NODY1htExLyImJ9O/xNYBtRtQcz3XiESERuAlleItJfX7cChKtxL7TqNHxGPRMTadPYJkr6HMomd+jHwU2BdgeJ2Jf6/Ab+KiOUAEbEs4/gBDEynBwH/LGB8IuJR4O0ONpkIXB+JJ4CtJY3IInZE/K3l505hv3dW3vI9L1gPk8f5qNfriYXX8IhYnE4vAYZ3tLGkfUn+IntpC2K29QqRke1tExGNwApg6BbE7Gr8XJNJWkAyiZ1e2hodEX8oUMwuxSdp4fyQpMckPSHpiIzjXwicImkhyZNwXy9g/Hx09ftRLIX83ll5K5fvnFnZKdtXBnVE0oPAtm2s+m7uTESEpHYf20z/6r8BmBQRzYXNsjxJOgWoBz6eUbwK4BLg9CzitaOK5HLjwSQtLo9K2j0i3sko/knAdRHxc0n7AzdI2q23fOcAJB1CUngdWOpczMxKqVsWXhFxWHvrJC2VNCIiFqeFVZuXlSQNBP4AfDe9/LIl8nkNUss2CyVVkVxyemsL43YlPpIOIylOPx4R6zOKvRWwG/Cn9MrqtsB0SZ+OiJkZxIfkr+0ZEbEReEXSPJJC7MmM4k8GjgCIiMcl9SF5h1khL3l2JK/vR7FI2gO4CjgyIgr1nbfyVtLvnFk564mXGqcDLW8znQTc03qD9DUfd5Hc93J7AWLm8wqR3LyOBx6O9E7ELOJL2gv4DfDpAt/j1GHsiFgREcMiYmxEjCW5z6dQRVen8VN3k7R2IWkYyaXHlzOM/zpwaBp/V6AP0FCg+PmYDpyWPt04AViRczm+qCSNAe4ETo2IeVnEtLLg1yqZtafUd/cXeiC5b+ohYD7wIDAkXV4PXJVOnwJsBJ7JGT66hXGPAuaR3Cv23XTZj0iKDEh+2d4GLAD+DuxY4M/dWfwHgaU5n3d6VrFbbfsnCvhUY56fXSSXO+cAzwEnZhx/PPAYyZNdzwCfLHD8m0mezN1I0ro3Gfgy8OWcz/+rNL/nCvnzzyP2VcDynO/dzEJ+dg/lO7T1/8JDzx/aOieUOqdyG9xzvZmZmVlGeuKlRjMzM7Oy5MLLzMzMLCMuvMzMzMwy4sLLzMzMLCMuvMzMzMwy4sLLzMzMLCMuvMzMzMwy4sLLzMzMLCP/A7g1UlXtS3JVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.distplot(confidences)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(has_others)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUT_DIR + 'df_tp_conf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
