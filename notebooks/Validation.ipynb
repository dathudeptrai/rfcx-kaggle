{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas\n",
    "except:\n",
    "    !pip install pandas iterative-stratification nlpaug==0.0.20 tqdm click tensorflow_probability==0.11.1 tf2_resnets tensorflow_addons==0.11.1 image-classifiers==0.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from train import get_model\n",
    "from split_data import get_split\n",
    "from metrics import LwlrapAccumulator\n",
    "from dataloaders.val import MelSampler\n",
    "from dataloaders.utils import csv_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.metric import lwlrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_scale_eval(checkpoints_path, fold, scales):\n",
    "    \"\"\"\n",
    "    This function will compute each species's lrap at different scale.\n",
    "    The idea is, for each species in test-set, we will use its predicted\n",
    "    value at the scale that maximize its lrap in eval set. in the case\n",
    "    that the maximum lrap value is achieved at many different scales, let take a\n",
    "    maximum scale because the smaller scale, the more false positive samples.\n",
    "    \"\"\"\n",
    "    train_data = pd.read_csv(\"../data/new_train_tp.csv\")\n",
    "    _, val_index = get_split(fold=fold)\n",
    "    valid_dataset_csv = train_data.iloc[val_index]\n",
    "\n",
    "    valid_data_loader = MelSampler(\n",
    "        csv_to_dict(valid_dataset_csv),\n",
    "        cache=True,\n",
    "        batch_size=64,\n",
    "        n_classes=24,\n",
    "        is_train=False,\n",
    "        use_cutmix=False,\n",
    "        shuffle_aug=False,\n",
    "        max_length=384,\n",
    "    )\n",
    "    all_checkpoints = sorted(\n",
    "        glob.glob(os.path.join(checkpoints_path, f\"fold{fold}\", \"model-*.h5\"))\n",
    "    )\n",
    "\n",
    "    model = get_model(\n",
    "        saved_path=checkpoints_path,\n",
    "        pretrained_with_contrastive=False,\n",
    "        pretrained_path=all_checkpoints[-1],\n",
    "    )\n",
    "    \n",
    "#     model.load_weights(all_checkpoints[-1])\n",
    "    \n",
    "    lwlrap_at_scale = np.zeros((len(scales), NUM_CLASSES))\n",
    "    preds = []\n",
    "    seg_preds = []\n",
    "\n",
    "    for s, max_length in enumerate(scales):\n",
    "        valid_data_loader.max_length = max_length\n",
    "        clip_preds, seg_pred = model.predict(valid_data_loader, verbose=0)  # [B, 24]\n",
    "#         clip_preds = tf.nn.sigmoid(clip_preds).numpy()\n",
    "        preds.append(clip_preds)\n",
    "        seg_preds.append(seg_pred)\n",
    "\n",
    "        # compute gts\n",
    "        gts = []\n",
    "        for i in range(len(valid_dataset_csv)):\n",
    "            gts.append(valid_dataset_csv.iloc[i][\"species_id\"])\n",
    "        gts = tf.keras.utils.to_categorical(gts, 24)\n",
    "\n",
    "        class_lwlrap, _ , score = lwlrap(gts, clip_preds)\n",
    "        \n",
    "        lwlrap_at_scale[s] = class_lwlrap\n",
    "        print(f\"Scale {scales[s]}:\\t{score:.3f}\")            \n",
    "\n",
    "    np.save(\n",
    "        os.path.join(checkpoints_path, f\"lwlrap_at_scale_{fold}.npy\"),\n",
    "        lwlrap_at_scale,\n",
    "    )\n",
    "    \n",
    "    return lwlrap_at_scale, np.array(preds), seg_preds, gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_FOLDER = LOG_PATH + \"2021-01-28/4/\"  # 0.898\n",
    "# CP_FOLDER = LOG_PATH + \"2021-01-28/12/\"  # 0.891\n",
    "# CP_FOLDER = LOG_PATH + \"2021-01-28/14/\"  # 0.897\n",
    "CP_FOLDER = LOG_PATH + \"2021-01-28/15/\"  # 0.907\n",
    "CP_FOLDER = LOG_PATH + \"2021-01-31/11/\"  # 0.910\n",
    "# CP_FOLDER = LOG_PATH + \"2021-01-31/12/\"  # 0.912\n",
    "CP_FOLDER = LOG_PATH + \"2021-02-01/20/\"  # 0.926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------   Fold 1 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-01/20/fold0/model-0.878-0.117.h5\n",
      "\n",
      "Scale 32:\t0.695\n",
      "Scale 64:\t0.828\n",
      "Scale 128:\t0.868\n",
      "Scale 192:\t0.867\n",
      "Scale 256:\t0.886\n",
      "Scale 320:\t0.882\n",
      "Scale 384:\t0.868\n",
      "Scale 448:\t0.864\n",
      "Scale 512:\t0.857\n",
      "\n",
      "Multi-scale : 0.892\n",
      "\n",
      "-------------   Fold 2 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-01/20/fold1/model-0.921-0.039.h5\n",
      "\n",
      "Scale 32:\t0.640\n",
      "Scale 64:\t0.856\n",
      "Scale 128:\t0.911\n",
      "Scale 192:\t0.923\n",
      "Scale 256:\t0.927\n",
      "Scale 320:\t0.909\n",
      "Scale 384:\t0.917\n",
      "Scale 448:\t0.914\n",
      "Scale 512:\t0.919\n",
      "\n",
      "Multi-scale : 0.930\n",
      "\n",
      "-------------   Fold 3 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-01/20/fold2/model-0.879-0.040.h5\n",
      "\n",
      "Scale 32:\t0.542\n",
      "Scale 64:\t0.745\n",
      "Scale 128:\t0.868\n",
      "Scale 192:\t0.884\n",
      "Scale 256:\t0.883\n",
      "Scale 320:\t0.877\n",
      "Scale 384:\t0.875\n",
      "Scale 448:\t0.874\n",
      "Scale 512:\t0.868\n",
      "\n",
      "Multi-scale : 0.906\n",
      "\n",
      "-------------   Fold 4 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-01/20/fold3/model-0.905-0.029.h5\n",
      "\n",
      "Scale 32:\t0.714\n",
      "Scale 64:\t0.838\n",
      "Scale 128:\t0.889\n",
      "Scale 192:\t0.903\n",
      "Scale 256:\t0.909\n",
      "Scale 320:\t0.904\n",
      "Scale 384:\t0.899\n",
      "Scale 448:\t0.898\n",
      "Scale 512:\t0.889\n",
      "\n",
      "Multi-scale : 0.903\n",
      "\n",
      "-------------   Fold 5 / 5  -------------\n",
      "\n",
      " -> Loading weights from ../logs/2021-02-01/20/fold4/model-0.901-0.069.h5\n",
      "\n",
      "Scale 32:\t0.610\n",
      "Scale 64:\t0.788\n",
      "Scale 128:\t0.881\n",
      "Scale 192:\t0.879\n",
      "Scale 256:\t0.906\n",
      "Scale 320:\t0.891\n",
      "Scale 384:\t0.880\n",
      "Scale 448:\t0.888\n",
      "Scale 512:\t0.896\n",
      "\n",
      "Multi-scale : 0.903\n"
     ]
    }
   ],
   "source": [
    "lwlraps = []\n",
    "preds = []\n",
    "seg_preds = []\n",
    "best_preds = []\n",
    "ys = []\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    if fold_idx in [0, 2, 4]:\n",
    "        tf.keras.backend.clear_session()\n",
    "    print(f\"\\n-------------   Fold {fold_idx + 1} / {5}  -------------\\n\")\n",
    "    lwlrap_at_scale, pred, seg_pred, y = run_multi_scale_eval(CP_FOLDER, fold_idx, SCALES)\n",
    "    \n",
    "    best_pred = []\n",
    "    for c in range(NUM_CLASSES):  # extended argmax\n",
    "        best_score = lwlrap_at_scale[:, c].max()\n",
    "        best_indexes = [i for i, j in enumerate(lwlrap_at_scale[:, c]) if j == best_score]\n",
    "\n",
    "        class_preds = [pred[idx, :, c] for idx in best_indexes]\n",
    "#         best_pred.append(np.mean(class_preds, 0))\n",
    "        best_pred.append(class_preds[-1])\n",
    "    best_pred = np.array(best_pred).T\n",
    "\n",
    "#     best_pred = np.array([pred[lwlrap_at_scale[:, i].argmax(), :, i] for i in range(NUM_CLASSES)]).T  # argmax\n",
    "\n",
    "    score = lwlrap(y, best_pred)[-1]\n",
    "\n",
    "    print(f'\\nMulti-scale : {score:.3f}')\n",
    "    \n",
    "    lwlraps.append(lwlrap_at_scale)\n",
    "    best_preds.append(best_pred)\n",
    "    seg_preds.append(seg_pred)\n",
    "    preds.append(pred)\n",
    "    ys.append(y)\n",
    "    \n",
    "\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local CV score 0.907\n"
     ]
    }
   ],
   "source": [
    "score = lwlrap(np.concatenate(ys), np.concatenate(best_preds))[-1]\n",
    "\n",
    "print(f'Local CV score {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for scale, pred in zip(SCALES, seg_preds[0]):\n",
    "    \n",
    "#     if scale != 256:\n",
    "#         continue\n",
    "        \n",
    "#     for i in range(pred.shape[0]):\n",
    "#         plt.figure(figsize=(12, 8))\n",
    "#         for j in range(24):\n",
    "#             plt.plot(pred[i][j], label=f'class {j}')\n",
    "#             plt.ylim(-0.01, 1.01)\n",
    "            \n",
    "#         plt.legend()\n",
    "#         plt.title(f'{scale} - {i}')\n",
    "#         plt.show()\n",
    "        \n",
    "# #     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
