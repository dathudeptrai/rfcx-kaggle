{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas\n",
    "except:\n",
    "    !pip install pandas iterative-stratification nlpaug==0.0.20 tqdm click tensorflow_probability==0.11.1 tf2_resnets tensorflow_addons==0.11.1 image-classifiers==0.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloaders.train import BalancedMelSampler\n",
    "from dataloaders.val import MelSampler\n",
    "from dataloaders.utils import csv_to_dict\n",
    "\n",
    "from losses import NpairsLoss, MovingAverageBCE\n",
    "from metrics import TFLWLRAP\n",
    "from split_data import get_split\n",
    "from train import get_model, get_callbacks\n",
    "from models import NUM_FRAMES, Classifier, DeepMetricLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.logger import prepare_log_folder, create_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "for i in range(len(physical_devices)):\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[i], True)\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(fold_idx=0, batch_size=64, saved_path=\"\", pretrained_path=\"\", model_name=\"\"):\n",
    "    os.makedirs(os.path.join(saved_path, f\"fold{fold_idx}\"), exist_ok=True)\n",
    "\n",
    "    print(' -> Preparing Data \\n')\n",
    "    \n",
    "    train_data = pd.read_csv(\"../data/new_train_tp.csv\")\n",
    "\n",
    "    train_index, val_index = get_split(fold=fold_idx)\n",
    "    \n",
    "    fold_train_dict = csv_to_dict(train_data.iloc[train_index])\n",
    "    fold_valid_dict = csv_to_dict(train_data.iloc[val_index])\n",
    "\n",
    "    balanced_train_data_loader = BalancedMelSampler(\n",
    "        fold_train_dict,\n",
    "        batch_size=batch_size,\n",
    "        max_length=NUM_FRAMES,\n",
    "        n_classes=24,\n",
    "        use_cutmix=True,\n",
    "        n_classes_in_batch=8,\n",
    "    )\n",
    "\n",
    "    valid_data_loader = MelSampler(\n",
    "        fold_valid_dict,\n",
    "        batch_size=batch_size,\n",
    "        n_classes=24,\n",
    "        max_length=NUM_FRAMES,\n",
    "    )\n",
    "\n",
    "    print(' -> Preparing Model \\n')\n",
    "    model = get_model(\n",
    "        model_name=model_name,\n",
    "        saved_path=saved_path,\n",
    "        pretrained_with_contrastive=False,\n",
    "        pretrained_path=pretrained_path,\n",
    "    )\n",
    "    model._build()\n",
    "    \n",
    "    scheduler = tfa.optimizers.Triangular2CyclicalLearningRate(\n",
    "        initial_learning_rate=1e-4,\n",
    "        maximal_learning_rate=1e-3,\n",
    "        step_size=50,\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(\n",
    "        tfa.optimizers.Lookahead(\n",
    "            tf.keras.optimizers.Adam(learning_rate=scheduler),\n",
    "            10,\n",
    "            0.5,\n",
    "        ),\n",
    "        \"dynamic\",\n",
    "    )\n",
    "    \n",
    "    step_per_epoch = int((len(fold_train_dict)) / balanced_train_data_loader.batch_size)\n",
    "    ma_bce = MovingAverageBCE(\n",
    "        train_data.iloc[train_index],\n",
    "        start_apply_step=20 * step_per_epoch,\n",
    "        momentum=0.9,\n",
    "        name=\"moving_average_loss\",\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        metrics=[TFLWLRAP(num_classes=24, name=\"lwlrap\")],\n",
    "        metric_loss_fn=NpairsLoss(temperature=0.1, name=\"n_pairs\"),\n",
    "        classification_loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        moving_average_bce=ma_bce,\n",
    "    )   \n",
    "\n",
    "    print(' -> Training Model \\n')\n",
    "\n",
    "    callbacks = get_callbacks(False, fold_idx, saved_path=saved_path)\n",
    "    steps_per_epoch = int((len(fold_train_dict)) / balanced_train_data_loader.batch_size)\n",
    "    \n",
    "    model.fit(\n",
    "        balanced_train_data_loader,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=100,\n",
    "        validation_data=valid_data_loader,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "pretrained_folder = \"../logs/2021-02-04/3/\"   # simple\n",
    "log_folder = \"../logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    'densenet121',\n",
    "#     'resnet18',\n",
    "#     'resnet34',\n",
    "#     'resnext50',\n",
    "#     'efficientnetb2',\n",
    "#     \"xception\",\n",
    "]\n",
    "\n",
    "BIGGER_MODELS = [  # BS = 32\n",
    "#     'resnest50',\n",
    "#     'efficientnetb3',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_FOLDERS = {\n",
    "    'densenet121': \"../logs/2021-02-04/3/\",\n",
    "    'resnet18': \"../logs/2021-02-13/14/\",\n",
    "    'resnet34': \"../logs/2021-02-14/0/\",\n",
    "    'resnext50': \"../logs/2021-02-14/1/\",\n",
    "    'efficientnetb2': \"../logs/2021-02-14/2/\",\n",
    "    \"xception\": \"../logs/2021-02-14/3/\",\n",
    "    \"resnest50\": \"../logs/2021-02-14/5/\",\n",
    "    \"efficientnetb3\": \"../logs/2021-02-14/6/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model densenet121\n",
      "\n",
      "\n",
      "Logging results to ../logs/2021-02-16/1/\n",
      "\n",
      "-------------   Fold 1 / 5  -------------\n",
      "\n",
      " -> Preparing Data \n",
      "\n",
      " -> Preparing Model \n",
      "\n",
      " -> Loading weights from ../logs/2021-02-04/3/pretrained_best_fold0.h5\n",
      "\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      " -> Training Model \n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "15/15 - 77s - loss: 0.4301 - lwlrap: 0.1761 - val_loss: 0.3393 - val_lwlrap: 0.2229\n",
      "Epoch 2/100\n",
      "15/15 - 7s - loss: 0.1356 - lwlrap: 0.2158 - val_loss: 0.1969 - val_lwlrap: 0.2677\n",
      "Epoch 3/100\n",
      "15/15 - 7s - loss: 0.1602 - lwlrap: 0.2660 - val_loss: 0.5926 - val_lwlrap: 0.2608\n",
      "Epoch 4/100\n",
      "15/15 - 6s - loss: 0.1880 - lwlrap: 0.3340 - val_loss: 0.1610 - val_lwlrap: 0.4544\n",
      "Epoch 5/100\n",
      "15/15 - 6s - loss: 0.3571 - lwlrap: 0.3489 - val_loss: 0.3296 - val_lwlrap: 0.3007\n",
      "Epoch 6/100\n",
      "15/15 - 6s - loss: 0.2989 - lwlrap: 0.4167 - val_loss: 0.1578 - val_lwlrap: 0.4732\n",
      "Epoch 7/100\n",
      "15/15 - 6s - loss: 0.2853 - lwlrap: 0.4425 - val_loss: 0.1569 - val_lwlrap: 0.5564\n",
      "Epoch 8/100\n",
      "15/15 - 6s - loss: 0.3074 - lwlrap: 0.4751 - val_loss: 0.1470 - val_lwlrap: 0.6321\n",
      "Epoch 9/100\n",
      "15/15 - 7s - loss: 0.1694 - lwlrap: 0.5094 - val_loss: 0.1245 - val_lwlrap: 0.6494\n",
      "Epoch 10/100\n",
      "15/15 - 6s - loss: 0.0811 - lwlrap: 0.4756 - val_loss: 0.1581 - val_lwlrap: 0.6386\n",
      "Epoch 11/100\n",
      "15/15 - 6s - loss: 0.0885 - lwlrap: 0.5053 - val_loss: 0.1506 - val_lwlrap: 0.6570\n",
      "Epoch 12/100\n",
      "15/15 - 6s - loss: 0.2108 - lwlrap: 0.5109 - val_loss: 0.1454 - val_lwlrap: 0.7388\n",
      "Epoch 13/100\n",
      "15/15 - 6s - loss: 0.1074 - lwlrap: 0.6154 - val_loss: 0.1332 - val_lwlrap: 0.7263\n",
      "Epoch 14/100\n",
      "15/15 - 6s - loss: 0.0859 - lwlrap: 0.6131 - val_loss: 0.1250 - val_lwlrap: 0.7314\n",
      "Epoch 15/100\n",
      "15/15 - 6s - loss: 0.1027 - lwlrap: 0.6188 - val_loss: 0.1330 - val_lwlrap: 0.7347\n",
      "Epoch 16/100\n",
      "15/15 - 6s - loss: 0.0737 - lwlrap: 0.5942 - val_loss: 0.1369 - val_lwlrap: 0.7367\n",
      "Epoch 17/100\n",
      "15/15 - 7s - loss: 0.2228 - lwlrap: 0.6281 - val_loss: 0.1287 - val_lwlrap: 0.6941\n",
      "Epoch 18/100\n",
      "15/15 - 6s - loss: 0.2624 - lwlrap: 0.6149 - val_loss: 0.1433 - val_lwlrap: 0.6790\n",
      "Epoch 19/100\n",
      "15/15 - 6s - loss: 0.0692 - lwlrap: 0.6544 - val_loss: 0.1301 - val_lwlrap: 0.7428\n",
      "Epoch 20/100\n",
      "15/15 - 6s - loss: 0.0603 - lwlrap: 0.6570 - val_loss: 0.1231 - val_lwlrap: 0.7539\n",
      "Epoch 21/100\n",
      "15/15 - 7s - loss: 0.0839 - lwlrap: 0.6714 - val_loss: 0.1220 - val_lwlrap: 0.7350\n",
      "Epoch 22/100\n",
      "15/15 - 7s - loss: 0.1056 - lwlrap: 0.6957 - val_loss: 0.1210 - val_lwlrap: 0.7556\n",
      "Epoch 23/100\n",
      "15/15 - 6s - loss: 0.1487 - lwlrap: 0.6902 - val_loss: 0.1305 - val_lwlrap: 0.7535\n",
      "Epoch 24/100\n",
      "15/15 - 6s - loss: 0.1850 - lwlrap: 0.6679 - val_loss: 0.1217 - val_lwlrap: 0.7257\n",
      "Epoch 25/100\n",
      "15/15 - 6s - loss: 0.0899 - lwlrap: 0.6931 - val_loss: 0.1177 - val_lwlrap: 0.7575\n",
      "Epoch 26/100\n",
      "15/15 - 7s - loss: 0.1911 - lwlrap: 0.7765 - val_loss: 0.1111 - val_lwlrap: 0.7589\n",
      "Epoch 27/100\n",
      "15/15 - 6s - loss: 0.1215 - lwlrap: 0.7244 - val_loss: 0.1137 - val_lwlrap: 0.7842\n",
      "Epoch 28/100\n",
      "15/15 - 7s - loss: 0.1004 - lwlrap: 0.7347 - val_loss: 0.1118 - val_lwlrap: 0.7569\n",
      "Epoch 29/100\n",
      "15/15 - 6s - loss: 0.0873 - lwlrap: 0.7154 - val_loss: 0.1118 - val_lwlrap: 0.7691\n",
      "Epoch 30/100\n",
      "15/15 - 6s - loss: 0.1325 - lwlrap: 0.7520 - val_loss: 0.1211 - val_lwlrap: 0.7745\n",
      "Epoch 31/100\n",
      "15/15 - 7s - loss: 0.1591 - lwlrap: 0.7239 - val_loss: 0.1143 - val_lwlrap: 0.7747\n",
      "Epoch 32/100\n",
      "15/15 - 7s - loss: 0.1105 - lwlrap: 0.7742 - val_loss: 0.1109 - val_lwlrap: 0.7831\n",
      "Epoch 33/100\n",
      "15/15 - 7s - loss: 0.1226 - lwlrap: 0.7397 - val_loss: 0.1062 - val_lwlrap: 0.7868\n",
      "Epoch 34/100\n",
      "15/15 - 6s - loss: 0.1001 - lwlrap: 0.7776 - val_loss: 0.1083 - val_lwlrap: 0.7785\n",
      "Epoch 35/100\n",
      "15/15 - 6s - loss: 0.0981 - lwlrap: 0.7395 - val_loss: 0.1159 - val_lwlrap: 0.7617\n",
      "Epoch 36/100\n",
      "15/15 - 7s - loss: 0.1519 - lwlrap: 0.7708 - val_loss: 0.1087 - val_lwlrap: 0.7855\n",
      "Epoch 37/100\n",
      "15/15 - 6s - loss: 0.0991 - lwlrap: 0.7580 - val_loss: 0.1152 - val_lwlrap: 0.7759\n",
      "Epoch 38/100\n",
      "15/15 - 6s - loss: 0.1424 - lwlrap: 0.7728 - val_loss: 0.1218 - val_lwlrap: 0.7673\n",
      "Epoch 39/100\n",
      "15/15 - 7s - loss: 0.1461 - lwlrap: 0.7946 - val_loss: 0.1117 - val_lwlrap: 0.7840\n",
      "Epoch 40/100\n",
      "15/15 - 7s - loss: 0.1498 - lwlrap: 0.7852 - val_loss: 0.1140 - val_lwlrap: 0.7830\n",
      "Epoch 41/100\n",
      "15/15 - 7s - loss: 0.0973 - lwlrap: 0.7883 - val_loss: 0.1172 - val_lwlrap: 0.7807\n",
      "Epoch 42/100\n",
      "15/15 - 6s - loss: 0.0843 - lwlrap: 0.7847 - val_loss: 0.1195 - val_lwlrap: 0.7821\n",
      "Epoch 43/100\n",
      "15/15 - 7s - loss: 0.0901 - lwlrap: 0.8104 - val_loss: 0.1317 - val_lwlrap: 0.7698\n",
      "Epoch 44/100\n",
      "15/15 - 7s - loss: 0.1463 - lwlrap: 0.8164 - val_loss: 0.1204 - val_lwlrap: 0.7859\n",
      "Epoch 45/100\n",
      "15/15 - 6s - loss: 0.0838 - lwlrap: 0.7725 - val_loss: 0.1287 - val_lwlrap: 0.7565\n",
      "Epoch 46/100\n",
      "15/15 - 7s - loss: 0.1577 - lwlrap: 0.7969 - val_loss: 0.1243 - val_lwlrap: 0.7747\n",
      "Epoch 47/100\n",
      "15/15 - 7s - loss: 0.1541 - lwlrap: 0.8282 - val_loss: 0.1176 - val_lwlrap: 0.7774\n",
      "Epoch 48/100\n",
      "15/15 - 7s - loss: 0.0729 - lwlrap: 0.8005 - val_loss: 0.1187 - val_lwlrap: 0.7808\n",
      "Epoch 49/100\n",
      "15/15 - 6s - loss: 0.1634 - lwlrap: 0.8078 - val_loss: 0.1132 - val_lwlrap: 0.7896\n",
      "Epoch 50/100\n",
      "15/15 - 7s - loss: 0.1602 - lwlrap: 0.7934 - val_loss: 0.1133 - val_lwlrap: 0.7725\n",
      "Epoch 51/100\n",
      "15/15 - 6s - loss: 0.0710 - lwlrap: 0.7937 - val_loss: 0.1167 - val_lwlrap: 0.7867\n",
      "Epoch 52/100\n",
      "15/15 - 7s - loss: 0.0838 - lwlrap: 0.8682 - val_loss: 0.1167 - val_lwlrap: 0.7952\n",
      "Epoch 53/100\n",
      "15/15 - 7s - loss: 0.1680 - lwlrap: 0.8241 - val_loss: 0.1165 - val_lwlrap: 0.7999\n",
      "Epoch 54/100\n",
      "15/15 - 7s - loss: 0.0783 - lwlrap: 0.8201 - val_loss: 0.1198 - val_lwlrap: 0.7957\n",
      "Epoch 55/100\n",
      "15/15 - 7s - loss: 0.1525 - lwlrap: 0.8428 - val_loss: 0.1226 - val_lwlrap: 0.7920\n",
      "Epoch 56/100\n",
      "15/15 - 7s - loss: 0.0747 - lwlrap: 0.8329 - val_loss: 0.1235 - val_lwlrap: 0.8055\n",
      "Epoch 57/100\n",
      "15/15 - 7s - loss: 0.0758 - lwlrap: 0.8537 - val_loss: 0.1314 - val_lwlrap: 0.7909\n",
      "Epoch 58/100\n",
      "15/15 - 6s - loss: 0.1026 - lwlrap: 0.8171 - val_loss: 0.1299 - val_lwlrap: 0.7851\n",
      "Epoch 59/100\n",
      "15/15 - 7s - loss: 0.1662 - lwlrap: 0.8569 - val_loss: 0.1271 - val_lwlrap: 0.7926\n",
      "Epoch 60/100\n",
      "15/15 - 7s - loss: 0.0745 - lwlrap: 0.8417 - val_loss: 0.1306 - val_lwlrap: 0.8033\n",
      "Epoch 61/100\n",
      "15/15 - 7s - loss: 0.1700 - lwlrap: 0.8559 - val_loss: 0.1293 - val_lwlrap: 0.7860\n",
      "Epoch 62/100\n",
      "15/15 - 6s - loss: 0.1857 - lwlrap: 0.8182 - val_loss: 0.1346 - val_lwlrap: 0.7842\n",
      "Epoch 63/100\n",
      "15/15 - 6s - loss: 0.1787 - lwlrap: 0.8484 - val_loss: 0.1310 - val_lwlrap: 0.7972\n",
      "Epoch 64/100\n",
      "15/15 - 7s - loss: 0.0779 - lwlrap: 0.8333 - val_loss: 0.1368 - val_lwlrap: 0.8013\n",
      "Epoch 65/100\n",
      "15/15 - 6s - loss: 0.1781 - lwlrap: 0.8410 - val_loss: 0.1377 - val_lwlrap: 0.7980\n",
      "Epoch 66/100\n",
      "15/15 - 7s - loss: 0.0680 - lwlrap: 0.8558 - val_loss: 0.1296 - val_lwlrap: 0.8104\n",
      "Epoch 67/100\n",
      "15/15 - 7s - loss: 0.1722 - lwlrap: 0.8767 - val_loss: 0.1354 - val_lwlrap: 0.8049\n",
      "Epoch 68/100\n",
      "15/15 - 7s - loss: 0.1646 - lwlrap: 0.8504 - val_loss: 0.1302 - val_lwlrap: 0.8199\n",
      "Epoch 69/100\n",
      "15/15 - 7s - loss: 0.1695 - lwlrap: 0.8634 - val_loss: 0.1297 - val_lwlrap: 0.8134\n",
      "Epoch 70/100\n",
      "15/15 - 6s - loss: 0.0819 - lwlrap: 0.8524 - val_loss: 0.1272 - val_lwlrap: 0.8114\n",
      "Epoch 71/100\n",
      "15/15 - 7s - loss: 0.1705 - lwlrap: 0.8555 - val_loss: 0.1290 - val_lwlrap: 0.8013\n",
      "Epoch 72/100\n",
      "15/15 - 7s - loss: 0.1841 - lwlrap: 0.8842 - val_loss: 0.1234 - val_lwlrap: 0.8040\n",
      "Epoch 73/100\n",
      "15/15 - 6s - loss: 0.0827 - lwlrap: 0.8556 - val_loss: 0.1405 - val_lwlrap: 0.7977\n",
      "Epoch 74/100\n",
      "15/15 - 7s - loss: 0.1772 - lwlrap: 0.8600 - val_loss: 0.1356 - val_lwlrap: 0.8058\n",
      "Epoch 75/100\n",
      "15/15 - 7s - loss: 0.0600 - lwlrap: 0.8400 - val_loss: 0.1350 - val_lwlrap: 0.7820\n",
      "Epoch 76/100\n",
      "15/15 - 6s - loss: 0.1719 - lwlrap: 0.8626 - val_loss: 0.1327 - val_lwlrap: 0.7946\n",
      "Epoch 77/100\n",
      "15/15 - 7s - loss: 0.1755 - lwlrap: 0.8767 - val_loss: 0.1350 - val_lwlrap: 0.8039\n",
      "Epoch 78/100\n",
      "15/15 - 7s - loss: 0.0630 - lwlrap: 0.8507 - val_loss: 0.1272 - val_lwlrap: 0.7911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "15/15 - 6s - loss: 0.0986 - lwlrap: 0.8440 - val_loss: 0.1279 - val_lwlrap: 0.8024\n",
      "Epoch 80/100\n",
      "15/15 - 7s - loss: 0.1723 - lwlrap: 0.9241 - val_loss: 0.1262 - val_lwlrap: 0.8103\n",
      "Epoch 81/100\n",
      "15/15 - 6s - loss: 0.1776 - lwlrap: 0.8709 - val_loss: 0.1381 - val_lwlrap: 0.7948\n",
      "Epoch 82/100\n",
      "15/15 - 7s - loss: 0.1862 - lwlrap: 0.8729 - val_loss: 0.1338 - val_lwlrap: 0.8109\n",
      "Epoch 83/100\n",
      "15/15 - 7s - loss: 0.1911 - lwlrap: 0.8781 - val_loss: 0.1451 - val_lwlrap: 0.8112\n",
      "Epoch 84/100\n",
      "15/15 - 6s - loss: 0.0756 - lwlrap: 0.8714 - val_loss: 0.1495 - val_lwlrap: 0.7984\n",
      "Epoch 85/100\n",
      "15/15 - 7s - loss: 0.1922 - lwlrap: 0.8863 - val_loss: 0.1440 - val_lwlrap: 0.8048\n",
      "Epoch 86/100\n",
      "15/15 - 6s - loss: 0.0880 - lwlrap: 0.8560 - val_loss: 0.1435 - val_lwlrap: 0.7977\n",
      "Epoch 87/100\n",
      "15/15 - 7s - loss: 0.1755 - lwlrap: 0.8655 - val_loss: 0.1415 - val_lwlrap: 0.7863\n",
      "Epoch 88/100\n",
      "15/15 - 6s - loss: 0.0884 - lwlrap: 0.8508 - val_loss: 0.1343 - val_lwlrap: 0.7910\n",
      "Epoch 89/100\n",
      "15/15 - 6s - loss: 0.0667 - lwlrap: 0.8393 - val_loss: 0.1462 - val_lwlrap: 0.7999\n",
      "Epoch 90/100\n",
      "15/15 - 7s - loss: 0.0856 - lwlrap: 0.8579 - val_loss: 0.1356 - val_lwlrap: 0.7977\n",
      "Epoch 91/100\n",
      "15/15 - 7s - loss: 0.1746 - lwlrap: 0.8926 - val_loss: 0.1297 - val_lwlrap: 0.8022\n",
      "Epoch 92/100\n",
      "15/15 - 7s - loss: 0.0714 - lwlrap: 0.8958 - val_loss: 0.1332 - val_lwlrap: 0.7980\n",
      "Epoch 93/100\n",
      "15/15 - 7s - loss: 0.0865 - lwlrap: 0.9134 - val_loss: 0.1286 - val_lwlrap: 0.8075\n",
      "Epoch 94/100\n",
      "15/15 - 7s - loss: 0.1677 - lwlrap: 0.8877 - val_loss: 0.1321 - val_lwlrap: 0.7986\n",
      "Epoch 95/100\n",
      "15/15 - 7s - loss: 0.1760 - lwlrap: 0.8692 - val_loss: 0.1326 - val_lwlrap: 0.8059\n",
      "Epoch 96/100\n",
      "15/15 - 7s - loss: 0.0618 - lwlrap: 0.8884 - val_loss: 0.1425 - val_lwlrap: 0.8040\n",
      "Epoch 97/100\n",
      "15/15 - 7s - loss: 0.0667 - lwlrap: 0.9072 - val_loss: 0.1375 - val_lwlrap: 0.8054\n",
      "Epoch 98/100\n",
      "15/15 - 7s - loss: 0.1802 - lwlrap: 0.8717 - val_loss: 0.1368 - val_lwlrap: 0.8030\n",
      "\n",
      "-------------   Fold 2 / 5  -------------\n",
      "\n",
      " -> Preparing Data \n",
      "\n",
      " -> Preparing Model \n",
      "\n",
      " -> Loading weights from ../logs/2021-02-04/3/pretrained_best_fold1.h5\n",
      "\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      " -> Training Model \n",
      "\n",
      "Epoch 1/100\n",
      "15/15 - 76s - loss: 0.3125 - lwlrap: 0.1870 - val_loss: 0.3466 - val_lwlrap: 0.2018\n",
      "Epoch 2/100\n",
      "15/15 - 7s - loss: 0.2388 - lwlrap: 0.2243 - val_loss: 0.2446 - val_lwlrap: 0.3224\n",
      "Epoch 3/100\n",
      "15/15 - 6s - loss: 0.3520 - lwlrap: 0.2853 - val_loss: 0.1873 - val_lwlrap: 0.3391\n",
      "Epoch 4/100\n",
      "15/15 - 6s - loss: 0.2591 - lwlrap: 0.3189 - val_loss: 0.1988 - val_lwlrap: 0.4508\n",
      "Epoch 5/100\n",
      "15/15 - 7s - loss: 0.2050 - lwlrap: 0.4118 - val_loss: 0.2256 - val_lwlrap: 0.4671\n",
      "Epoch 6/100\n",
      "15/15 - 6s - loss: 0.2259 - lwlrap: 0.4000 - val_loss: 0.1926 - val_lwlrap: 0.6127\n",
      "Epoch 7/100\n",
      "15/15 - 6s - loss: 0.4347 - lwlrap: 0.4597 - val_loss: 0.1692 - val_lwlrap: 0.6859\n",
      "Epoch 8/100\n",
      "15/15 - 7s - loss: 0.1150 - lwlrap: 0.5163 - val_loss: 0.1556 - val_lwlrap: 0.7157\n",
      "Epoch 9/100\n",
      "15/15 - 6s - loss: 0.1999 - lwlrap: 0.5148 - val_loss: 0.1384 - val_lwlrap: 0.7009\n",
      "Epoch 10/100\n",
      "15/15 - 7s - loss: 0.2026 - lwlrap: 0.5761 - val_loss: 0.1348 - val_lwlrap: 0.7151\n",
      "Epoch 11/100\n",
      "15/15 - 7s - loss: 0.2435 - lwlrap: 0.5564 - val_loss: 0.1351 - val_lwlrap: 0.6834\n",
      "Epoch 12/100\n",
      "15/15 - 7s - loss: 0.1240 - lwlrap: 0.5900 - val_loss: 0.1120 - val_lwlrap: 0.7563\n",
      "Epoch 13/100\n",
      "15/15 - 6s - loss: 0.0703 - lwlrap: 0.6269 - val_loss: 0.1111 - val_lwlrap: 0.7737\n",
      "Epoch 14/100\n",
      "15/15 - 6s - loss: 0.1694 - lwlrap: 0.6246 - val_loss: 0.1089 - val_lwlrap: 0.7699\n",
      "Epoch 15/100\n",
      "15/15 - 7s - loss: 0.2059 - lwlrap: 0.6143 - val_loss: 0.1228 - val_lwlrap: 0.7516\n",
      "Epoch 16/100\n",
      "15/15 - 6s - loss: 0.0909 - lwlrap: 0.6554 - val_loss: 0.1062 - val_lwlrap: 0.7926\n",
      "Epoch 17/100\n",
      "15/15 - 6s - loss: 0.1636 - lwlrap: 0.6764 - val_loss: 0.1242 - val_lwlrap: 0.7574\n",
      "Epoch 18/100\n",
      "15/15 - 7s - loss: 0.1093 - lwlrap: 0.6581 - val_loss: 0.1049 - val_lwlrap: 0.7598\n",
      "Epoch 19/100\n",
      "15/15 - 6s - loss: 0.1336 - lwlrap: 0.6548 - val_loss: 0.1088 - val_lwlrap: 0.7481\n",
      "Epoch 20/100\n",
      "15/15 - 7s - loss: 0.1388 - lwlrap: 0.6676 - val_loss: 0.1000 - val_lwlrap: 0.7874\n",
      "Epoch 21/100\n",
      "15/15 - 6s - loss: 0.1443 - lwlrap: 0.6347 - val_loss: 0.1089 - val_lwlrap: 0.7908\n",
      "Epoch 22/100\n",
      "15/15 - 7s - loss: 0.0991 - lwlrap: 0.6921 - val_loss: 0.1130 - val_lwlrap: 0.7918\n",
      "Epoch 23/100\n",
      "15/15 - 7s - loss: 0.0759 - lwlrap: 0.7197 - val_loss: 0.1143 - val_lwlrap: 0.7770\n",
      "Epoch 24/100\n",
      "15/15 - 7s - loss: 0.0845 - lwlrap: 0.6945 - val_loss: 0.1062 - val_lwlrap: 0.7740\n",
      "Epoch 25/100\n",
      "15/15 - 6s - loss: 0.1615 - lwlrap: 0.7036 - val_loss: 0.1092 - val_lwlrap: 0.7873\n",
      "Epoch 26/100\n",
      "15/15 - 6s - loss: 0.1193 - lwlrap: 0.7261 - val_loss: 0.1110 - val_lwlrap: 0.7940\n",
      "Epoch 27/100\n",
      "15/15 - 7s - loss: 0.1477 - lwlrap: 0.7309 - val_loss: 0.1089 - val_lwlrap: 0.7972\n",
      "Epoch 28/100\n",
      "15/15 - 7s - loss: 0.0982 - lwlrap: 0.7730 - val_loss: 0.1082 - val_lwlrap: 0.7957\n",
      "Epoch 29/100\n",
      "15/15 - 6s - loss: 0.1036 - lwlrap: 0.7360 - val_loss: 0.1109 - val_lwlrap: 0.8064\n",
      "Epoch 30/100\n",
      "15/15 - 7s - loss: 0.1177 - lwlrap: 0.7422 - val_loss: 0.1092 - val_lwlrap: 0.8151\n",
      "Epoch 31/100\n",
      "15/15 - 7s - loss: 0.0834 - lwlrap: 0.7743 - val_loss: 0.1050 - val_lwlrap: 0.8110\n",
      "Epoch 32/100\n",
      "15/15 - 7s - loss: 0.1050 - lwlrap: 0.7948 - val_loss: 0.1096 - val_lwlrap: 0.8285\n",
      "Epoch 33/100\n",
      "15/15 - 6s - loss: 0.1425 - lwlrap: 0.7587 - val_loss: 0.1195 - val_lwlrap: 0.8123\n",
      "Epoch 34/100\n",
      "15/15 - 7s - loss: 0.1395 - lwlrap: 0.7825 - val_loss: 0.1138 - val_lwlrap: 0.8268\n",
      "Epoch 35/100\n",
      "15/15 - 7s - loss: 0.1107 - lwlrap: 0.7973 - val_loss: 0.1092 - val_lwlrap: 0.8249\n",
      "Epoch 36/100\n",
      "15/15 - 7s - loss: 0.1113 - lwlrap: 0.8095 - val_loss: 0.1095 - val_lwlrap: 0.8266\n",
      "Epoch 37/100\n",
      "15/15 - 7s - loss: 0.0894 - lwlrap: 0.7951 - val_loss: 0.1198 - val_lwlrap: 0.8170\n",
      "Epoch 38/100\n",
      "15/15 - 7s - loss: 0.1303 - lwlrap: 0.8090 - val_loss: 0.1125 - val_lwlrap: 0.8299\n",
      "Epoch 39/100\n",
      "15/15 - 7s - loss: 0.1349 - lwlrap: 0.7975 - val_loss: 0.1048 - val_lwlrap: 0.8450\n",
      "Epoch 40/100\n",
      "15/15 - 7s - loss: 0.1117 - lwlrap: 0.8150 - val_loss: 0.1072 - val_lwlrap: 0.8408\n",
      "Epoch 41/100\n",
      "15/15 - 6s - loss: 0.1055 - lwlrap: 0.7963 - val_loss: 0.1180 - val_lwlrap: 0.8282\n",
      "Epoch 42/100\n",
      "15/15 - 7s - loss: 0.0993 - lwlrap: 0.7838 - val_loss: 0.1240 - val_lwlrap: 0.8215\n",
      "Epoch 43/100\n",
      "15/15 - 7s - loss: 0.1131 - lwlrap: 0.8229 - val_loss: 0.1170 - val_lwlrap: 0.8338\n",
      "Epoch 44/100\n",
      "15/15 - 7s - loss: 0.1228 - lwlrap: 0.8057 - val_loss: 0.1159 - val_lwlrap: 0.8268\n",
      "Epoch 45/100\n",
      "15/15 - 7s - loss: 0.0926 - lwlrap: 0.7906 - val_loss: 0.1225 - val_lwlrap: 0.8350\n",
      "Epoch 46/100\n",
      "15/15 - 7s - loss: 0.1154 - lwlrap: 0.8411 - val_loss: 0.1121 - val_lwlrap: 0.8380\n",
      "Epoch 47/100\n",
      "15/15 - 7s - loss: 0.1397 - lwlrap: 0.8364 - val_loss: 0.1046 - val_lwlrap: 0.8502\n",
      "Epoch 48/100\n",
      "15/15 - 7s - loss: 0.0746 - lwlrap: 0.8264 - val_loss: 0.1148 - val_lwlrap: 0.8422\n",
      "Epoch 49/100\n",
      "15/15 - 7s - loss: 0.1281 - lwlrap: 0.8511 - val_loss: 0.1151 - val_lwlrap: 0.8454\n",
      "Epoch 50/100\n",
      "15/15 - 7s - loss: 0.1482 - lwlrap: 0.8639 - val_loss: 0.1105 - val_lwlrap: 0.8537\n",
      "Epoch 51/100\n",
      "15/15 - 7s - loss: 0.1470 - lwlrap: 0.8237 - val_loss: 0.1131 - val_lwlrap: 0.8509\n",
      "Epoch 52/100\n",
      "15/15 - 7s - loss: 0.0724 - lwlrap: 0.8258 - val_loss: 0.1043 - val_lwlrap: 0.8596\n",
      "Epoch 53/100\n",
      "15/15 - 7s - loss: 0.1491 - lwlrap: 0.8361 - val_loss: 0.1054 - val_lwlrap: 0.8407\n",
      "Epoch 54/100\n",
      "15/15 - 7s - loss: 0.0944 - lwlrap: 0.8293 - val_loss: 0.1080 - val_lwlrap: 0.8439\n",
      "Epoch 55/100\n",
      "15/15 - 7s - loss: 0.0769 - lwlrap: 0.8449 - val_loss: 0.1136 - val_lwlrap: 0.8373\n",
      "Epoch 56/100\n",
      "15/15 - 6s - loss: 0.0784 - lwlrap: 0.8307 - val_loss: 0.1148 - val_lwlrap: 0.8378\n",
      "Epoch 57/100\n",
      "15/15 - 6s - loss: 0.1500 - lwlrap: 0.8386 - val_loss: 0.1202 - val_lwlrap: 0.8372\n",
      "Epoch 58/100\n",
      "15/15 - 7s - loss: 0.1531 - lwlrap: 0.8736 - val_loss: 0.1234 - val_lwlrap: 0.8265\n",
      "Epoch 59/100\n",
      "15/15 - 7s - loss: 0.1234 - lwlrap: 0.8535 - val_loss: 0.1180 - val_lwlrap: 0.8417\n",
      "Epoch 60/100\n",
      "15/15 - 7s - loss: 0.1528 - lwlrap: 0.8527 - val_loss: 0.1165 - val_lwlrap: 0.8332\n",
      "Epoch 61/100\n",
      "15/15 - 7s - loss: 0.1686 - lwlrap: 0.8606 - val_loss: 0.1164 - val_lwlrap: 0.8410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "15/15 - 7s - loss: 0.1683 - lwlrap: 0.8397 - val_loss: 0.1184 - val_lwlrap: 0.8345\n",
      "Epoch 63/100\n",
      "15/15 - 6s - loss: 0.0642 - lwlrap: 0.8712 - val_loss: 0.1155 - val_lwlrap: 0.8560\n",
      "Epoch 64/100\n",
      "15/15 - 7s - loss: 0.0830 - lwlrap: 0.8533 - val_loss: 0.1224 - val_lwlrap: 0.8511\n",
      "Epoch 65/100\n",
      "15/15 - 7s - loss: 0.0656 - lwlrap: 0.8354 - val_loss: 0.1230 - val_lwlrap: 0.8518\n",
      "Epoch 66/100\n",
      "15/15 - 7s - loss: 0.0715 - lwlrap: 0.8710 - val_loss: 0.1240 - val_lwlrap: 0.8529\n",
      "Epoch 67/100\n",
      "15/15 - 7s - loss: 0.0810 - lwlrap: 0.8501 - val_loss: 0.1231 - val_lwlrap: 0.8536\n",
      "Epoch 68/100\n",
      "15/15 - 7s - loss: 0.1669 - lwlrap: 0.8561 - val_loss: 0.1219 - val_lwlrap: 0.8589\n",
      "Epoch 69/100\n",
      "15/15 - 7s - loss: 0.1797 - lwlrap: 0.8632 - val_loss: 0.1156 - val_lwlrap: 0.8597\n",
      "Epoch 70/100\n",
      "15/15 - 7s - loss: 0.1710 - lwlrap: 0.8659 - val_loss: 0.1183 - val_lwlrap: 0.8574\n",
      "Epoch 71/100\n",
      "15/15 - 7s - loss: 0.0613 - lwlrap: 0.8803 - val_loss: 0.1138 - val_lwlrap: 0.8424\n",
      "Epoch 72/100\n",
      "15/15 - 6s - loss: 0.0757 - lwlrap: 0.8543 - val_loss: 0.1147 - val_lwlrap: 0.8472\n",
      "Epoch 73/100\n",
      "15/15 - 7s - loss: 0.0624 - lwlrap: 0.8864 - val_loss: 0.1163 - val_lwlrap: 0.8467\n",
      "Epoch 74/100\n",
      "15/15 - 7s - loss: 0.0757 - lwlrap: 0.9065 - val_loss: 0.1177 - val_lwlrap: 0.8522\n",
      "Epoch 75/100\n",
      "15/15 - 7s - loss: 0.1609 - lwlrap: 0.8603 - val_loss: 0.1260 - val_lwlrap: 0.8475\n",
      "Epoch 76/100\n",
      "15/15 - 7s - loss: 0.0684 - lwlrap: 0.8716 - val_loss: 0.1284 - val_lwlrap: 0.8395\n",
      "Epoch 77/100\n",
      "15/15 - 6s - loss: 0.0693 - lwlrap: 0.8581 - val_loss: 0.1305 - val_lwlrap: 0.8445\n",
      "Epoch 78/100\n",
      "15/15 - 6s - loss: 0.0677 - lwlrap: 0.8666 - val_loss: 0.1215 - val_lwlrap: 0.8499\n",
      "Epoch 79/100\n",
      "15/15 - 7s - loss: 0.0738 - lwlrap: 0.8762 - val_loss: 0.1246 - val_lwlrap: 0.8432\n",
      "Epoch 80/100\n",
      "15/15 - 7s - loss: 0.0644 - lwlrap: 0.8996 - val_loss: 0.1244 - val_lwlrap: 0.8443\n",
      "Epoch 81/100\n",
      "15/15 - 6s - loss: 0.0578 - lwlrap: 0.8569 - val_loss: 0.1207 - val_lwlrap: 0.8437\n",
      "Epoch 82/100\n",
      "15/15 - 7s - loss: 0.1531 - lwlrap: 0.9031 - val_loss: 0.1180 - val_lwlrap: 0.8461\n",
      "Epoch 83/100\n",
      "15/15 - 7s - loss: 0.1686 - lwlrap: 0.8839 - val_loss: 0.1246 - val_lwlrap: 0.8474\n",
      "Epoch 84/100\n",
      "15/15 - 7s - loss: 0.0584 - lwlrap: 0.9203 - val_loss: 0.1229 - val_lwlrap: 0.8439\n",
      "Epoch 85/100\n",
      "15/15 - 7s - loss: 0.1540 - lwlrap: 0.8806 - val_loss: 0.1226 - val_lwlrap: 0.8471\n",
      "Epoch 86/100\n",
      "15/15 - 7s - loss: 0.0700 - lwlrap: 0.8783 - val_loss: 0.1279 - val_lwlrap: 0.8493\n",
      "Epoch 87/100\n",
      "15/15 - 7s - loss: 0.0555 - lwlrap: 0.9008 - val_loss: 0.1262 - val_lwlrap: 0.8416\n",
      "Epoch 88/100\n",
      "15/15 - 7s - loss: 0.1643 - lwlrap: 0.8989 - val_loss: 0.1258 - val_lwlrap: 0.8437\n",
      "Epoch 89/100\n",
      "15/15 - 7s - loss: 0.1545 - lwlrap: 0.9020 - val_loss: 0.1254 - val_lwlrap: 0.8469\n",
      "Epoch 90/100\n",
      "15/15 - 7s - loss: 0.0566 - lwlrap: 0.8797 - val_loss: 0.1266 - val_lwlrap: 0.8433\n",
      "Epoch 91/100\n",
      "15/15 - 7s - loss: 0.1630 - lwlrap: 0.9154 - val_loss: 0.1346 - val_lwlrap: 0.8393\n",
      "Epoch 92/100\n",
      "15/15 - 6s - loss: 0.1701 - lwlrap: 0.8795 - val_loss: 0.1367 - val_lwlrap: 0.8309\n",
      "Epoch 93/100\n",
      "15/15 - 6s - loss: 0.0600 - lwlrap: 0.8843 - val_loss: 0.1369 - val_lwlrap: 0.8277\n",
      "Epoch 94/100\n",
      "15/15 - 7s - loss: 0.1699 - lwlrap: 0.9041 - val_loss: 0.1331 - val_lwlrap: 0.8366\n",
      "Epoch 95/100\n",
      "15/15 - 7s - loss: 0.1616 - lwlrap: 0.9000 - val_loss: 0.1289 - val_lwlrap: 0.8373\n",
      "Epoch 96/100\n",
      "15/15 - 6s - loss: 0.1506 - lwlrap: 0.8949 - val_loss: 0.1301 - val_lwlrap: 0.8332\n",
      "Epoch 97/100\n",
      "15/15 - 7s - loss: 0.0653 - lwlrap: 0.8938 - val_loss: 0.1298 - val_lwlrap: 0.8434\n",
      "Epoch 98/100\n",
      "15/15 - 7s - loss: 0.1567 - lwlrap: 0.9099 - val_loss: 0.1331 - val_lwlrap: 0.8417\n",
      "Epoch 99/100\n",
      "15/15 - 7s - loss: 0.0530 - lwlrap: 0.9121 - val_loss: 0.1305 - val_lwlrap: 0.8351\n",
      "\n",
      "-------------   Fold 3 / 5  -------------\n",
      "\n",
      " -> Preparing Data \n",
      "\n",
      " -> Preparing Model \n",
      "\n",
      " -> Loading weights from ../logs/2021-02-04/3/pretrained_best_fold2.h5\n",
      "\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      " -> Training Model \n",
      "\n",
      "Epoch 1/100\n",
      "15/15 - 70s - loss: 0.2708 - lwlrap: 0.1903 - val_loss: 0.3818 - val_lwlrap: 0.1821\n",
      "Epoch 2/100\n",
      "15/15 - 6s - loss: 0.3116 - lwlrap: 0.2194 - val_loss: 0.2349 - val_lwlrap: 0.2665\n",
      "Epoch 3/100\n",
      "15/15 - 6s - loss: 0.1884 - lwlrap: 0.2626 - val_loss: 0.1688 - val_lwlrap: 0.4002\n",
      "Epoch 4/100\n",
      "15/15 - 7s - loss: 0.3509 - lwlrap: 0.3299 - val_loss: 0.1750 - val_lwlrap: 0.5164\n",
      "Epoch 5/100\n",
      "15/15 - 7s - loss: 0.1542 - lwlrap: 0.3866 - val_loss: 0.1981 - val_lwlrap: 0.4673\n",
      "Epoch 6/100\n",
      "15/15 - 6s - loss: 0.2243 - lwlrap: 0.3979 - val_loss: 0.1742 - val_lwlrap: 0.5651\n",
      "Epoch 7/100\n",
      "15/15 - 7s - loss: 0.0990 - lwlrap: 0.4687 - val_loss: 0.1666 - val_lwlrap: 0.6186\n",
      "Epoch 8/100\n",
      "15/15 - 7s - loss: 0.0887 - lwlrap: 0.4597 - val_loss: 0.1575 - val_lwlrap: 0.6298\n",
      "Epoch 9/100\n",
      "15/15 - 6s - loss: 0.1100 - lwlrap: 0.4418 - val_loss: 0.1825 - val_lwlrap: 0.5330\n",
      "Epoch 10/100\n",
      "15/15 - 6s - loss: 0.0930 - lwlrap: 0.4945 - val_loss: 0.1451 - val_lwlrap: 0.6749\n",
      "Epoch 11/100\n",
      "15/15 - 6s - loss: 0.1734 - lwlrap: 0.4903 - val_loss: 0.1337 - val_lwlrap: 0.6051\n",
      "Epoch 12/100\n",
      "15/15 - 6s - loss: 0.1257 - lwlrap: 0.5229 - val_loss: 0.1129 - val_lwlrap: 0.7001\n",
      "Epoch 13/100\n",
      "15/15 - 6s - loss: 0.0813 - lwlrap: 0.5327 - val_loss: 0.1151 - val_lwlrap: 0.7199\n",
      "Epoch 14/100\n",
      "15/15 - 6s - loss: 0.1426 - lwlrap: 0.5452 - val_loss: 0.1189 - val_lwlrap: 0.7203\n",
      "Epoch 15/100\n",
      "15/15 - 6s - loss: 0.1010 - lwlrap: 0.5641 - val_loss: 0.1207 - val_lwlrap: 0.7171\n",
      "Epoch 16/100\n",
      "15/15 - 7s - loss: 0.1008 - lwlrap: 0.6501 - val_loss: 0.1182 - val_lwlrap: 0.7098\n",
      "Epoch 17/100\n",
      "15/15 - 6s - loss: 0.0823 - lwlrap: 0.6142 - val_loss: 0.1510 - val_lwlrap: 0.6344\n",
      "Epoch 18/100\n",
      "15/15 - 7s - loss: 0.0728 - lwlrap: 0.6460 - val_loss: 0.1242 - val_lwlrap: 0.7024\n",
      "Epoch 19/100\n",
      "15/15 - 6s - loss: 0.0770 - lwlrap: 0.6862 - val_loss: 0.1190 - val_lwlrap: 0.6856\n",
      "Epoch 20/100\n",
      "15/15 - 6s - loss: 0.1036 - lwlrap: 0.6469 - val_loss: 0.1109 - val_lwlrap: 0.7148\n",
      "Epoch 21/100\n",
      "15/15 - 6s - loss: 0.1484 - lwlrap: 0.6379 - val_loss: 0.1056 - val_lwlrap: 0.7060\n",
      "Epoch 22/100\n",
      "15/15 - 7s - loss: 0.0949 - lwlrap: 0.6709 - val_loss: 0.1094 - val_lwlrap: 0.7150\n",
      "Epoch 23/100\n",
      "15/15 - 7s - loss: 0.0823 - lwlrap: 0.7103 - val_loss: 0.1230 - val_lwlrap: 0.6914\n",
      "Epoch 24/100\n",
      "15/15 - 7s - loss: 0.0880 - lwlrap: 0.7392 - val_loss: 0.1107 - val_lwlrap: 0.7097\n",
      "Epoch 25/100\n",
      "15/15 - 6s - loss: 0.0908 - lwlrap: 0.6460 - val_loss: 0.1144 - val_lwlrap: 0.6835\n",
      "Epoch 26/100\n",
      "15/15 - 7s - loss: 0.1687 - lwlrap: 0.7257 - val_loss: 0.0991 - val_lwlrap: 0.7402\n",
      "Epoch 27/100\n",
      "15/15 - 7s - loss: 0.1255 - lwlrap: 0.6698 - val_loss: 0.1043 - val_lwlrap: 0.7387\n",
      "Epoch 28/100\n",
      "15/15 - 7s - loss: 0.1467 - lwlrap: 0.7589 - val_loss: 0.0997 - val_lwlrap: 0.7441\n",
      "Epoch 29/100\n",
      "15/15 - 6s - loss: 0.1467 - lwlrap: 0.6923 - val_loss: 0.0981 - val_lwlrap: 0.7582\n",
      "Epoch 30/100\n",
      "15/15 - 7s - loss: 0.1902 - lwlrap: 0.7440 - val_loss: 0.1015 - val_lwlrap: 0.7484\n",
      "Epoch 31/100\n",
      "15/15 - 6s - loss: 0.1340 - lwlrap: 0.7245 - val_loss: 0.1057 - val_lwlrap: 0.7260\n",
      "Epoch 32/100\n",
      "15/15 - 7s - loss: 0.1467 - lwlrap: 0.6994 - val_loss: 0.1099 - val_lwlrap: 0.7208\n",
      "Epoch 33/100\n",
      "15/15 - 6s - loss: 0.1181 - lwlrap: 0.7396 - val_loss: 0.1177 - val_lwlrap: 0.7289\n",
      "Epoch 34/100\n",
      "15/15 - 7s - loss: 0.1198 - lwlrap: 0.7517 - val_loss: 0.1151 - val_lwlrap: 0.7281\n",
      "Epoch 35/100\n",
      "15/15 - 7s - loss: 0.1322 - lwlrap: 0.7677 - val_loss: 0.1124 - val_lwlrap: 0.7449\n",
      "Epoch 36/100\n",
      "15/15 - 7s - loss: 0.1289 - lwlrap: 0.7300 - val_loss: 0.1118 - val_lwlrap: 0.7465\n",
      "Epoch 37/100\n",
      "15/15 - 6s - loss: 0.1625 - lwlrap: 0.7286 - val_loss: 0.1046 - val_lwlrap: 0.7459\n",
      "Epoch 38/100\n",
      "15/15 - 7s - loss: 0.1011 - lwlrap: 0.7631 - val_loss: 0.1078 - val_lwlrap: 0.7361\n",
      "Epoch 39/100\n",
      "15/15 - 7s - loss: 0.1580 - lwlrap: 0.7399 - val_loss: 0.1038 - val_lwlrap: 0.7407\n",
      "Epoch 40/100\n",
      "15/15 - 6s - loss: 0.0849 - lwlrap: 0.7206 - val_loss: 0.1074 - val_lwlrap: 0.7564\n",
      "Epoch 41/100\n",
      "15/15 - 6s - loss: 0.1177 - lwlrap: 0.7306 - val_loss: 0.1153 - val_lwlrap: 0.7349\n",
      "Epoch 42/100\n",
      "15/15 - 6s - loss: 0.1608 - lwlrap: 0.7471 - val_loss: 0.1087 - val_lwlrap: 0.7481\n",
      "Epoch 43/100\n",
      "15/15 - 7s - loss: 0.1551 - lwlrap: 0.7882 - val_loss: 0.1075 - val_lwlrap: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "15/15 - 7s - loss: 0.1804 - lwlrap: 0.7813 - val_loss: 0.1043 - val_lwlrap: 0.7521\n",
      "Epoch 45/100\n",
      "15/15 - 7s - loss: 0.1781 - lwlrap: 0.7892 - val_loss: 0.1068 - val_lwlrap: 0.7626\n",
      "Epoch 46/100\n",
      "15/15 - 7s - loss: 0.1177 - lwlrap: 0.7796 - val_loss: 0.1118 - val_lwlrap: 0.7651\n",
      "Epoch 47/100\n",
      "15/15 - 7s - loss: 0.1712 - lwlrap: 0.7696 - val_loss: 0.1129 - val_lwlrap: 0.7543\n",
      "Epoch 48/100\n",
      "15/15 - 6s - loss: 0.0732 - lwlrap: 0.7962 - val_loss: 0.1145 - val_lwlrap: 0.7517\n",
      "Epoch 49/100\n",
      "15/15 - 6s - loss: 0.1071 - lwlrap: 0.7910 - val_loss: 0.1084 - val_lwlrap: 0.7595\n",
      "Epoch 50/100\n",
      "15/15 - 7s - loss: 0.1169 - lwlrap: 0.8197 - val_loss: 0.1095 - val_lwlrap: 0.7538\n",
      "Epoch 51/100\n",
      "15/15 - 7s - loss: 0.1814 - lwlrap: 0.7945 - val_loss: 0.1168 - val_lwlrap: 0.7475\n",
      "Epoch 52/100\n",
      "15/15 - 6s - loss: 0.0911 - lwlrap: 0.7651 - val_loss: 0.1212 - val_lwlrap: 0.7578\n",
      "Epoch 53/100\n",
      "15/15 - 7s - loss: 0.1476 - lwlrap: 0.8231 - val_loss: 0.1194 - val_lwlrap: 0.7519\n",
      "Epoch 54/100\n",
      "15/15 - 7s - loss: 0.1644 - lwlrap: 0.8040 - val_loss: 0.1173 - val_lwlrap: 0.7596\n",
      "Epoch 55/100\n",
      "15/15 - 7s - loss: 0.1753 - lwlrap: 0.8427 - val_loss: 0.1152 - val_lwlrap: 0.7691\n",
      "Epoch 56/100\n",
      "15/15 - 7s - loss: 0.0911 - lwlrap: 0.7960 - val_loss: 0.1139 - val_lwlrap: 0.7698\n",
      "Epoch 57/100\n",
      "15/15 - 6s - loss: 0.1731 - lwlrap: 0.8245 - val_loss: 0.1144 - val_lwlrap: 0.7617\n",
      "Epoch 58/100\n",
      "15/15 - 7s - loss: 0.1759 - lwlrap: 0.8284 - val_loss: 0.1128 - val_lwlrap: 0.7652\n",
      "Epoch 59/100\n",
      "15/15 - 7s - loss: 0.1933 - lwlrap: 0.8335 - val_loss: 0.1189 - val_lwlrap: 0.7684\n",
      "Epoch 60/100\n",
      "15/15 - 7s - loss: 0.0890 - lwlrap: 0.8169 - val_loss: 0.1176 - val_lwlrap: 0.7669\n",
      "Epoch 61/100\n",
      "15/15 - 6s - loss: 0.0745 - lwlrap: 0.8165 - val_loss: 0.1255 - val_lwlrap: 0.7782\n",
      "Epoch 62/100\n",
      "15/15 - 7s - loss: 0.1755 - lwlrap: 0.8234 - val_loss: 0.1223 - val_lwlrap: 0.7877\n",
      "Epoch 63/100\n",
      "15/15 - 7s - loss: 0.1770 - lwlrap: 0.8387 - val_loss: 0.1181 - val_lwlrap: 0.7885\n",
      "Epoch 64/100\n",
      "15/15 - 7s - loss: 0.1806 - lwlrap: 0.8370 - val_loss: 0.1195 - val_lwlrap: 0.7811\n",
      "Epoch 65/100\n",
      "15/15 - 6s - loss: 0.1796 - lwlrap: 0.8081 - val_loss: 0.1202 - val_lwlrap: 0.7663\n",
      "Epoch 66/100\n",
      "15/15 - 7s - loss: 0.1792 - lwlrap: 0.8447 - val_loss: 0.1206 - val_lwlrap: 0.7740\n",
      "Epoch 67/100\n",
      "15/15 - 7s - loss: 0.0886 - lwlrap: 0.8453 - val_loss: 0.1209 - val_lwlrap: 0.7838\n",
      "Epoch 68/100\n",
      "15/15 - 7s - loss: 0.0836 - lwlrap: 0.8373 - val_loss: 0.1194 - val_lwlrap: 0.7866\n",
      "Epoch 69/100\n",
      "15/15 - 6s - loss: 0.1835 - lwlrap: 0.8235 - val_loss: 0.1271 - val_lwlrap: 0.7775\n",
      "Epoch 70/100\n",
      "15/15 - 7s - loss: 0.1968 - lwlrap: 0.8476 - val_loss: 0.1293 - val_lwlrap: 0.7753\n",
      "Epoch 71/100\n",
      "15/15 - 7s - loss: 0.1818 - lwlrap: 0.8268 - val_loss: 0.1311 - val_lwlrap: 0.7578\n",
      "Epoch 72/100\n",
      "15/15 - 7s - loss: 0.1867 - lwlrap: 0.8400 - val_loss: 0.1294 - val_lwlrap: 0.7728\n",
      "Epoch 73/100\n",
      "15/15 - 7s - loss: 0.1924 - lwlrap: 0.8250 - val_loss: 0.1245 - val_lwlrap: 0.7665\n",
      "Epoch 74/100\n",
      "15/15 - 7s - loss: 0.1984 - lwlrap: 0.8501 - val_loss: 0.1205 - val_lwlrap: 0.7745\n",
      "Epoch 75/100\n",
      "15/15 - 7s - loss: 0.1823 - lwlrap: 0.8571 - val_loss: 0.1209 - val_lwlrap: 0.7642\n",
      "Epoch 76/100\n",
      "15/15 - 6s - loss: 0.0749 - lwlrap: 0.8322 - val_loss: 0.1180 - val_lwlrap: 0.7643\n",
      "Epoch 77/100\n",
      "15/15 - 7s - loss: 0.0960 - lwlrap: 0.8537 - val_loss: 0.1234 - val_lwlrap: 0.7558\n",
      "Epoch 78/100\n",
      "15/15 - 6s - loss: 0.0883 - lwlrap: 0.8339 - val_loss: 0.1255 - val_lwlrap: 0.7590\n",
      "Epoch 79/100\n",
      "15/15 - 7s - loss: 0.1888 - lwlrap: 0.8497 - val_loss: 0.1310 - val_lwlrap: 0.7834\n",
      "Epoch 80/100\n",
      "15/15 - 7s - loss: 0.0805 - lwlrap: 0.8633 - val_loss: 0.1289 - val_lwlrap: 0.7783\n",
      "Epoch 81/100\n",
      "15/15 - 7s - loss: 0.0748 - lwlrap: 0.8475 - val_loss: 0.1202 - val_lwlrap: 0.7766\n",
      "Epoch 82/100\n",
      "15/15 - 7s - loss: 0.1777 - lwlrap: 0.8516 - val_loss: 0.1240 - val_lwlrap: 0.7689\n",
      "Epoch 83/100\n",
      "15/15 - 7s - loss: 0.1764 - lwlrap: 0.8318 - val_loss: 0.1244 - val_lwlrap: 0.7639\n",
      "Epoch 84/100\n",
      "15/15 - 6s - loss: 0.0856 - lwlrap: 0.8377 - val_loss: 0.1259 - val_lwlrap: 0.7727\n",
      "Epoch 85/100\n",
      "15/15 - 7s - loss: 0.0890 - lwlrap: 0.8557 - val_loss: 0.1217 - val_lwlrap: 0.7648\n",
      "Epoch 86/100\n",
      "15/15 - 7s - loss: 0.1818 - lwlrap: 0.8849 - val_loss: 0.1170 - val_lwlrap: 0.7756\n",
      "Epoch 87/100\n",
      "15/15 - 6s - loss: 0.1838 - lwlrap: 0.8171 - val_loss: 0.1182 - val_lwlrap: 0.7842\n",
      "Epoch 88/100\n",
      "15/15 - 6s - loss: 0.0921 - lwlrap: 0.8396 - val_loss: 0.1185 - val_lwlrap: 0.7898\n",
      "Epoch 89/100\n",
      "15/15 - 7s - loss: 0.1878 - lwlrap: 0.8665 - val_loss: 0.1200 - val_lwlrap: 0.7788\n",
      "Epoch 90/100\n",
      "15/15 - 7s - loss: 0.0759 - lwlrap: 0.8719 - val_loss: 0.1209 - val_lwlrap: 0.7765\n",
      "Epoch 91/100\n",
      "15/15 - 7s - loss: 0.2050 - lwlrap: 0.8735 - val_loss: 0.1262 - val_lwlrap: 0.7773\n",
      "Epoch 92/100\n",
      "15/15 - 7s - loss: 0.1836 - lwlrap: 0.8921 - val_loss: 0.1236 - val_lwlrap: 0.7680\n",
      "Epoch 93/100\n",
      "15/15 - 6s - loss: 0.0744 - lwlrap: 0.8405 - val_loss: 0.1230 - val_lwlrap: 0.7759\n",
      "Epoch 94/100\n",
      "15/15 - 6s - loss: 0.0632 - lwlrap: 0.8482 - val_loss: 0.1228 - val_lwlrap: 0.7773\n",
      "Epoch 95/100\n",
      "15/15 - 7s - loss: 0.1906 - lwlrap: 0.8936 - val_loss: 0.1254 - val_lwlrap: 0.7960\n",
      "Epoch 96/100\n",
      "15/15 - 7s - loss: 0.1785 - lwlrap: 0.8884 - val_loss: 0.1255 - val_lwlrap: 0.7873\n",
      "Epoch 97/100\n",
      "15/15 - 6s - loss: 0.1682 - lwlrap: 0.8687 - val_loss: 0.1275 - val_lwlrap: 0.7621\n",
      "Epoch 98/100\n",
      "15/15 - 7s - loss: 0.1866 - lwlrap: 0.8779 - val_loss: 0.1288 - val_lwlrap: 0.7659\n",
      "Epoch 99/100\n",
      "15/15 - 7s - loss: 0.1909 - lwlrap: 0.8863 - val_loss: 0.1377 - val_lwlrap: 0.7815\n",
      "Epoch 100/100\n",
      "15/15 - 7s - loss: 0.1770 - lwlrap: 0.8806 - val_loss: 0.1320 - val_lwlrap: 0.7762\n",
      "\n",
      "-------------   Fold 4 / 5  -------------\n",
      "\n",
      " -> Preparing Data \n",
      "\n",
      " -> Preparing Model \n",
      "\n",
      " -> Loading weights from ../logs/2021-02-04/3/pretrained_best_fold3.h5\n",
      "\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      " -> Training Model \n",
      "\n",
      "Epoch 1/100\n",
      "15/15 - 72s - loss: 0.2804 - lwlrap: 0.1855 - val_loss: 0.3806 - val_lwlrap: 0.2146\n",
      "Epoch 2/100\n",
      "15/15 - 6s - loss: 0.2845 - lwlrap: 0.2231 - val_loss: 0.2151 - val_lwlrap: 0.2644\n",
      "Epoch 3/100\n",
      "15/15 - 6s - loss: 0.2892 - lwlrap: 0.2637 - val_loss: 0.1733 - val_lwlrap: 0.4015\n",
      "Epoch 4/100\n",
      "15/15 - 6s - loss: 0.3272 - lwlrap: 0.2912 - val_loss: 0.1733 - val_lwlrap: 0.3816\n",
      "Epoch 5/100\n",
      "15/15 - 6s - loss: 0.1417 - lwlrap: 0.3481 - val_loss: 0.2050 - val_lwlrap: 0.5665\n",
      "Epoch 6/100\n",
      "15/15 - 6s - loss: 0.3426 - lwlrap: 0.4080 - val_loss: 0.1870 - val_lwlrap: 0.6192\n",
      "Epoch 7/100\n",
      "15/15 - 6s - loss: 0.1526 - lwlrap: 0.4489 - val_loss: 0.1634 - val_lwlrap: 0.7001\n",
      "Epoch 8/100\n",
      "15/15 - 6s - loss: 0.2920 - lwlrap: 0.4622 - val_loss: 0.1485 - val_lwlrap: 0.7165\n",
      "Epoch 9/100\n",
      "15/15 - 6s - loss: 0.1285 - lwlrap: 0.4773 - val_loss: 0.1449 - val_lwlrap: 0.7032\n",
      "Epoch 10/100\n",
      "15/15 - 6s - loss: 0.1946 - lwlrap: 0.4935 - val_loss: 0.1473 - val_lwlrap: 0.6693\n",
      "Epoch 11/100\n",
      "15/15 - 6s - loss: 0.2076 - lwlrap: 0.4820 - val_loss: 0.1298 - val_lwlrap: 0.6503\n",
      "Epoch 12/100\n",
      "15/15 - 7s - loss: 0.1179 - lwlrap: 0.5524 - val_loss: 0.1160 - val_lwlrap: 0.7401\n",
      "Epoch 13/100\n",
      "15/15 - 6s - loss: 0.1241 - lwlrap: 0.5165 - val_loss: 0.0998 - val_lwlrap: 0.7227\n",
      "Epoch 14/100\n",
      "15/15 - 6s - loss: 0.0612 - lwlrap: 0.5770 - val_loss: 0.0964 - val_lwlrap: 0.7771\n",
      "Epoch 15/100\n",
      "15/15 - 6s - loss: 0.0767 - lwlrap: 0.5732 - val_loss: 0.0993 - val_lwlrap: 0.7684\n",
      "Epoch 16/100\n",
      "15/15 - 6s - loss: 0.1655 - lwlrap: 0.5610 - val_loss: 0.0954 - val_lwlrap: 0.7917\n",
      "Epoch 17/100\n",
      "15/15 - 6s - loss: 0.1519 - lwlrap: 0.5799 - val_loss: 0.1080 - val_lwlrap: 0.7468\n",
      "Epoch 18/100\n",
      "15/15 - 6s - loss: 0.1454 - lwlrap: 0.6127 - val_loss: 0.1077 - val_lwlrap: 0.7423\n",
      "Epoch 19/100\n",
      "15/15 - 7s - loss: 0.2035 - lwlrap: 0.6960 - val_loss: 0.0989 - val_lwlrap: 0.7702\n",
      "Epoch 20/100\n",
      "15/15 - 6s - loss: 0.1039 - lwlrap: 0.6606 - val_loss: 0.1029 - val_lwlrap: 0.7854\n",
      "Epoch 21/100\n",
      "15/15 - 6s - loss: 0.1392 - lwlrap: 0.6387 - val_loss: 0.1004 - val_lwlrap: 0.7886\n",
      "Epoch 22/100\n",
      "15/15 - 6s - loss: 0.0850 - lwlrap: 0.7001 - val_loss: 0.1021 - val_lwlrap: 0.7986\n",
      "Epoch 23/100\n",
      "15/15 - 6s - loss: 0.1843 - lwlrap: 0.6533 - val_loss: 0.1042 - val_lwlrap: 0.7770\n",
      "Epoch 24/100\n",
      "15/15 - 6s - loss: 0.1991 - lwlrap: 0.6663 - val_loss: 0.1021 - val_lwlrap: 0.7816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "15/15 - 7s - loss: 0.0972 - lwlrap: 0.7166 - val_loss: 0.1010 - val_lwlrap: 0.8043\n",
      "Epoch 26/100\n",
      "15/15 - 6s - loss: 0.1664 - lwlrap: 0.7199 - val_loss: 0.0942 - val_lwlrap: 0.8056\n",
      "Epoch 27/100\n",
      "15/15 - 7s - loss: 0.1316 - lwlrap: 0.7022 - val_loss: 0.0934 - val_lwlrap: 0.8067\n",
      "Epoch 28/100\n",
      "15/15 - 7s - loss: 0.1036 - lwlrap: 0.7385 - val_loss: 0.0955 - val_lwlrap: 0.8038\n",
      "Epoch 29/100\n",
      "15/15 - 6s - loss: 0.1133 - lwlrap: 0.7197 - val_loss: 0.0979 - val_lwlrap: 0.8121\n",
      "Epoch 30/100\n",
      "15/15 - 7s - loss: 0.0985 - lwlrap: 0.7066 - val_loss: 0.0951 - val_lwlrap: 0.8075\n",
      "Epoch 31/100\n",
      "15/15 - 7s - loss: 0.1213 - lwlrap: 0.7460 - val_loss: 0.0966 - val_lwlrap: 0.7795\n",
      "Epoch 32/100\n",
      "15/15 - 7s - loss: 0.1587 - lwlrap: 0.7438 - val_loss: 0.0908 - val_lwlrap: 0.8110\n",
      "Epoch 33/100\n",
      "15/15 - 7s - loss: 0.1161 - lwlrap: 0.8156 - val_loss: 0.0902 - val_lwlrap: 0.8368\n",
      "Epoch 34/100\n",
      "15/15 - 7s - loss: 0.1366 - lwlrap: 0.7793 - val_loss: 0.0938 - val_lwlrap: 0.8327\n",
      "Epoch 35/100\n",
      "15/15 - 7s - loss: 0.0908 - lwlrap: 0.7758 - val_loss: 0.0918 - val_lwlrap: 0.8338\n",
      "Epoch 36/100\n",
      "15/15 - 7s - loss: 0.1398 - lwlrap: 0.7637 - val_loss: 0.0947 - val_lwlrap: 0.8284\n",
      "Epoch 37/100\n",
      "15/15 - 6s - loss: 0.1426 - lwlrap: 0.7439 - val_loss: 0.0879 - val_lwlrap: 0.8291\n",
      "Epoch 38/100\n",
      "15/15 - 7s - loss: 0.0897 - lwlrap: 0.7889 - val_loss: 0.0882 - val_lwlrap: 0.8329\n",
      "Epoch 39/100\n",
      "15/15 - 6s - loss: 0.1047 - lwlrap: 0.7599 - val_loss: 0.0970 - val_lwlrap: 0.8145\n",
      "Epoch 40/100\n",
      "15/15 - 7s - loss: 0.0888 - lwlrap: 0.7654 - val_loss: 0.0940 - val_lwlrap: 0.8277\n",
      "Epoch 41/100\n",
      "15/15 - 7s - loss: 0.0998 - lwlrap: 0.7585 - val_loss: 0.0952 - val_lwlrap: 0.8253\n",
      "Epoch 42/100\n",
      "15/15 - 6s - loss: 0.0748 - lwlrap: 0.7602 - val_loss: 0.0950 - val_lwlrap: 0.8323\n",
      "Epoch 43/100\n",
      "15/15 - 7s - loss: 0.1637 - lwlrap: 0.7554 - val_loss: 0.0988 - val_lwlrap: 0.8351\n",
      "Epoch 44/100\n",
      "15/15 - 7s - loss: 0.1516 - lwlrap: 0.8281 - val_loss: 0.0912 - val_lwlrap: 0.8467\n",
      "Epoch 45/100\n",
      "15/15 - 7s - loss: 0.1597 - lwlrap: 0.8262 - val_loss: 0.0885 - val_lwlrap: 0.8447\n",
      "Epoch 46/100\n",
      "15/15 - 6s - loss: 0.1417 - lwlrap: 0.7733 - val_loss: 0.0913 - val_lwlrap: 0.8420\n",
      "Epoch 47/100\n",
      "15/15 - 7s - loss: 0.0959 - lwlrap: 0.8121 - val_loss: 0.0998 - val_lwlrap: 0.8297\n",
      "Epoch 48/100\n",
      "15/15 - 7s - loss: 0.1607 - lwlrap: 0.8361 - val_loss: 0.0964 - val_lwlrap: 0.8370\n",
      "Epoch 49/100\n",
      "15/15 - 7s - loss: 0.1483 - lwlrap: 0.8164 - val_loss: 0.0934 - val_lwlrap: 0.8323\n",
      "Epoch 50/100\n",
      "15/15 - 7s - loss: 0.1577 - lwlrap: 0.8219 - val_loss: 0.0891 - val_lwlrap: 0.8392\n",
      "Epoch 51/100\n",
      "15/15 - 6s - loss: 0.0824 - lwlrap: 0.8168 - val_loss: 0.0941 - val_lwlrap: 0.8424\n",
      "Epoch 52/100\n",
      "15/15 - 6s - loss: 0.1014 - lwlrap: 0.8226 - val_loss: 0.0963 - val_lwlrap: 0.8437\n",
      "Epoch 53/100\n",
      "15/15 - 7s - loss: 0.0817 - lwlrap: 0.8199 - val_loss: 0.0975 - val_lwlrap: 0.8387\n",
      "Epoch 54/100\n",
      "15/15 - 7s - loss: 0.0930 - lwlrap: 0.7947 - val_loss: 0.0944 - val_lwlrap: 0.8369\n",
      "Epoch 55/100\n",
      "15/15 - 6s - loss: 0.0933 - lwlrap: 0.8212 - val_loss: 0.0998 - val_lwlrap: 0.8271\n",
      "Epoch 56/100\n",
      "15/15 - 7s - loss: 0.1839 - lwlrap: 0.8596 - val_loss: 0.1013 - val_lwlrap: 0.8379\n",
      "Epoch 57/100\n",
      "15/15 - 6s - loss: 0.1684 - lwlrap: 0.8044 - val_loss: 0.0953 - val_lwlrap: 0.8263\n",
      "Epoch 58/100\n",
      "15/15 - 7s - loss: 0.0768 - lwlrap: 0.8173 - val_loss: 0.0986 - val_lwlrap: 0.8310\n",
      "Epoch 59/100\n",
      "15/15 - 7s - loss: 0.0838 - lwlrap: 0.8362 - val_loss: 0.1004 - val_lwlrap: 0.8316\n",
      "Epoch 60/100\n",
      "15/15 - 6s - loss: 0.1714 - lwlrap: 0.7984 - val_loss: 0.0987 - val_lwlrap: 0.8265\n",
      "Epoch 61/100\n",
      "15/15 - 7s - loss: 0.1652 - lwlrap: 0.8440 - val_loss: 0.0992 - val_lwlrap: 0.8430\n",
      "Epoch 62/100\n",
      "15/15 - 7s - loss: 0.1751 - lwlrap: 0.8624 - val_loss: 0.0952 - val_lwlrap: 0.8476\n",
      "Epoch 63/100\n",
      "15/15 - 7s - loss: 0.1705 - lwlrap: 0.8530 - val_loss: 0.0950 - val_lwlrap: 0.8456\n",
      "Epoch 64/100\n",
      "15/15 - 6s - loss: 0.0842 - lwlrap: 0.8319 - val_loss: 0.0971 - val_lwlrap: 0.8369\n",
      "Epoch 65/100\n",
      "15/15 - 7s - loss: 0.1613 - lwlrap: 0.8395 - val_loss: 0.1061 - val_lwlrap: 0.8382\n",
      "Epoch 66/100\n",
      "15/15 - 6s - loss: 0.0839 - lwlrap: 0.8423 - val_loss: 0.1032 - val_lwlrap: 0.8406\n",
      "Epoch 67/100\n",
      "15/15 - 7s - loss: 0.0737 - lwlrap: 0.8452 - val_loss: 0.0998 - val_lwlrap: 0.8282\n",
      "Epoch 68/100\n",
      "15/15 - 7s - loss: 0.0915 - lwlrap: 0.8553 - val_loss: 0.0982 - val_lwlrap: 0.8432\n",
      "Epoch 69/100\n",
      "15/15 - 7s - loss: 0.1733 - lwlrap: 0.8684 - val_loss: 0.1007 - val_lwlrap: 0.8506\n",
      "Epoch 70/100\n",
      "15/15 - 6s - loss: 0.1837 - lwlrap: 0.8379 - val_loss: 0.1020 - val_lwlrap: 0.8458\n",
      "Epoch 71/100\n",
      "15/15 - 7s - loss: 0.1787 - lwlrap: 0.8603 - val_loss: 0.1106 - val_lwlrap: 0.8211\n",
      "Epoch 72/100\n",
      "15/15 - 7s - loss: 0.1675 - lwlrap: 0.8517 - val_loss: 0.1075 - val_lwlrap: 0.8370\n",
      "Epoch 73/100\n",
      "15/15 - 6s - loss: 0.0656 - lwlrap: 0.8412 - val_loss: 0.1055 - val_lwlrap: 0.8271\n",
      "Epoch 74/100\n",
      "15/15 - 7s - loss: 0.1781 - lwlrap: 0.8679 - val_loss: 0.1079 - val_lwlrap: 0.8318\n",
      "Epoch 75/100\n",
      "15/15 - 7s - loss: 0.1836 - lwlrap: 0.8710 - val_loss: 0.0988 - val_lwlrap: 0.8305\n",
      "Epoch 76/100\n",
      "15/15 - 7s - loss: 0.1877 - lwlrap: 0.8636 - val_loss: 0.0997 - val_lwlrap: 0.8310\n",
      "Epoch 77/100\n",
      "15/15 - 6s - loss: 0.1910 - lwlrap: 0.8414 - val_loss: 0.1041 - val_lwlrap: 0.8155\n",
      "Epoch 78/100\n",
      "15/15 - 7s - loss: 0.0810 - lwlrap: 0.8699 - val_loss: 0.1097 - val_lwlrap: 0.8287\n",
      "Epoch 79/100\n",
      "15/15 - 6s - loss: 0.0800 - lwlrap: 0.8313 - val_loss: 0.1059 - val_lwlrap: 0.8254\n",
      "Epoch 80/100\n",
      "15/15 - 6s - loss: 0.1679 - lwlrap: 0.8593 - val_loss: 0.1070 - val_lwlrap: 0.8283\n",
      "Epoch 81/100\n",
      "15/15 - 6s - loss: 0.0610 - lwlrap: 0.8540 - val_loss: 0.1118 - val_lwlrap: 0.8300\n",
      "Epoch 82/100\n",
      "15/15 - 7s - loss: 0.0644 - lwlrap: 0.8643 - val_loss: 0.1066 - val_lwlrap: 0.8371\n",
      "Epoch 83/100\n",
      "15/15 - 7s - loss: 0.1680 - lwlrap: 0.8802 - val_loss: 0.1016 - val_lwlrap: 0.8427\n",
      "Epoch 84/100\n",
      "15/15 - 6s - loss: 0.1693 - lwlrap: 0.8580 - val_loss: 0.1011 - val_lwlrap: 0.8404\n",
      "Epoch 85/100\n",
      "15/15 - 7s - loss: 0.1745 - lwlrap: 0.8933 - val_loss: 0.1112 - val_lwlrap: 0.8340\n",
      "Epoch 86/100\n",
      "15/15 - 7s - loss: 0.1712 - lwlrap: 0.8864 - val_loss: 0.1090 - val_lwlrap: 0.8409\n",
      "Epoch 87/100\n",
      "15/15 - 6s - loss: 0.1782 - lwlrap: 0.8547 - val_loss: 0.1135 - val_lwlrap: 0.8341\n",
      "Epoch 88/100\n",
      "15/15 - 7s - loss: 0.1797 - lwlrap: 0.8669 - val_loss: 0.1102 - val_lwlrap: 0.8407\n",
      "Epoch 89/100\n",
      "15/15 - 7s - loss: 0.1791 - lwlrap: 0.8883 - val_loss: 0.1082 - val_lwlrap: 0.8269\n",
      "Epoch 90/100\n",
      "15/15 - 6s - loss: 0.0735 - lwlrap: 0.8743 - val_loss: 0.1096 - val_lwlrap: 0.8218\n",
      "Epoch 91/100\n",
      "15/15 - 7s - loss: 0.0649 - lwlrap: 0.8900 - val_loss: 0.1104 - val_lwlrap: 0.8451\n",
      "Epoch 92/100\n",
      "15/15 - 7s - loss: 0.1689 - lwlrap: 0.8984 - val_loss: 0.1086 - val_lwlrap: 0.8319\n",
      "Epoch 93/100\n",
      "15/15 - 7s - loss: 0.0673 - lwlrap: 0.8877 - val_loss: 0.1158 - val_lwlrap: 0.8226\n",
      "Epoch 94/100\n",
      "15/15 - 6s - loss: 0.1645 - lwlrap: 0.8775 - val_loss: 0.1148 - val_lwlrap: 0.8383\n",
      "Epoch 95/100\n",
      "15/15 - 7s - loss: 0.0631 - lwlrap: 0.8930 - val_loss: 0.1157 - val_lwlrap: 0.8508\n",
      "Epoch 96/100\n",
      "15/15 - 7s - loss: 0.0813 - lwlrap: 0.9108 - val_loss: 0.1190 - val_lwlrap: 0.8469\n",
      "Epoch 97/100\n",
      "15/15 - 6s - loss: 0.0857 - lwlrap: 0.8719 - val_loss: 0.1214 - val_lwlrap: 0.8204\n",
      "Epoch 98/100\n",
      "15/15 - 7s - loss: 0.1693 - lwlrap: 0.8905 - val_loss: 0.1229 - val_lwlrap: 0.8297\n",
      "Epoch 99/100\n",
      "15/15 - 7s - loss: 0.1869 - lwlrap: 0.8965 - val_loss: 0.1323 - val_lwlrap: 0.8248\n",
      "Epoch 100/100\n",
      "15/15 - 6s - loss: 0.0672 - lwlrap: 0.8719 - val_loss: 0.1235 - val_lwlrap: 0.8253\n",
      "\n",
      "-------------   Fold 5 / 5  -------------\n",
      "\n",
      " -> Preparing Data \n",
      "\n",
      " -> Preparing Model \n",
      "\n",
      " -> Loading weights from ../logs/2021-02-04/3/pretrained_best_fold4.h5\n",
      "\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      " -> Training Model \n",
      "\n",
      "Epoch 1/100\n",
      "15/15 - 73s - loss: 0.3233 - lwlrap: 0.1754 - val_loss: 0.2987 - val_lwlrap: 0.1716\n",
      "Epoch 2/100\n",
      "15/15 - 6s - loss: 0.2060 - lwlrap: 0.2086 - val_loss: 0.1933 - val_lwlrap: 0.2407\n",
      "Epoch 3/100\n",
      "15/15 - 6s - loss: 0.1363 - lwlrap: 0.2817 - val_loss: 0.1812 - val_lwlrap: 0.4056\n",
      "Epoch 4/100\n",
      "15/15 - 6s - loss: 0.1150 - lwlrap: 0.3474 - val_loss: 0.1603 - val_lwlrap: 0.5426\n",
      "Epoch 5/100\n",
      "15/15 - 7s - loss: 0.1085 - lwlrap: 0.3496 - val_loss: 0.1494 - val_lwlrap: 0.5071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "15/15 - 6s - loss: 0.1797 - lwlrap: 0.3680 - val_loss: 0.1477 - val_lwlrap: 0.6327\n",
      "Epoch 7/100\n",
      "15/15 - 6s - loss: 0.1322 - lwlrap: 0.4056 - val_loss: 0.1397 - val_lwlrap: 0.6700\n",
      "Epoch 8/100\n",
      "15/15 - 6s - loss: 0.1575 - lwlrap: 0.4416 - val_loss: 0.1291 - val_lwlrap: 0.7019\n",
      "Epoch 9/100\n",
      "15/15 - 6s - loss: 0.1183 - lwlrap: 0.4645 - val_loss: 0.1522 - val_lwlrap: 0.6294\n",
      "Epoch 10/100\n",
      "15/15 - 6s - loss: 0.0981 - lwlrap: 0.5211 - val_loss: 0.1378 - val_lwlrap: 0.6782\n",
      "Epoch 11/100\n",
      "15/15 - 6s - loss: 0.0951 - lwlrap: 0.4867 - val_loss: 0.1432 - val_lwlrap: 0.6723\n",
      "Epoch 12/100\n",
      "15/15 - 6s - loss: 0.1109 - lwlrap: 0.5807 - val_loss: 0.1415 - val_lwlrap: 0.7312\n",
      "Epoch 13/100\n",
      "15/15 - 7s - loss: 0.2303 - lwlrap: 0.5515 - val_loss: 0.1241 - val_lwlrap: 0.7508\n",
      "Epoch 14/100\n",
      "15/15 - 6s - loss: 0.2496 - lwlrap: 0.6025 - val_loss: 0.1210 - val_lwlrap: 0.7699\n",
      "Epoch 15/100\n",
      "15/15 - 6s - loss: 0.0892 - lwlrap: 0.5732 - val_loss: 0.1147 - val_lwlrap: 0.7692\n",
      "Epoch 16/100\n",
      "15/15 - 6s - loss: 0.1592 - lwlrap: 0.5851 - val_loss: 0.1192 - val_lwlrap: 0.7565\n",
      "Epoch 17/100\n",
      "15/15 - 7s - loss: 0.1291 - lwlrap: 0.6418 - val_loss: 0.1339 - val_lwlrap: 0.7452\n",
      "Epoch 18/100\n",
      "15/15 - 6s - loss: 0.2213 - lwlrap: 0.6167 - val_loss: 0.1043 - val_lwlrap: 0.7578\n",
      "Epoch 19/100\n",
      "15/15 - 7s - loss: 0.1961 - lwlrap: 0.6587 - val_loss: 0.1030 - val_lwlrap: 0.7358\n",
      "Epoch 20/100\n",
      "15/15 - 6s - loss: 0.0727 - lwlrap: 0.6604 - val_loss: 0.1023 - val_lwlrap: 0.7743\n",
      "Epoch 21/100\n",
      "15/15 - 6s - loss: 0.2553 - lwlrap: 0.6523 - val_loss: 0.1066 - val_lwlrap: 0.7655\n",
      "Epoch 22/100\n",
      "15/15 - 7s - loss: 0.1339 - lwlrap: 0.6950 - val_loss: 0.1042 - val_lwlrap: 0.7917\n",
      "Epoch 23/100\n",
      "15/15 - 7s - loss: 0.2021 - lwlrap: 0.6726 - val_loss: 0.1113 - val_lwlrap: 0.7448\n",
      "Epoch 24/100\n",
      "15/15 - 7s - loss: 0.1631 - lwlrap: 0.6577 - val_loss: 0.1082 - val_lwlrap: 0.7872\n",
      "Epoch 25/100\n",
      "15/15 - 6s - loss: 0.2414 - lwlrap: 0.6429 - val_loss: 0.1080 - val_lwlrap: 0.7753\n",
      "Epoch 26/100\n",
      "15/15 - 6s - loss: 0.1184 - lwlrap: 0.6633 - val_loss: 0.1091 - val_lwlrap: 0.7904\n",
      "Epoch 27/100\n",
      "15/15 - 6s - loss: 0.1226 - lwlrap: 0.6662 - val_loss: 0.1074 - val_lwlrap: 0.8079\n",
      "Epoch 28/100\n",
      "15/15 - 6s - loss: 0.1322 - lwlrap: 0.7005 - val_loss: 0.1062 - val_lwlrap: 0.8079\n",
      "Epoch 29/100\n",
      "15/15 - 7s - loss: 0.1274 - lwlrap: 0.7098 - val_loss: 0.1180 - val_lwlrap: 0.7631\n",
      "Epoch 30/100\n",
      "15/15 - 6s - loss: 0.1478 - lwlrap: 0.7095 - val_loss: 0.1116 - val_lwlrap: 0.7862\n",
      "Epoch 31/100\n",
      "15/15 - 6s - loss: 0.1574 - lwlrap: 0.7396 - val_loss: 0.1205 - val_lwlrap: 0.7403\n",
      "Epoch 32/100\n",
      "15/15 - 7s - loss: 0.1588 - lwlrap: 0.7294 - val_loss: 0.1004 - val_lwlrap: 0.8126\n",
      "Epoch 33/100\n",
      "15/15 - 7s - loss: 0.1417 - lwlrap: 0.7343 - val_loss: 0.1182 - val_lwlrap: 0.7869\n",
      "Epoch 34/100\n",
      "15/15 - 7s - loss: 0.1431 - lwlrap: 0.7542 - val_loss: 0.1072 - val_lwlrap: 0.8085\n",
      "Epoch 35/100\n",
      "15/15 - 6s - loss: 0.1698 - lwlrap: 0.7119 - val_loss: 0.1087 - val_lwlrap: 0.8143\n",
      "Epoch 36/100\n",
      "15/15 - 6s - loss: 0.0895 - lwlrap: 0.6976 - val_loss: 0.1111 - val_lwlrap: 0.8041\n",
      "Epoch 37/100\n",
      "15/15 - 6s - loss: 0.1522 - lwlrap: 0.7218 - val_loss: 0.1183 - val_lwlrap: 0.7909\n",
      "Epoch 38/100\n",
      "15/15 - 7s - loss: 0.1856 - lwlrap: 0.7603 - val_loss: 0.1113 - val_lwlrap: 0.8232\n",
      "Epoch 39/100\n",
      "15/15 - 7s - loss: 0.1590 - lwlrap: 0.8111 - val_loss: 0.1047 - val_lwlrap: 0.8301\n",
      "Epoch 40/100\n",
      "15/15 - 7s - loss: 0.2131 - lwlrap: 0.7364 - val_loss: 0.1066 - val_lwlrap: 0.8248\n",
      "Epoch 41/100\n",
      "15/15 - 7s - loss: 0.1632 - lwlrap: 0.7801 - val_loss: 0.1123 - val_lwlrap: 0.8108\n",
      "Epoch 42/100\n",
      "15/15 - 6s - loss: 0.1145 - lwlrap: 0.7338 - val_loss: 0.1207 - val_lwlrap: 0.8242\n",
      "Epoch 43/100\n",
      "15/15 - 7s - loss: 0.1127 - lwlrap: 0.7559 - val_loss: 0.1170 - val_lwlrap: 0.8188\n",
      "Epoch 44/100\n",
      "15/15 - 7s - loss: 0.1656 - lwlrap: 0.8036 - val_loss: 0.1155 - val_lwlrap: 0.8246\n",
      "Epoch 45/100\n",
      "15/15 - 6s - loss: 0.1115 - lwlrap: 0.7280 - val_loss: 0.1294 - val_lwlrap: 0.7984\n",
      "Epoch 46/100\n",
      "15/15 - 6s - loss: 0.1177 - lwlrap: 0.7681 - val_loss: 0.1289 - val_lwlrap: 0.8068\n",
      "Epoch 47/100\n",
      "15/15 - 7s - loss: 0.0911 - lwlrap: 0.7974 - val_loss: 0.1194 - val_lwlrap: 0.8112\n",
      "Epoch 48/100\n",
      "15/15 - 7s - loss: 0.1712 - lwlrap: 0.8021 - val_loss: 0.1245 - val_lwlrap: 0.8250\n",
      "Epoch 49/100\n",
      "15/15 - 6s - loss: 0.1052 - lwlrap: 0.7430 - val_loss: 0.1337 - val_lwlrap: 0.7969\n",
      "Epoch 50/100\n",
      "15/15 - 7s - loss: 0.1896 - lwlrap: 0.7801 - val_loss: 0.1297 - val_lwlrap: 0.8206\n",
      "Epoch 51/100\n",
      "15/15 - 7s - loss: 0.1881 - lwlrap: 0.7944 - val_loss: 0.1167 - val_lwlrap: 0.8263\n",
      "Epoch 52/100\n",
      "15/15 - 6s - loss: 0.1899 - lwlrap: 0.8011 - val_loss: 0.1264 - val_lwlrap: 0.8152\n",
      "Epoch 53/100\n",
      "15/15 - 7s - loss: 0.1852 - lwlrap: 0.8145 - val_loss: 0.1166 - val_lwlrap: 0.8317\n",
      "Epoch 54/100\n",
      "15/15 - 6s - loss: 0.0837 - lwlrap: 0.7787 - val_loss: 0.1160 - val_lwlrap: 0.8346\n",
      "Epoch 55/100\n",
      "15/15 - 6s - loss: 0.1131 - lwlrap: 0.7588 - val_loss: 0.1147 - val_lwlrap: 0.8373\n",
      "Epoch 56/100\n",
      "15/15 - 6s - loss: 0.2235 - lwlrap: 0.8062 - val_loss: 0.1289 - val_lwlrap: 0.8148\n",
      "Epoch 57/100\n",
      "15/15 - 6s - loss: 0.1918 - lwlrap: 0.7971 - val_loss: 0.1231 - val_lwlrap: 0.8283\n",
      "Epoch 58/100\n",
      "15/15 - 6s - loss: 0.0793 - lwlrap: 0.7982 - val_loss: 0.1247 - val_lwlrap: 0.8332\n",
      "Epoch 59/100\n",
      "15/15 - 6s - loss: 0.1057 - lwlrap: 0.7846 - val_loss: 0.1231 - val_lwlrap: 0.8246\n",
      "Epoch 60/100\n",
      "15/15 - 6s - loss: 0.1216 - lwlrap: 0.7925 - val_loss: 0.1345 - val_lwlrap: 0.8209\n",
      "Epoch 61/100\n",
      "15/15 - 6s - loss: 0.1028 - lwlrap: 0.8010 - val_loss: 0.1266 - val_lwlrap: 0.8132\n",
      "Epoch 62/100\n",
      "15/15 - 6s - loss: 0.1033 - lwlrap: 0.7836 - val_loss: 0.1318 - val_lwlrap: 0.8265\n",
      "Epoch 63/100\n",
      "15/15 - 7s - loss: 0.1880 - lwlrap: 0.8004 - val_loss: 0.1236 - val_lwlrap: 0.8226\n",
      "Epoch 64/100\n",
      "15/15 - 7s - loss: 0.2174 - lwlrap: 0.8496 - val_loss: 0.1172 - val_lwlrap: 0.8383\n",
      "Epoch 65/100\n",
      "15/15 - 6s - loss: 0.1231 - lwlrap: 0.8212 - val_loss: 0.1209 - val_lwlrap: 0.8114\n",
      "Epoch 66/100\n",
      "15/15 - 6s - loss: 0.1102 - lwlrap: 0.8405 - val_loss: 0.1184 - val_lwlrap: 0.8371\n",
      "Epoch 67/100\n",
      "15/15 - 7s - loss: 0.1921 - lwlrap: 0.8487 - val_loss: 0.1213 - val_lwlrap: 0.8161\n",
      "Epoch 68/100\n",
      "15/15 - 6s - loss: 0.1936 - lwlrap: 0.8405 - val_loss: 0.1204 - val_lwlrap: 0.8160\n",
      "Epoch 69/100\n",
      "15/15 - 6s - loss: 0.0868 - lwlrap: 0.8085 - val_loss: 0.1281 - val_lwlrap: 0.8300\n",
      "Epoch 70/100\n",
      "15/15 - 6s - loss: 0.1877 - lwlrap: 0.8224 - val_loss: 0.1338 - val_lwlrap: 0.8289\n",
      "Epoch 71/100\n",
      "15/15 - 7s - loss: 0.2080 - lwlrap: 0.8297 - val_loss: 0.1262 - val_lwlrap: 0.8342\n",
      "Epoch 72/100\n",
      "15/15 - 7s - loss: 0.0795 - lwlrap: 0.8254 - val_loss: 0.1294 - val_lwlrap: 0.8289\n",
      "Epoch 73/100\n",
      "15/15 - 6s - loss: 0.1443 - lwlrap: 0.8354 - val_loss: 0.1272 - val_lwlrap: 0.8339\n",
      "Epoch 74/100\n",
      "15/15 - 7s - loss: 0.1962 - lwlrap: 0.8590 - val_loss: 0.1253 - val_lwlrap: 0.8395\n",
      "Epoch 75/100\n",
      "15/15 - 7s - loss: 0.1951 - lwlrap: 0.8481 - val_loss: 0.1362 - val_lwlrap: 0.8163\n",
      "Epoch 76/100\n",
      "15/15 - 7s - loss: 0.0789 - lwlrap: 0.8660 - val_loss: 0.1365 - val_lwlrap: 0.8336\n",
      "Epoch 77/100\n",
      "15/15 - 7s - loss: 0.0691 - lwlrap: 0.8505 - val_loss: 0.1364 - val_lwlrap: 0.8402\n",
      "Epoch 78/100\n",
      "15/15 - 6s - loss: 0.0834 - lwlrap: 0.8375 - val_loss: 0.1350 - val_lwlrap: 0.8345\n",
      "Epoch 79/100\n",
      "15/15 - 6s - loss: 0.1141 - lwlrap: 0.8401 - val_loss: 0.1313 - val_lwlrap: 0.8219\n",
      "Epoch 80/100\n",
      "15/15 - 7s - loss: 0.1933 - lwlrap: 0.8435 - val_loss: 0.1346 - val_lwlrap: 0.8261\n",
      "Epoch 81/100\n",
      "15/15 - 6s - loss: 0.1990 - lwlrap: 0.8362 - val_loss: 0.1335 - val_lwlrap: 0.8299\n",
      "Epoch 82/100\n",
      "15/15 - 7s - loss: 0.1978 - lwlrap: 0.8563 - val_loss: 0.1370 - val_lwlrap: 0.8272\n",
      "Epoch 83/100\n",
      "15/15 - 7s - loss: 0.2023 - lwlrap: 0.8627 - val_loss: 0.1424 - val_lwlrap: 0.8254\n",
      "Epoch 84/100\n",
      "15/15 - 7s - loss: 0.2034 - lwlrap: 0.8746 - val_loss: 0.1323 - val_lwlrap: 0.8421\n",
      "Epoch 85/100\n",
      "15/15 - 7s - loss: 0.2098 - lwlrap: 0.8797 - val_loss: 0.1321 - val_lwlrap: 0.8357\n",
      "Epoch 86/100\n",
      "15/15 - 7s - loss: 0.2029 - lwlrap: 0.8675 - val_loss: 0.1291 - val_lwlrap: 0.8432\n",
      "Epoch 87/100\n",
      "15/15 - 7s - loss: 0.2020 - lwlrap: 0.8676 - val_loss: 0.1293 - val_lwlrap: 0.8541\n",
      "Epoch 88/100\n",
      "15/15 - 7s - loss: 0.1981 - lwlrap: 0.8633 - val_loss: 0.1247 - val_lwlrap: 0.8431\n",
      "Epoch 89/100\n",
      "15/15 - 6s - loss: 0.0761 - lwlrap: 0.8400 - val_loss: 0.1282 - val_lwlrap: 0.8307\n",
      "Epoch 90/100\n",
      "15/15 - 6s - loss: 0.0778 - lwlrap: 0.8569 - val_loss: 0.1295 - val_lwlrap: 0.8349\n",
      "Epoch 91/100\n",
      "15/15 - 7s - loss: 0.0901 - lwlrap: 0.8692 - val_loss: 0.1277 - val_lwlrap: 0.8595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "15/15 - 7s - loss: 0.2034 - lwlrap: 0.8704 - val_loss: 0.1295 - val_lwlrap: 0.8559\n",
      "Epoch 93/100\n",
      "15/15 - 7s - loss: 0.0994 - lwlrap: 0.8733 - val_loss: 0.1410 - val_lwlrap: 0.8276\n",
      "Epoch 94/100\n",
      "15/15 - 7s - loss: 0.1940 - lwlrap: 0.8505 - val_loss: 0.1370 - val_lwlrap: 0.8284\n",
      "Epoch 95/100\n",
      "15/15 - 7s - loss: 0.2130 - lwlrap: 0.8608 - val_loss: 0.1359 - val_lwlrap: 0.8279\n",
      "Epoch 96/100\n",
      "15/15 - 6s - loss: 0.2074 - lwlrap: 0.8755 - val_loss: 0.1358 - val_lwlrap: 0.8436\n",
      "Epoch 97/100\n",
      "15/15 - 6s - loss: 0.1924 - lwlrap: 0.8500 - val_loss: 0.1376 - val_lwlrap: 0.8228\n",
      "Epoch 98/100\n",
      "15/15 - 7s - loss: 0.0767 - lwlrap: 0.8661 - val_loss: 0.1410 - val_lwlrap: 0.8342\n",
      "Epoch 99/100\n",
      "15/15 - 7s - loss: 0.0740 - lwlrap: 0.8692 - val_loss: 0.1583 - val_lwlrap: 0.7959\n",
      "Epoch 100/100\n",
      "15/15 - 7s - loss: 0.0745 - lwlrap: 0.8983 - val_loss: 0.1460 - val_lwlrap: 0.8076\n"
     ]
    }
   ],
   "source": [
    "for model_name in MODELS:\n",
    "    print(f\"\\n\\nModel {model_name}\\n\\n\")\n",
    "    if not DEBUG:\n",
    "        log_folder = prepare_log_folder(LOG_PATH)\n",
    "        print(f'Logging results to {log_folder}')\n",
    "        create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "    for fold_idx in range(5):\n",
    "        tf.keras.backend.clear_session()\n",
    "        print(f\"\\n-------------   Fold {fold_idx + 1} / {5}  -------------\\n\")\n",
    "\n",
    "        main(\n",
    "            model_name=model_name,\n",
    "            fold_idx=fold_idx, \n",
    "            saved_path=log_folder, \n",
    "            pretrained_path=PRETRAINED_FOLDERS[model_name] + f\"pretrained_best_fold{fold_idx}.h5\",\n",
    "        )\n",
    "\n",
    "        if DEBUG:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model_name in BIGGER_MODELS:\n",
    "    print(f\"\\n\\nModel {model_name}\\n\\n\")\n",
    "    if not DEBUG:\n",
    "        log_folder = prepare_log_folder(LOG_PATH)\n",
    "        print(f'Logging results to {log_folder}')\n",
    "        create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "    for fold_idx in range(4, 5):\n",
    "        tf.keras.backend.clear_session()\n",
    "        print(f\"\\n-------------   Fold {fold_idx + 1} / {5}  -------------\\n\")\n",
    "\n",
    "        main(\n",
    "            model_name=model_name,\n",
    "            batch_size=32,\n",
    "            fold_idx=fold_idx, \n",
    "            saved_path=log_folder, \n",
    "            pretrained_path=PRETRAINED_FOLDERS[model_name] + f\"pretrained_best_fold{fold_idx}.h5\",\n",
    "        )\n",
    "\n",
    "        if DEBUG:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
