{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/notebooks/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas\n",
    "except:\n",
    "    !pip install pandas iterative-stratification nlpaug==0.0.20 tqdm click tensorflow_probability==0.11.1 tf2_resnets tensorflow_addons==0.11.1 image-classifiers==0.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloader import BalancedMelSampler, MelSampler, convert_csv_to_dict_for_dataloader\n",
    "from losses import NpairsLoss\n",
    "from metrics import TFLWLRAP\n",
    "from split_data import get_split\n",
    "from train import get_model, get_callbacks, get_lr_metric\n",
    "from models import NUM_FRAMES, Classifier, DeepMetricLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.logger import prepare_log_folder, create_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "for i in range(len(physical_devices)):\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[i], True)\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(epoch, lr, min_lr=1e-5, max_lr=1e-3, epochs=30, warmup_prop=0.1):   \n",
    "    if epoch <= epochs * warmup_prop:\n",
    "        return min_lr + max_lr - (max_lr * (epochs * warmup_prop - epoch) / (epochs * warmup_prop))\n",
    "    else:\n",
    "        return min_lr + max_lr - (max_lr * (epoch - epochs * warmup_prop) / (epochs - epochs * warmup_prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(fold_idx, saved_path, pretrained_path, pretrained_with_contrastive):\n",
    "    os.makedirs(os.path.join(saved_path, f\"fold{fold_idx}\"), exist_ok=True)\n",
    "    pretrained_with_contrastive = bool(pretrained_with_contrastive)\n",
    "\n",
    "    print(' -> Preparing Data \\n')\n",
    "    \n",
    "    train_data = pd.read_csv(\"../data/new_train_tp.csv\")\n",
    "    train_index, val_index = get_split(fold=fold_idx)\n",
    "    fold_train_dict = convert_csv_to_dict_for_dataloader(train_data.iloc[train_index])\n",
    "    fold_valid_dict = convert_csv_to_dict_for_dataloader(train_data.iloc[val_index])\n",
    "\n",
    "    balanced_train_data_loader = BalancedMelSampler(\n",
    "        fold_train_dict,\n",
    "        batch_size=32,\n",
    "        max_length=NUM_FRAMES,\n",
    "        is_train=True,\n",
    "        n_classes=24,\n",
    "        use_cutmix=True,\n",
    "        cache=True,\n",
    "        n_classes_in_batch=8,\n",
    "        shuffle_aug=False,\n",
    "    )\n",
    "\n",
    "    valid_data_loader = MelSampler(\n",
    "        fold_valid_dict,\n",
    "        batch_size=balanced_train_data_loader.batch_size,\n",
    "        n_classes=balanced_train_data_loader.n_classes,\n",
    "        cache=True,\n",
    "        max_length=NUM_FRAMES,\n",
    "        is_train=False,\n",
    "        use_cutmix=False,\n",
    "        shuffle_aug=balanced_train_data_loader.shuffle_aug,\n",
    "    )\n",
    "    \n",
    "#     return 0\n",
    "\n",
    "    print(' -> Preparing Model \\n')\n",
    "    model = get_model(\n",
    "        saved_path=saved_path,\n",
    "        pretrained_with_contrastive=pretrained_with_contrastive,\n",
    "        pretrained_path=pretrained_path,\n",
    "    )\n",
    "    model._build()\n",
    "    \n",
    "    scheduler = tfa.optimizers.Triangular2CyclicalLearningRate(\n",
    "        initial_learning_rate=1e-4,\n",
    "        maximal_learning_rate=1e-3,\n",
    "        step_size=15 * 20,\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(\n",
    "        tfa.optimizers.Lookahead(\n",
    "            tf.keras.optimizers.Adam(learning_rate=scheduler),\n",
    "            10,\n",
    "            0.5,\n",
    "        ),\n",
    "        \"dynamic\",\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        metrics=[TFLWLRAP(num_classes=24, name=\"lwlrap\")],\n",
    "        metric_loss_fn=NpairsLoss(temperature=0.1, name=\"n_pairs\"),\n",
    "        classification_loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    )   \n",
    "\n",
    "    print(' -> Training Model \\n')\n",
    "\n",
    "    callbacks = get_callbacks(pretrained_with_contrastive, fold_idx, saved_path=saved_path)\n",
    "    steps_per_epoch = int((len(fold_train_dict)) / balanced_train_data_loader.batch_size)\n",
    "    \n",
    "    model.fit(\n",
    "        balanced_train_data_loader,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=60,\n",
    "        validation_data=valid_data_loader,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "pretrained_folder = \"../logs/2021-01-28/1/\"   # simple\n",
    "pretrained_folder = \"../logs/2021-01-30/42/\"  # mixstyle + iunterpolate + cbam\n",
    "pretrained_folder = \"../logs/2021-01-31/8/\"  # mixstyle + iunterpolate + cbam without relu\n",
    "log_folder = \"../logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbones = [\n",
    "    \"efficientnetb0\",\n",
    "    \"efficientnetb1\",\n",
    "    \"efficientnetb2\",\n",
    "    \"efficientnetb3\",\n",
    "    \"efficientnetb4\",\n",
    "    \"resnet50\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging results to ../logs/2021-01-31/14/\n",
      "\n",
      "-------------   Fold 1 / 5  -------------\n",
      "\n",
      " -> Preparing Data \n",
      "\n",
      " -> Preparing Model \n",
      "\n",
      " -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold0.h5\n",
      "\n",
      " -> Training Model \n",
      "\n",
      "Epoch 1/60\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "30/30 - 10s - loss: 0.0730 - lwlrap: 0.5469 - val_loss: 0.0821 - val_lwlrap: 0.7128\n",
      "Epoch 2/60\n",
      "30/30 - 8s - loss: 0.0667 - lwlrap: 0.7439 - val_loss: 0.0697 - val_lwlrap: 0.6979\n",
      "Epoch 3/60\n",
      "30/30 - 8s - loss: 0.0538 - lwlrap: 0.7060 - val_loss: 0.0716 - val_lwlrap: 0.7001\n",
      "Epoch 4/60\n",
      "30/30 - 8s - loss: 0.0436 - lwlrap: 0.7766 - val_loss: 0.0715 - val_lwlrap: 0.7104\n",
      "Epoch 5/60\n",
      "30/30 - 8s - loss: 0.0334 - lwlrap: 0.8058 - val_loss: 0.0527 - val_lwlrap: 0.7283\n",
      "Epoch 6/60\n",
      "30/30 - 8s - loss: 0.0274 - lwlrap: 0.8369 - val_loss: 0.0524 - val_lwlrap: 0.7538\n",
      "Epoch 7/60\n",
      "30/30 - 8s - loss: 0.0229 - lwlrap: 0.8557 - val_loss: 0.0587 - val_lwlrap: 0.7711\n",
      "Epoch 8/60\n",
      "30/30 - 8s - loss: 0.0198 - lwlrap: 0.8534 - val_loss: 0.0476 - val_lwlrap: 0.7886\n",
      "Epoch 9/60\n",
      "30/30 - 8s - loss: 0.0396 - lwlrap: 0.8463 - val_loss: 0.0525 - val_lwlrap: 0.7436\n",
      "Epoch 10/60\n",
      "30/30 - 8s - loss: 0.0346 - lwlrap: 0.7870 - val_loss: 0.0443 - val_lwlrap: 0.7634\n",
      "Epoch 11/60\n",
      "30/30 - 8s - loss: 0.0535 - lwlrap: 0.8739 - val_loss: 0.0415 - val_lwlrap: 0.7504\n",
      "Epoch 12/60\n",
      "30/30 - 8s - loss: 0.0267 - lwlrap: 0.8697 - val_loss: 0.0499 - val_lwlrap: 0.8033\n",
      "Epoch 13/60\n",
      "30/30 - 8s - loss: 0.0184 - lwlrap: 0.9220 - val_loss: 0.0478 - val_lwlrap: 0.8116\n",
      "Epoch 14/60\n",
      "30/30 - 8s - loss: 0.0147 - lwlrap: 0.9479 - val_loss: 0.0398 - val_lwlrap: 0.7789\n",
      "Epoch 15/60\n",
      "30/30 - 8s - loss: 0.0113 - lwlrap: 0.9472 - val_loss: 0.0495 - val_lwlrap: 0.7999\n",
      "Epoch 16/60\n",
      "30/30 - 8s - loss: 0.0132 - lwlrap: 0.9620 - val_loss: 0.0471 - val_lwlrap: 0.8061\n",
      "Epoch 17/60\n",
      "30/30 - 8s - loss: 0.0135 - lwlrap: 0.9734 - val_loss: 0.0522 - val_lwlrap: 0.8132\n",
      "Epoch 18/60\n",
      "30/30 - 8s - loss: 0.0087 - lwlrap: 0.9784 - val_loss: 0.0470 - val_lwlrap: 0.8003\n",
      "Epoch 19/60\n",
      "30/30 - 8s - loss: 0.0056 - lwlrap: 0.9868 - val_loss: 0.0566 - val_lwlrap: 0.8094\n",
      "Epoch 20/60\n",
      "30/30 - 8s - loss: 0.0072 - lwlrap: 0.9837 - val_loss: 0.0555 - val_lwlrap: 0.8193\n",
      "Epoch 21/60\n",
      "30/30 - 8s - loss: 0.0050 - lwlrap: 0.9884 - val_loss: 0.0512 - val_lwlrap: 0.8283\n",
      "Epoch 22/60\n",
      "30/30 - 8s - loss: 0.0050 - lwlrap: 0.9898 - val_loss: 0.0631 - val_lwlrap: 0.8145\n",
      "Epoch 23/60\n",
      "30/30 - 8s - loss: 0.0065 - lwlrap: 0.9911 - val_loss: 0.0570 - val_lwlrap: 0.8246\n",
      "Epoch 24/60\n",
      "30/30 - 8s - loss: 0.0037 - lwlrap: 0.9932 - val_loss: 0.0598 - val_lwlrap: 0.8011\n",
      "Epoch 25/60\n",
      "30/30 - 8s - loss: 0.0088 - lwlrap: 0.9908 - val_loss: 0.0484 - val_lwlrap: 0.7982\n",
      "Epoch 26/60\n",
      "30/30 - 8s - loss: 0.0053 - lwlrap: 0.9931 - val_loss: 0.0508 - val_lwlrap: 0.8239\n",
      "Epoch 27/60\n",
      "30/30 - 8s - loss: 0.0088 - lwlrap: 0.9935 - val_loss: 0.0470 - val_lwlrap: 0.8229\n",
      "Epoch 28/60\n",
      "30/30 - 8s - loss: 0.0047 - lwlrap: 0.9903 - val_loss: 0.0578 - val_lwlrap: 0.8257\n",
      "Epoch 29/60\n",
      "30/30 - 8s - loss: 0.0115 - lwlrap: 0.9925 - val_loss: 0.0493 - val_lwlrap: 0.8249\n",
      "Epoch 30/60\n",
      "30/30 - 8s - loss: 0.0049 - lwlrap: 0.9818 - val_loss: 0.0525 - val_lwlrap: 0.8227\n",
      "Epoch 31/60\n",
      "30/30 - 8s - loss: 0.0080 - lwlrap: 0.9889 - val_loss: 0.0516 - val_lwlrap: 0.7980\n",
      "Epoch 32/60\n",
      "30/30 - 8s - loss: 0.0075 - lwlrap: 0.9896 - val_loss: 0.0544 - val_lwlrap: 0.8108\n",
      "Epoch 33/60\n",
      "30/30 - 8s - loss: 0.0053 - lwlrap: 0.9878 - val_loss: 0.0552 - val_lwlrap: 0.8351\n",
      "Epoch 34/60\n",
      "30/30 - 8s - loss: 0.0093 - lwlrap: 0.9918 - val_loss: 0.0453 - val_lwlrap: 0.8051\n",
      "Epoch 35/60\n",
      "30/30 - 8s - loss: 0.0052 - lwlrap: 0.9924 - val_loss: 0.0597 - val_lwlrap: 0.8394\n",
      "Epoch 36/60\n",
      "30/30 - 8s - loss: 0.0055 - lwlrap: 0.9947 - val_loss: 0.0502 - val_lwlrap: 0.8306\n",
      "Epoch 37/60\n",
      "30/30 - 8s - loss: 0.0026 - lwlrap: 0.9986 - val_loss: 0.0510 - val_lwlrap: 0.8258\n",
      "Epoch 38/60\n",
      "30/30 - 8s - loss: 0.0043 - lwlrap: 0.9971 - val_loss: 0.0588 - val_lwlrap: 0.8259\n",
      "Epoch 39/60\n",
      "30/30 - 8s - loss: 0.0034 - lwlrap: 0.9990 - val_loss: 0.0465 - val_lwlrap: 0.8221\n",
      "Epoch 40/60\n",
      "30/30 - 8s - loss: 0.0043 - lwlrap: 0.9976 - val_loss: 0.0538 - val_lwlrap: 0.8262\n",
      "Epoch 41/60\n",
      "30/30 - 8s - loss: 0.0026 - lwlrap: 0.9990 - val_loss: 0.0527 - val_lwlrap: 0.8080\n",
      "Epoch 42/60\n",
      "30/30 - 8s - loss: 0.0022 - lwlrap: 0.9995 - val_loss: 0.0551 - val_lwlrap: 0.7935\n",
      "Epoch 43/60\n",
      "30/30 - 8s - loss: 0.0035 - lwlrap: 0.9996 - val_loss: 0.0628 - val_lwlrap: 0.8288\n",
      "Epoch 44/60\n",
      "30/30 - 8s - loss: 0.0069 - lwlrap: 0.9992 - val_loss: 0.0603 - val_lwlrap: 0.8211\n",
      "Epoch 45/60\n",
      "30/30 - 8s - loss: 0.0036 - lwlrap: 0.9996 - val_loss: 0.0696 - val_lwlrap: 0.7974\n",
      "Epoch 46/60\n",
      "30/30 - 8s - loss: 0.0033 - lwlrap: 0.9991 - val_loss: 0.0696 - val_lwlrap: 0.8005\n",
      "Epoch 47/60\n",
      "30/30 - 8s - loss: 0.0044 - lwlrap: 0.9988 - val_loss: 0.0700 - val_lwlrap: 0.8187\n",
      "Epoch 48/60\n",
      "30/30 - 8s - loss: 0.0028 - lwlrap: 0.9986 - val_loss: 0.0594 - val_lwlrap: 0.7972\n",
      "Epoch 49/60\n",
      "30/30 - 8s - loss: 0.0077 - lwlrap: 0.9992 - val_loss: 0.0729 - val_lwlrap: 0.8017\n",
      "Epoch 50/60\n",
      "30/30 - 8s - loss: 0.0025 - lwlrap: 0.9973 - val_loss: 0.0674 - val_lwlrap: 0.8057\n",
      "Epoch 51/60\n",
      "30/30 - 8s - loss: 0.0015 - lwlrap: 1.0000 - val_loss: 0.0604 - val_lwlrap: 0.7813\n",
      "Epoch 52/60\n",
      "30/30 - 8s - loss: 0.0063 - lwlrap: 0.9984 - val_loss: 0.0641 - val_lwlrap: 0.7884\n",
      "Epoch 53/60\n",
      "30/30 - 8s - loss: 0.0035 - lwlrap: 0.9995 - val_loss: 0.0594 - val_lwlrap: 0.8189\n",
      "Epoch 54/60\n",
      "30/30 - 8s - loss: 0.0036 - lwlrap: 0.9986 - val_loss: 0.0549 - val_lwlrap: 0.7889\n",
      "Epoch 55/60\n",
      "30/30 - 8s - loss: 0.0028 - lwlrap: 0.9994 - val_loss: 0.0545 - val_lwlrap: 0.8248\n",
      "\n",
      "-------------   Fold 2 / 5  -------------\n",
      "\n",
      " -> Preparing Data \n",
      "\n",
      " -> Preparing Model \n",
      "\n",
      " -> Loading weights from ../logs/2021-01-31/8/pretrained_best_fold1.h5\n",
      "\n",
      " -> Training Model \n",
      "\n",
      "Epoch 1/60\n",
      "30/30 - 10s - loss: 0.0424 - lwlrap: 0.4926 - val_loss: 0.0576 - val_lwlrap: 0.7078\n",
      "Epoch 2/60\n",
      "30/30 - 8s - loss: 0.0332 - lwlrap: 0.7924 - val_loss: 0.0551 - val_lwlrap: 0.7878\n",
      "Epoch 3/60\n",
      "30/30 - 8s - loss: 0.0197 - lwlrap: 0.8702 - val_loss: 0.0475 - val_lwlrap: 0.8283\n",
      "Epoch 4/60\n",
      "30/30 - 8s - loss: 0.0155 - lwlrap: 0.8814 - val_loss: 0.0399 - val_lwlrap: 0.7949\n",
      "Epoch 5/60\n",
      "30/30 - 8s - loss: 0.0223 - lwlrap: 0.8994 - val_loss: 0.0384 - val_lwlrap: 0.8051\n",
      "Epoch 6/60\n",
      "30/30 - 8s - loss: 0.0172 - lwlrap: 0.9001 - val_loss: 0.0376 - val_lwlrap: 0.8122\n",
      "Epoch 7/60\n",
      "30/30 - 8s - loss: 0.0396 - lwlrap: 0.8576 - val_loss: 0.0353 - val_lwlrap: 0.7706\n",
      "Epoch 8/60\n",
      "30/30 - 8s - loss: 0.0275 - lwlrap: 0.8860 - val_loss: 0.0327 - val_lwlrap: 0.8201\n",
      "Epoch 9/60\n",
      "30/30 - 8s - loss: 0.0166 - lwlrap: 0.8981 - val_loss: 0.0309 - val_lwlrap: 0.7300\n",
      "Epoch 10/60\n",
      "30/30 - 8s - loss: 0.0237 - lwlrap: 0.9045 - val_loss: 0.0327 - val_lwlrap: 0.7567\n",
      "Epoch 11/60\n",
      "30/30 - 8s - loss: 0.0164 - lwlrap: 0.9324 - val_loss: 0.0287 - val_lwlrap: 0.8018\n",
      "Epoch 12/60\n",
      "30/30 - 8s - loss: 0.0160 - lwlrap: 0.9475 - val_loss: 0.0289 - val_lwlrap: 0.8567\n",
      "Epoch 13/60\n",
      "30/30 - 8s - loss: 0.0148 - lwlrap: 0.9649 - val_loss: 0.0251 - val_lwlrap: 0.8397\n",
      "Epoch 14/60\n",
      "30/30 - 8s - loss: 0.0063 - lwlrap: 0.9822 - val_loss: 0.0304 - val_lwlrap: 0.8484\n",
      "Epoch 15/60\n",
      "30/30 - 8s - loss: 0.0191 - lwlrap: 0.9804 - val_loss: 0.0320 - val_lwlrap: 0.8644\n",
      "Epoch 16/60\n",
      "30/30 - 8s - loss: 0.0049 - lwlrap: 0.9818 - val_loss: 0.0309 - val_lwlrap: 0.8379\n",
      "Epoch 17/60\n",
      "30/30 - 8s - loss: 0.0056 - lwlrap: 0.9935 - val_loss: 0.0285 - val_lwlrap: 0.8576\n",
      "Epoch 18/60\n",
      "30/30 - 8s - loss: 0.0165 - lwlrap: 0.9931 - val_loss: 0.0300 - val_lwlrap: 0.8520\n",
      "Epoch 19/60\n",
      "30/30 - 8s - loss: 0.0080 - lwlrap: 0.9886 - val_loss: 0.0297 - val_lwlrap: 0.8794\n",
      "Epoch 20/60\n",
      "30/30 - 8s - loss: 0.0030 - lwlrap: 0.9932 - val_loss: 0.0311 - val_lwlrap: 0.8759\n",
      "Epoch 21/60\n",
      "30/30 - 8s - loss: 0.0084 - lwlrap: 0.9957 - val_loss: 0.0327 - val_lwlrap: 0.8682\n",
      "Epoch 22/60\n",
      "30/30 - 8s - loss: 0.0062 - lwlrap: 0.9964 - val_loss: 0.0324 - val_lwlrap: 0.8579\n",
      "Epoch 23/60\n",
      "30/30 - 8s - loss: 0.0058 - lwlrap: 0.9942 - val_loss: 0.0363 - val_lwlrap: 0.8643\n",
      "Epoch 24/60\n",
      "30/30 - 8s - loss: 0.0050 - lwlrap: 0.9969 - val_loss: 0.0350 - val_lwlrap: 0.8717\n",
      "Epoch 25/60\n",
      "30/30 - 8s - loss: 0.0050 - lwlrap: 0.9964 - val_loss: 0.0334 - val_lwlrap: 0.8584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/60\n",
      "30/30 - 8s - loss: 0.0060 - lwlrap: 0.9927 - val_loss: 0.0359 - val_lwlrap: 0.8668\n",
      "Epoch 27/60\n",
      "30/30 - 8s - loss: 0.0057 - lwlrap: 0.9946 - val_loss: 0.0345 - val_lwlrap: 0.8792\n",
      "Epoch 28/60\n",
      "30/30 - 8s - loss: 0.0073 - lwlrap: 0.9924 - val_loss: 0.0389 - val_lwlrap: 0.8506\n",
      "Epoch 29/60\n",
      "30/30 - 8s - loss: 0.0067 - lwlrap: 0.9967 - val_loss: 0.0407 - val_lwlrap: 0.8339\n",
      "Epoch 30/60\n",
      "30/30 - 8s - loss: 0.0069 - lwlrap: 0.9944 - val_loss: 0.0418 - val_lwlrap: 0.8241\n",
      "Epoch 31/60\n",
      "30/30 - 8s - loss: 0.0035 - lwlrap: 0.9977 - val_loss: 0.0440 - val_lwlrap: 0.8553\n",
      "Epoch 32/60\n",
      "30/30 - 8s - loss: 0.0076 - lwlrap: 0.9949 - val_loss: 0.0486 - val_lwlrap: 0.8265\n",
      "Epoch 33/60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7e1ad824e66f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlog_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpretrained_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"pretrained_best_fold{fold_idx}.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpretrained_with_contrastive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ea6365c95a21>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(fold_idx, saved_path, pretrained_path, pretrained_with_contrastive)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autoreload of backbones failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/tf/notebooks/src/backbones/__init__.py\", line 12, in <module>\n",
      "    from backbones.resnext import ResNeXt50\n",
      "  File \"/tf/notebooks/src/backbones/resnext.py\", line 2, in <module>\n",
      "    from tf2_resnets.resnet import ResNet\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2_resnets/resnet.py\", line 298, in <module>\n",
      "    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TORCH)\n",
      "KeyError: 'error'\n",
      "]\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/tf/notebooks/src\n"
     ]
    }
   ],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f'Logging results to {log_folder}')\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "    \n",
    "for fold_idx in range(5):\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(f\"\\n-------------   Fold {fold_idx + 1} / {5}  -------------\\n\")\n",
    "    \n",
    "    main(\n",
    "        fold_idx, \n",
    "        log_folder, \n",
    "        pretrained_folder + f\"pretrained_best_fold{fold_idx}.h5\", \n",
    "        pretrained_with_contrastive=False\n",
    "    )\n",
    "    \n",
    "    if DEBUG:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
